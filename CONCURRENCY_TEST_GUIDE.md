# 🧪 并发测试指南

**目的**: 测试后端最大并发处理能力，找出最佳并发数

---

## 📋 测试说明

### 测试内容
- 测试1-10个并发请求
- 每个测试发送N个同时请求到后端
- 统计成功率、响应时间、吞吐量
- 找出最佳并发数

### 测试指标
1. **成功率** - 请求成功的百分比
2. **平均响应时间** - 平均每个请求的耗时
3. **吞吐量** - 每秒处理的请求数
4. **最大/最小响应时间** - 响应时间范围

---

## 🚀 使用方法

### 方法1: 使用批处理脚本（推荐）
```bash
# Windows
TEST_CONCURRENCY.bat

# 会自动安装依赖并运行测试
```

### 方法2: 直接运行Python脚本
```bash
# 1. 安装依赖
pip install aiohttp

# 2. 运行测试
python test_concurrency.py
```

---

## 📊 测试流程

### 1. 准备阶段
```
✅ 检查Python版本（需要3.7+）
✅ 安装aiohttp库
✅ 确认后端运行在 http://localhost:8000
```

### 2. 测试阶段
```
测试并发数: 1
  发送1个请求
  统计结果
  
等待5秒...

测试并发数: 2
  发送2个同时请求
  统计结果
  
等待5秒...

... (依次测试 3, 4, 5, 6, 8, 10)
```

### 3. 结果分析
```
生成测试报告
保存JSON结果文件
给出推荐并发数
```

---

## 📈 预期结果

### 示例输出
```
====================================
🚀 测试并发数: 2
====================================

📊 测试结果:
  总请求数: 2
  总耗时: 35.23秒
  ✅ 成功: 2 (100.0%)
  ❌ 失败: 0
  ⏱️  超时: 0
  🔥 错误: 0

⏱️  响应时间统计:
  平均: 32.45秒
  最快: 30.12秒
  最慢: 34.78秒

📈 吞吐量: 0.06 请求/秒

📋 详细结果:
  ✅ 请求#1: success - 30.12秒
  ✅ 请求#2: success - 34.78秒
```

### 总结报告
```
====================================
📊 测试总结
====================================

并发数   成功率     平均耗时     吞吐量       推荐
------------------------------------------------------------
1        100.0%     30.23s       0.03/s      
2        100.0%     32.45s       0.06/s      ✅ 推荐
3        100.0%     45.67s       0.07/s      
4        75.0%      60.12s       0.05/s      
5        60.0%      75.34s       0.04/s      ❌ 不推荐
6        50.0%      90.45s       0.03/s      ❌ 不推荐

====================================
🎯 推荐并发数: 2
   理由: 成功率100%，吞吐量最高(0.06请求/秒)
====================================
```

---

## 🎯 结果解读

### 成功率 100%
- ✅ 所有请求都成功完成
- ✅ 没有超时或错误
- ✅ 这个并发数是安全的

### 成功率 < 100%
- ⚠️ 有请求失败或超时
- ⚠️ 并发数可能过高
- ⚠️ 后端处理不过来

### 吞吐量
- 越高越好
- 表示单位时间处理的请求数
- 找到成功率100%时的最高吞吐量

---

## 💡 优化建议

### 如果并发数很低（1-2）
**原因**:
- 后端处理速度慢
- LLM调用耗时长
- 没有并发优化

**解决方案**:
1. 使用异步处理
2. 添加请求队列
3. 优化LLM调用
4. 使用缓存

### 如果并发数适中（3-5）
**原因**:
- 后端有一定并发能力
- 但受限于资源

**解决方案**:
1. 增加服务器资源
2. 优化代码性能
3. 使用连接池

### 如果并发数很高（6+）
**原因**:
- 后端并发能力强
- 资源充足

**建议**:
- 保持当前配置
- 可以适当提高并发限制

---

## 🔧 配置调整

### 修改测试参数
编辑 `test_concurrency.py`:

```python
# 修改测试的并发数
test_cases = [1, 2, 3, 4, 5, 6, 8, 10]  # 可以添加更多

# 修改超时时间
timeout=120  # 秒

# 修改测试股票
STOCK_CODE = "600519"  # 贵州茅台

# 修改测试智能体
TEST_AGENT_ID = "technical"  # 技术分析师
```

### 修改前端并发限制
编辑 `AnalysisView.vue`:

```javascript
// 根据测试结果调整批次大小
await runAgentsInBatches(stage3Ids, fetchedStockData, 2) // 改为测试得出的最佳值
```

---

## 📝 测试记录

### 测试环境
- **CPU**: _______
- **内存**: _______
- **后端**: Python + FastAPI
- **LLM**: _______

### 测试结果
| 日期 | 并发数 | 成功率 | 平均耗时 | 吞吐量 | 备注 |
|------|--------|--------|----------|--------|------|
| 2025-12-05 | 2 | 100% | 32s | 0.06/s | 推荐 |
| | | | | | |

---

## ⚠️ 注意事项

### 1. 测试前确认
- ✅ 后端正在运行
- ✅ 端口8000可访问
- ✅ LLM服务正常

### 2. 测试期间
- ⏸️ 不要进行其他操作
- ⏸️ 不要同时运行多个测试
- ⏸️ 观察后端日志

### 3. 测试后
- 📊 查看生成的JSON文件
- 📊 分析详细数据
- 📊 根据结果调整配置

---

## 🐛 常见问题

### Q: 所有请求都超时
**A**: 
- 检查后端是否运行
- 检查端口是否正确
- 增加超时时间

### Q: 成功率很低
**A**:
- 降低并发数
- 检查后端日志
- 优化后端性能

### Q: 测试很慢
**A**:
- 这是正常的
- LLM调用需要时间
- 可以减少测试用例

---

## 📞 技术支持

如有问题，请查看：
- 后端日志: `backend/logs/`
- 测试结果: `concurrency_test_results_*.json`
- 错误信息: 控制台输出

---

**开始测试**: 运行 `TEST_CONCURRENCY.bat` 🚀
