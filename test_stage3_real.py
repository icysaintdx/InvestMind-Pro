#!/usr/bin/env python3
"""
æ¨¡æ‹Ÿç¬¬ä¸‰é˜¶æ®µçš„çœŸå®å¹¶å‘è¯·æ±‚
ä½¿ç”¨çœŸå®çš„å‰åºè¾“å‡ºå’Œé£æ§æŒ‡ä»¤
"""

import asyncio
import aiohttp
import time
import json
from datetime import datetime

# çœŸå®çš„å‰åºè¾“å‡ºï¼ˆä»å®é™…è¿è¡Œä¸­è·å–ï¼‰
PREVIOUS_OUTPUTS = {
    "news_analyst": "åŸºäºå½“å‰å¸‚åœºç¯å¢ƒåˆ†æï¼Œè¯¥è‚¡ç¥¨è¿‘æœŸæ–°é—»èˆ†æƒ…åå‘ä¸­æ€§ï¼Œæ²¡æœ‰é‡å¤§åˆ©ç©ºæ¶ˆæ¯ã€‚",
    "social_analyst": "ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†ææ˜¾ç¤ºå¸‚åœºæƒ…ç»ªç›¸å¯¹ç†æ€§ï¼Œæ•£æˆ·è®¨è®ºçƒ­åº¦ä¸­ç­‰ã€‚",
    "china_market": "Aè‚¡å¤§ç›˜å¤„äºéœ‡è¡æ•´ç†é˜¶æ®µï¼Œå¸‚åœºæµåŠ¨æ€§é€‚ä¸­ï¼Œæ”¿ç­–ç¯å¢ƒç›¸å¯¹ç¨³å®šã€‚",
    "industry": "è¡Œä¸šå¤„äºæˆé•¿æœŸï¼Œç«äº‰æ ¼å±€ç›¸å¯¹ç¨³å®šï¼Œäº§ä¸šé“¾ä¸Šä¸‹æ¸¸å…³ç³»è‰¯å¥½ã€‚",
    "macro": "è´§å¸æ”¿ç­–ä¿æŒç¨³å¥ï¼Œè´¢æ”¿æ”¿ç­–é€‚åº¦å®½æ¾ï¼Œç»æµå‘¨æœŸå¤„äºå¤è‹é˜¶æ®µã€‚",
    "technical": "Kçº¿å½¢æ€æ˜¾ç¤ºä¸Šå‡è¶‹åŠ¿ï¼Œå‡çº¿ç³»ç»Ÿå‘ˆå¤šå¤´æ’åˆ—ï¼ŒMACDæŒ‡æ ‡æ˜¾ç¤ºä¹°å…¥ä¿¡å·ã€‚",
    "funds": "ä¸»åŠ›èµ„é‡‘å‡€æµå…¥ï¼Œæœºæ„æŒä»“ç¨³å®šï¼ŒåŒ—å‘èµ„é‡‘æŒç»­ä¹°å…¥ï¼Œèµ„é‡‘é¢åå¼ºã€‚",
    "fundamental": "PEä¼°å€¼å¤„äºåˆç†åŒºé—´ï¼ŒROEä¿æŒè¾ƒé«˜æ°´å¹³ï¼Œè´¢åŠ¡å¥åº·åº¦è‰¯å¥½ï¼ŒåŸºæœ¬é¢è‰¯å¥½ã€‚",
    "bull_researcher": "çœ‹æ¶¨é€»è¾‘ï¼šè¡Œä¸šæ™¯æ°”åº¦æå‡ï¼Œå…¬å¸ç«äº‰åŠ›å¢å¼ºï¼Œä¼°å€¼ä¿®å¤ç©ºé—´å¤§ï¼Œå»ºè®®ä¹°å…¥ã€‚",
    "bear_researcher": "çœ‹è·Œé£é™©ï¼šå®è§‚ç»æµå­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¡Œä¸šç«äº‰åŠ å‰§ï¼Œä¼°å€¼åé«˜ï¼Œè°¨æ…æ“ä½œã€‚",
    "manager_fundamental": "åŸºæœ¬é¢ç»¼åˆè¯„ä¼°ï¼šå†…åœ¨ä»·å€¼è¯„ä¼°åˆç†ï¼Œé•¿æœŸæŠ•èµ„ä»·å€¼è¾ƒé«˜ï¼Œè¯„çº§æ¨èä¹°å…¥ã€‚",
    "manager_momentum": "å¸‚åœºåŠ¨èƒ½åˆ†æï¼šçŸ­æœŸåŠ¨èƒ½åå¼ºï¼Œå¸‚åœºæƒ…ç»ªç§¯æï¼Œèµ„é‡‘æµå…¥æŒç»­ï¼ŒçŸ­æœŸçœ‹å¤šã€‚",
    "research_manager": "ç ”ç©¶éƒ¨ç»¼åˆæ„è§ï¼šåŸºæœ¬é¢æ”¯æŒï¼ŒæŠ€æœ¯é¢é…åˆï¼Œèµ„é‡‘é¢è‰¯å¥½ï¼Œè¯„çº§ä¹°å…¥ã€‚"
}

# 6ä¸ªé£æ§æ™ºèƒ½ä½“çš„é…ç½®
RISK_AGENTS = [
    {
        "id": "risk_aggressive",
        "instruction": "å‡è®¾æˆ‘ä»¬å¿…é¡»ä¹°å…¥ï¼Œå¦‚ä½•è®¾ç½®æ­¢æŸä»¥æœ€å¤§åŒ–èµ”ç‡ï¼Ÿ"
    },
    {
        "id": "risk_conservative",
        "instruction": "æŒ‡å‡ºå½“å‰æœ€å±é™©çš„é£é™©ç‚¹ï¼Œå¹¶ç»™å‡ºæœ€ä¿å®ˆçš„ä»“ä½å»ºè®®ã€‚"
    },
    {
        "id": "risk_neutral",
        "instruction": "ä»ä¸­ç«‹è§’åº¦è¯„ä¼°é£é™©æ”¶ç›Šæ¯”ï¼Œç»™å‡ºåˆç†çš„é£é™©ç®¡ç†å»ºè®®ã€‚"
    },
    {
        "id": "risk_system",
        "instruction": "è¯„ä¼°ç³»ç»Ÿæ€§é£é™©å¯¹è¯¥è‚¡ç¥¨çš„æ½œåœ¨å½±å“ã€‚"
    },
    {
        "id": "risk_portfolio",
        "instruction": "ä»ç»„åˆç®¡ç†è§’åº¦ï¼Œè¯„ä¼°è¯¥è‚¡ç¥¨åœ¨æŠ•èµ„ç»„åˆä¸­çš„é£é™©è´¡çŒ®ã€‚"
    },
    {
        "id": "risk_manager",
        "instruction": "ä½œä¸ºé£é™©æ€»ç›‘ï¼Œç»™å‡ºæœ€ç»ˆçš„é£é™©è¯„ä¼°å’Œä»“ä½å»ºè®®ã€‚"
    }
]

STOCK_DATA = {
    "symbol": "600547",
    "name": "å±±ä¸œé»„é‡‘",
    "price": 10.50,
    "change": 2.5,
    "volume": 1000000
}

async def send_request(session, agent, attempt=1):
    """å‘é€å•ä¸ªåˆ†æè¯·æ±‚"""
    url = "http://localhost:8000/api/analyze"
    
    payload = {
        "agent_id": agent["id"],
        "stock_code": STOCK_DATA["symbol"],
        "stock_data": STOCK_DATA,
        "previous_outputs": PREVIOUS_OUTPUTS,
        "custom_instruction": agent["instruction"]
    }
    
    start_time = time.time()
    
    try:
        print(f"[{agent['id']}] ğŸš€ å¼€å§‹è¯·æ±‚ (å°è¯• {attempt})")
        
        async with session.post(url, json=payload, timeout=aiohttp.ClientTimeout(total=150)) as response:
            elapsed = time.time() - start_time
            
            if response.status == 200:
                result = await response.json()
                if result.get("success"):
                    print(f"[{agent['id']}] âœ… æˆåŠŸ ({elapsed:.1f}ç§’)")
                    return {
                        "agent_id": agent["id"],
                        "success": True,
                        "elapsed": elapsed,
                        "result_length": len(result.get("result", ""))
                    }
                else:
                    print(f"[{agent['id']}] âŒ å¤±è´¥: {result.get('error')}")
                    return {
                        "agent_id": agent["id"],
                        "success": False,
                        "elapsed": elapsed,
                        "error": result.get("error")
                    }
            else:
                print(f"[{agent['id']}] âŒ HTTP {response.status}")
                return {
                    "agent_id": agent["id"],
                    "success": False,
                    "elapsed": elapsed,
                    "error": f"HTTP {response.status}"
                }
                
    except asyncio.TimeoutError:
        elapsed = time.time() - start_time
        print(f"[{agent['id']}] â±ï¸ è¶…æ—¶ ({elapsed:.1f}ç§’)")
        return {
            "agent_id": agent["id"],
            "success": False,
            "elapsed": elapsed,
            "error": "Timeout"
        }
    except Exception as e:
        elapsed = time.time() - start_time
        print(f"[{agent['id']}] âŒ é”™è¯¯: {str(e)}")
        return {
            "agent_id": agent["id"],
            "success": False,
            "elapsed": elapsed,
            "error": str(e)
        }

async def test_batch(batch_size):
    """æµ‹è¯•æŒ‡å®šæ‰¹æ¬¡å¤§å°çš„å¹¶å‘"""
    print(f"\n{'='*70}")
    print(f"æµ‹è¯•æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"{'='*70}\n")
    
    async with aiohttp.ClientSession() as session:
        results = []
        
        # åˆ†æ‰¹å‘é€
        for i in range(0, len(RISK_AGENTS), batch_size):
            batch = RISK_AGENTS[i:i+batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(RISK_AGENTS) + batch_size - 1) // batch_size
            
            print(f"\n--- æ‰¹æ¬¡ {batch_num}/{total_batches} ---")
            
            # å¹¶å‘å‘é€è¿™ä¸€æ‰¹
            tasks = [send_request(session, agent) for agent in batch]
            batch_results = await asyncio.gather(*tasks)
            results.extend(batch_results)
            
            # æ‰¹æ¬¡é—´ç­‰å¾…
            if i + batch_size < len(RISK_AGENTS):
                print(f"\nâ¸ï¸  ç­‰å¾…3ç§’åç»§ç»­ä¸‹ä¸€æ‰¹...\n")
                await asyncio.sleep(3)
        
        return results

def analyze_results(results, batch_size):
    """åˆ†ææµ‹è¯•ç»“æœ"""
    print(f"\n{'='*70}")
    print(f"ç»“æœåˆ†æ (æ‰¹æ¬¡å¤§å°: {batch_size})")
    print(f"{'='*70}\n")
    
    success_count = sum(1 for r in results if r["success"])
    total_count = len(results)
    success_rate = success_count / total_count * 100
    
    successful = [r for r in results if r["success"]]
    failed = [r for r in results if not r["success"]]
    
    print(f"æ€»è¯·æ±‚æ•°: {total_count}")
    print(f"æˆåŠŸ: {success_count} ({success_rate:.1f}%)")
    print(f"å¤±è´¥: {len(failed)} ({100-success_rate:.1f}%)")
    print()
    
    if successful:
        avg_time = sum(r["elapsed"] for r in successful) / len(successful)
        min_time = min(r["elapsed"] for r in successful)
        max_time = max(r["elapsed"] for r in successful)
        print(f"æˆåŠŸè¯·æ±‚è€—æ—¶:")
        print(f"  å¹³å‡: {avg_time:.1f}ç§’")
        print(f"  æœ€å¿«: {min_time:.1f}ç§’")
        print(f"  æœ€æ…¢: {max_time:.1f}ç§’")
        print()
    
    if failed:
        print(f"å¤±è´¥è¯·æ±‚:")
        for r in failed:
            print(f"  [{r['agent_id']}] {r['error']} ({r['elapsed']:.1f}ç§’)")
        print()
    
    return {
        "batch_size": batch_size,
        "total": total_count,
        "success": success_count,
        "failed": len(failed),
        "success_rate": success_rate,
        "avg_time": avg_time if successful else 0
    }

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*70)
    print("ç¬¬ä¸‰é˜¶æ®µçœŸå®å¹¶å‘æµ‹è¯•")
    print("="*70)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"åç«¯åœ°å€: http://localhost:8000")
    print(f"è‚¡ç¥¨ä»£ç : {STOCK_DATA['symbol']}")
    print(f"å‰åºè¾“å‡ºæ•°é‡: {len(PREVIOUS_OUTPUTS)}")
    print(f"é£æ§æ™ºèƒ½ä½“æ•°é‡: {len(RISK_AGENTS)}")
    print()
    
    # æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°
    test_cases = [
        ("æ‰¹æ¬¡2ï¼ˆå½“å‰è®¾ç½®ï¼‰", 2),
        ("æ‰¹æ¬¡3", 3),
        ("æ‰¹æ¬¡6ï¼ˆå…¨å¹¶å‘ï¼‰", 6),
    ]
    
    all_results = []
    
    for name, batch_size in test_cases:
        print(f"\n{'#'*70}")
        print(f"# {name}")
        print(f"{'#'*70}")
        
        results = await test_batch(batch_size)
        summary = analyze_results(results, batch_size)
        all_results.append(summary)
        
        # æµ‹è¯•é—´ç­‰å¾…
        print(f"\nâ¸ï¸  ç­‰å¾…10ç§’åç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...\n")
        await asyncio.sleep(10)
    
    # æ€»ç»“
    print(f"\n{'='*70}")
    print("æ€»ç»“")
    print(f"{'='*70}\n")
    
    print(f"{'æ‰¹æ¬¡å¤§å°':<15} {'æˆåŠŸç‡':<15} {'å¹³å‡è€—æ—¶':<15}")
    print("-" * 45)
    for r in all_results:
        print(f"{r['batch_size']:<15} {r['success_rate']:.1f}%{'':<10} {r['avg_time']:.1f}ç§’")
    
    print()
    print("ğŸ¯ å…³é”®å‘ç°:")
    
    # æ‰¾å‡ºæˆåŠŸç‡æœ€é«˜çš„
    best = max(all_results, key=lambda x: x['success_rate'])
    print(f"  æœ€ä½³æ‰¹æ¬¡å¤§å°: {best['batch_size']} (æˆåŠŸç‡ {best['success_rate']:.1f}%)")
    
    # æ‰¾å‡ºé—®é¢˜
    worst = min(all_results, key=lambda x: x['success_rate'])
    if worst['success_rate'] < 100:
        print(f"  é—®é¢˜æ‰¹æ¬¡: {worst['batch_size']} (æˆåŠŸç‡ {worst['success_rate']:.1f}%)")
        print(f"  å¤±è´¥æ•°é‡: {worst['failed']}")

if __name__ == "__main__":
    asyncio.run(main())
