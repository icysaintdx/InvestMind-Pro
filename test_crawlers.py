#!/usr/bin/env python3
"""
æµ‹è¯•çˆ¬è™«åŠŸèƒ½
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from backend.dataflows.news.china_market_crawler import ChinaMarketCrawler
from backend.utils.logging_config import get_logger

logger = get_logger("test_crawlers")

print("=" * 80)
print("ğŸ§ª æµ‹è¯•ä¸­å›½å¸‚åœºçˆ¬è™«")
print("=" * 80)
print()

# æµ‹è¯•è‚¡ç¥¨ä»£ç 
test_stock = "600519"

# åˆ›å»ºçˆ¬è™«å®ä¾‹
crawler = ChinaMarketCrawler()

# æµ‹è¯•1: ä¸œæ–¹è´¢å¯Œæ–°é—»
print("ğŸ“° æµ‹è¯•1: ä¸œæ–¹è´¢å¯Œæ–°é—»")
print("-" * 80)
try:
    news_list = crawler.get_eastmoney_news(test_stock, limit=5)
    if news_list:
        print(f"âœ… æˆåŠŸè·å– {len(news_list)} æ¡æ–°é—»")
        for i, news in enumerate(news_list[:3], 1):
            print(f"\n{i}. {news.get('title', 'N/A')}")
            print(f"   æ—¶é—´: {news.get('publish_time', 'N/A')}")
            print(f"   æ¥æº: {news.get('source', 'N/A')}")
    else:
        print("âš ï¸ æœªè·å–åˆ°æ–°é—»")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n")

# æµ‹è¯•2: æ–°æµªè´¢ç»æ–°é—»
print("ğŸ“° æµ‹è¯•2: æ–°æµªè´¢ç»æ–°é—»")
print("-" * 80)
try:
    news_list = crawler.get_sina_news(test_stock, limit=5)
    if news_list:
        print(f"âœ… æˆåŠŸè·å– {len(news_list)} æ¡æ–°é—»")
        for i, news in enumerate(news_list[:3], 1):
            print(f"\n{i}. {news.get('title', 'N/A')}")
            print(f"   æ—¶é—´: {news.get('publish_time', 'N/A')}")
    else:
        print("âš ï¸ æœªè·å–åˆ°æ–°é—»")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n")

# æµ‹è¯•3: é›ªçƒè¯„è®º
print("ğŸ’¬ æµ‹è¯•3: é›ªçƒè¯„è®º")
print("-" * 80)
try:
    comments = crawler.get_xueqiu_comments(test_stock, limit=5)
    if comments:
        print(f"âœ… æˆåŠŸè·å– {len(comments)} æ¡è¯„è®º")
        for i, comment in enumerate(comments[:3], 1):
            print(f"\n{i}. {comment.get('text', 'N/A')[:100]}")
            print(f"   ä½œè€…: {comment.get('user_name', 'N/A')}")
            print(f"   ç‚¹èµ: {comment.get('like_count', 0)}")
    else:
        print("âš ï¸ æœªè·å–åˆ°è¯„è®º")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n")

# æµ‹è¯•4: è´¢è”ç¤¾å¿«è®¯
print("âš¡ æµ‹è¯•4: è´¢è”ç¤¾å¿«è®¯")
print("-" * 80)
try:
    news_list = crawler.get_cls_news(limit=5)
    if news_list:
        print(f"âœ… æˆåŠŸè·å– {len(news_list)} æ¡å¿«è®¯")
        for i, news in enumerate(news_list[:3], 1):
            print(f"\n{i}. {news.get('title', 'N/A')}")
            print(f"   æ—¶é—´: {news.get('publish_time', 'N/A')}")
    else:
        print("âš ï¸ æœªè·å–åˆ°å¿«è®¯")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n")

# æµ‹è¯•5: AKShareæ–°é—»
print("ğŸ“Š æµ‹è¯•5: AKShareæ–°é—»")
print("-" * 80)
try:
    # AKShare ä¸æ”¯æŒ limit å‚æ•°
    news_list = crawler.get_akshare_news(test_stock)
    if news_list:
        print(f"âœ… æˆåŠŸè·å– {len(news_list)} æ¡æ–°é—»")
        for i, news in enumerate(news_list[:3], 1):
            print(f"\n{i}. {news.get('title', 'N/A')}")
            print(f"   æ—¶é—´: {news.get('publish_time', 'N/A')}")
    else:
        print("âš ï¸ æœªè·å–åˆ°æ–°é—»")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n")

# æµ‹è¯•6: Tushareæ–°é—»ï¼ˆå¦‚æœé…ç½®äº†tokenï¼‰
print("ğŸ“ˆ æµ‹è¯•6: Tushareæ–°é—»")
print("-" * 80)
try:
    if crawler.pro:
        # Tushare ä¸æ”¯æŒ limit å‚æ•°ï¼Œä½¿ç”¨æ—¥æœŸèŒƒå›´
        from datetime import datetime, timedelta
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        news_list = crawler.get_tushare_news(test_stock, start_date, end_date)
        if news_list:
            print(f"âœ… æˆåŠŸè·å– {len(news_list)} æ¡æ–°é—»")
            for i, news in enumerate(news_list[:3], 1):
                print(f"\n{i}. {news.get('title', 'N/A')}")
                print(f"   æ—¶é—´: {news.get('publish_time', 'N/A')}")
        else:
            print("âš ï¸ æœªè·å–åˆ°æ–°é—»")
    else:
        print("âš ï¸ æœªé…ç½®TUSHARE_TOKENï¼Œè·³è¿‡æµ‹è¯•")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n")
print("=" * 80)
print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
print("=" * 80)
print()
print("âœ… = æµ‹è¯•é€šè¿‡")
print("âš ï¸ = æµ‹è¯•é€šè¿‡ä½†æ— æ•°æ®")
print("âŒ = æµ‹è¯•å¤±è´¥")
print()
print("ä¸‹ä¸€æ­¥:")
print("1. ä¿®å¤å¤±è´¥çš„çˆ¬è™«")
print("2. ä¼˜åŒ–æ•°æ®è§£æ")
print("3. é›†æˆåˆ°ç»Ÿä¸€æ¥å£")
print()
