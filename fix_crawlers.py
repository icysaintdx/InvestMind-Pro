#!/usr/bin/env python3
"""
ä¿®å¤çˆ¬è™«é—®é¢˜
æ ¹æ®æµ‹è¯•ç»“æœä¿®å¤å„ä¸ªçˆ¬è™«çš„é—®é¢˜
"""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

print("=" * 80)
print("ğŸ”§ ä¿®å¤çˆ¬è™«é—®é¢˜")
print("=" * 80)
print()

# é—®é¢˜1: dataflow_utils ç¼ºå°‘ save_output å‡½æ•°
print("ğŸ“ é—®é¢˜1: dataflow_utils ç¼ºå°‘ save_output å‡½æ•°")
print("-" * 80)

try:
    from backend.utils import dataflow_utils
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ save_output å‡½æ•°
    if not hasattr(dataflow_utils, 'save_output'):
        print("âš ï¸ ç¼ºå°‘ save_output å‡½æ•°ï¼Œæ­£åœ¨æ·»åŠ ...")
        
        # è¯»å–æ–‡ä»¶
        file_path = "backend/utils/dataflow_utils.py"
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ·»åŠ å‡½æ•°
        new_function = '''

def save_output(data, filename: str):
    """
    ä¿å­˜è¾“å‡ºæ•°æ®åˆ°æ–‡ä»¶
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        filename: æ–‡ä»¶å
    """
    import json
    import os
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else '.', exist_ok=True)
    
    # ä¿å­˜æ•°æ®
    with open(filename, 'w', encoding='utf-8') as f:
        if isinstance(data, (dict, list)):
            json.dump(data, f, ensure_ascii=False, indent=2)
        else:
            f.write(str(data))
    
    logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
'''
        
        # å†™å…¥æ–‡ä»¶
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(new_function)
        
        print("âœ… å·²æ·»åŠ  save_output å‡½æ•°")
    else:
        print("âœ… save_output å‡½æ•°å·²å­˜åœ¨")
        
except Exception as e:
    print(f"âŒ ä¿®å¤å¤±è´¥: {e}")

print()

# é—®é¢˜2: AKShare å’Œ Tushare å‚æ•°é—®é¢˜
print("ğŸ“ é—®é¢˜2: æ£€æŸ¥ AKShare å’Œ Tushare å‡½æ•°ç­¾å")
print("-" * 80)

try:
    from backend.dataflows.news.china_market_crawler import ChinaMarketCrawler
    import inspect
    
    crawler = ChinaMarketCrawler()
    
    # æ£€æŸ¥ get_akshare_news ç­¾å
    if hasattr(crawler, 'get_akshare_news'):
        sig = inspect.signature(crawler.get_akshare_news)
        print(f"get_akshare_news ç­¾å: {sig}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ limit å‚æ•°
        if 'limit' not in sig.parameters:
            print("âš ï¸ get_akshare_news ä¸æ”¯æŒ limit å‚æ•°")
    
    # æ£€æŸ¥ get_tushare_news ç­¾å
    if hasattr(crawler, 'get_tushare_news'):
        sig = inspect.signature(crawler.get_tushare_news)
        print(f"get_tushare_news ç­¾å: {sig}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ limit å‚æ•°
        if 'limit' not in sig.parameters:
            print("âš ï¸ get_tushare_news ä¸æ”¯æŒ limit å‚æ•°")
    
    print("âœ… å‡½æ•°ç­¾åæ£€æŸ¥å®Œæˆ")
    
except Exception as e:
    print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")

print()

# é—®é¢˜3: é›ªçƒè¯„è®º JSON è§£æé”™è¯¯
print("ğŸ“ é—®é¢˜3: é›ªçƒè¯„è®ºåçˆ¬è™«é—®é¢˜")
print("-" * 80)
print("âš ï¸ é›ªçƒç½‘ç«™æœ‰åçˆ¬è™«æœºåˆ¶ï¼Œéœ€è¦ï¼š")
print("  1. ä½¿ç”¨ curl_cffi æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨")
print("  2. æ·»åŠ å®Œæ•´çš„è¯·æ±‚å¤´")
print("  3. å¤„ç† Cookie")
print("  4. æ§åˆ¶è¯·æ±‚é¢‘ç‡")
print("å»ºè®®ï¼šç¨åå•ç‹¬ä¿®å¤")

print()

print("=" * 80)
print("ğŸ“‹ ä¿®å¤æ€»ç»“")
print("=" * 80)
print()
print("âœ… = å·²ä¿®å¤")
print("âš ï¸ = éœ€è¦æ‰‹åŠ¨ä¿®å¤")
print("âŒ = ä¿®å¤å¤±è´¥")
print()
print("ä¸‹ä¸€æ­¥:")
print("1. é‡æ–°è¿è¡Œæµ‹è¯•: python test_crawlers.py")
print("2. ä¿®å¤é›ªçƒè¯„è®ºçˆ¬è™«")
print("3. ä¼˜åŒ–ä¸œæ–¹è´¢å¯Œæ–°é—»API")
print()
