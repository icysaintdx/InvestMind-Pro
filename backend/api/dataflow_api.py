"""
æ•°æ®æµç›‘æ§API
æä¾›è‚¡ç¥¨æ•°æ®æµç›‘æ§ã€æ–°é—»èˆ†æƒ…åˆ†æã€é£é™©é¢„è­¦ç­‰åŠŸèƒ½
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import asyncio
import os

from backend.utils.logging_config import get_logger
from backend.utils.tool_logging import log_api_call
import math


def sanitize_float_values(obj):
    """
    é€’å½’æ¸…ç†æ•°æ®ä¸­çš„éæ³•floatå€¼ï¼ˆinf, -inf, nanï¼‰
    å°†å®ƒä»¬è½¬æ¢ä¸ºNoneï¼Œä»¥ä¾¿JSONåºåˆ—åŒ–
    """
    if isinstance(obj, dict):
        return {k: sanitize_float_values(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_float_values(item) for item in obj]
    elif isinstance(obj, float):
        if math.isnan(obj) or math.isinf(obj):
            return None
        return obj
    else:
        return obj

# å¯¼å…¥é£é™©ç›‘æ§æ¨¡å—
from backend.dataflows.risk import (
    check_suspend_status,
    is_st_stock,
    get_stock_realtime_quote,
    analyze_stock_risk
)

# å¯¼å…¥æ–°é—»å’Œæƒ…ç»ªåˆ†ææ¨¡å—
from backend.dataflows.news.multi_source_news_aggregator import get_news_aggregator
from backend.dataflows.news.sentiment_engine import get_sentiment_engine

# å¯¼å…¥ç»¼åˆæ•°æ®æœåŠ¡
from backend.dataflows.comprehensive_stock_data import get_comprehensive_service

logger = get_logger("api.dataflow")
router = APIRouter(prefix="/api/dataflow", tags=["Data Flow"])


# ==================== æ•°æ®æ¨¡å‹ ====================

class MonitorStockRequest(BaseModel):
    """æ·»åŠ ç›‘æ§è‚¡ç¥¨è¯·æ±‚"""
    code: str = Field(..., description="è‚¡ç¥¨ä»£ç ï¼Œå¦‚600519.SH")
    frequency: str = Field("1h", description="æ›´æ–°é¢‘ç‡ï¼š5m/15m/30m/1h/1d")
    items: Dict[str, bool] = Field(
        default_factory=lambda: {
            "news": True,
            "risk": True,
            "sentiment": True,
            "suspend": False
        },
        description="ç›‘æ§é¡¹ç›®"
    )


class RemoveMonitorRequest(BaseModel):
    """ç§»é™¤ç›‘æ§è¯·æ±‚"""
    code: str = Field(..., description="è‚¡ç¥¨ä»£ç ")


class UpdateMonitorRequest(BaseModel):
    """ç«‹å³æ›´æ–°è¯·æ±‚"""
    code: str = Field(..., description="è‚¡ç¥¨ä»£ç ")


# ==================== å…¨å±€çŠ¶æ€ ====================

# å¯¼å…¥æŒä¹…åŒ–å­˜å‚¨
from backend.dataflows.persistence.monitor_storage import get_monitor_storage

# ç›‘æ§çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨ï¼‰
def _load_monitored_stocks():
    """ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½ç›‘æ§è‚¡ç¥¨"""
    try:
        storage = get_monitor_storage()
        return storage.get_monitored_stocks()
    except Exception as e:
        logger.error(f"åŠ è½½ç›‘æ§è‚¡ç¥¨å¤±è´¥: {e}")
        return {}

def _save_monitored_stocks():
    """ä¿å­˜ç›‘æ§è‚¡ç¥¨åˆ°æŒä¹…åŒ–å­˜å‚¨"""
    try:
        storage = get_monitor_storage()
        storage.save_monitor_config({'stocks': monitored_stocks})
    except Exception as e:
        logger.error(f"ä¿å­˜ç›‘æ§è‚¡ç¥¨å¤±è´¥: {e}")

# åˆå§‹åŒ–æ—¶ä»æ–‡ä»¶åŠ è½½
monitored_stocks = _load_monitored_stocks()

# æ•°æ®ç¼“å­˜ - é¿å…é‡å¤è¯·æ±‚
data_cache = {}
data_sources_status = {
    "tushare": {
        "id": "tushare",
        "name": "Tushare",
        "type": "è‚¡ç¥¨æ•°æ®/æ–°é—»",
        "status": "offline",
        "todayCalls": 0,
        "lastUpdate": None,
        "error": None
    },
    "akshare": {
        "id": "akshare",
        "name": "AKShare",
        "type": "è‚¡ç¥¨æ•°æ®/èµ„è®¯",
        "status": "offline",
        "todayCalls": 0,
        "lastUpdate": None,
        "error": None
    },
    "eastmoney": {
        "id": "eastmoney",
        "name": "ä¸œæ–¹è´¢å¯Œ",
        "type": "æ–°é—»/èµ„è®¯",
        "status": "offline",
        "todayCalls": 0,
        "lastUpdate": None,
        "error": None
    },
    "juhe": {
        "id": "juhe",
        "name": "èšåˆæ•°æ®",
        "type": "æ–°é—»/èˆ†æƒ…",
        "status": "offline",
        "todayCalls": 0,
        "lastUpdate": None,
        "error": None
    }
}

# æ–°é—»åˆ—è¡¨
news_list = []


# ==================== APIæ¥å£ ====================

@router.get("/daily-stats")
@log_api_call("è·å–æ¯æ—¥ç»Ÿè®¡æ•°æ®")
async def get_daily_stats():
    """
    è·å–æ¯æ—¥ç»Ÿè®¡æ•°æ®
    åŒ…æ‹¬ï¼šç›‘æ§è‚¡ç¥¨æ•°ã€ä»Šæ—¥æ–°é—»æ•°ã€é£é™©é¢„è­¦æ•°ã€åˆ†æä»»åŠ¡æ•°
    """
    try:
        # ç»Ÿè®¡ç›‘æ§è‚¡ç¥¨æ•°
        monitored_count = len(monitored_stocks)

        # ç»Ÿè®¡ä»Šæ—¥æ–°é—»æ•°
        today = datetime.now().date()
        today_news_count = 0
        for news in news_list:
            try:
                news_time = news.get('publishTime') or news.get('pub_time', '')
                if news_time:
                    news_date = datetime.fromisoformat(news_time.replace('Z', '+00:00')).date()
                    if news_date == today:
                        today_news_count += 1
            except:
                pass

        # ç»Ÿè®¡é£é™©é¢„è­¦æ•°ï¼ˆé«˜é£é™©è‚¡ç¥¨æ•°ï¼‰
        risk_alert_count = sum(
            1 for stock in monitored_stocks.values()
            if stock.get('riskLevel') in ['high', 'medium']
        )

        # ç»Ÿè®¡åˆ†æä»»åŠ¡æ•°ï¼ˆå¾…å¤„ç†ä»»åŠ¡ï¼‰
        analysis_task_count = sum(
            stock.get('pendingTasks', 0)
            for stock in monitored_stocks.values()
        )

        # APIè°ƒç”¨ç»Ÿè®¡
        api_calls = {}
        for source_id, source_data in data_sources_status.items():
            api_calls[source_id] = source_data.get('todayCalls', 0)

        return {
            "success": True,
            "stats": {
                "monitoredStocks": monitored_count,
                "todayNews": today_news_count or len(news_list),  # å¦‚æœä»Šæ—¥æ–°é—»ä¸º0ï¼Œè¿”å›æ€»æ–°é—»æ•°
                "riskAlerts": risk_alert_count,
                "analysisTasks": analysis_task_count,
                "apiCalls": api_calls
            }
        }

    except Exception as e:
        logger.error(f"è·å–æ¯æ—¥ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/stock/comprehensive/{ts_code}/from-db")
@log_api_call("ä»æ•°æ®åº“è·å–è‚¡ç¥¨ç»¼åˆæ•°æ®")
async def get_stock_comprehensive_from_db(ts_code: str):
    """
    ä»æ•°æ®åº“/ç¼“å­˜è·å–è‚¡ç¥¨çš„ç»¼åˆæ•°æ®ï¼ˆä¸è§¦å‘æ–°çš„APIè¯·æ±‚ï¼‰
    ä¼˜å…ˆä»ç¼“å­˜è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›ç©ºæ•°æ®

    Args:
        ts_code: è‚¡ç¥¨ä»£ç 
    """
    try:
        logger.info(f"ğŸ“Š ä»æ•°æ®åº“è·å– {ts_code} çš„ç»¼åˆæ•°æ®...")

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"comprehensive_{ts_code}"

        if cache_key in data_cache:
            cached_data = data_cache[cache_key]
            logger.info(f"âœ… ä»ç¼“å­˜è·å–æ•°æ®æˆåŠŸ")
            # æ¸…ç†éæ³•floatå€¼ï¼ˆinf, -inf, nanï¼‰
            sanitized_data = sanitize_float_values(cached_data.get('data', {}))
            return {
                "success": True,
                "has_data": True,
                "data": sanitized_data,
                "loaded_at": cached_data.get('cached_at'),
                "from_database": True
            }

        # æ£€æŸ¥ç›‘æ§è‚¡ç¥¨ä¸­æ˜¯å¦æœ‰æ•°æ®
        if ts_code in monitored_stocks:
            stock_data = monitored_stocks[ts_code]
            # æ„å»ºç»¼åˆæ•°æ®
            comprehensive = {
                "ts_code": ts_code,
                "name": stock_data.get("name", ts_code.split('.')[0]),
                "sentimentScore": stock_data.get("sentimentScore", 50),
                "riskLevel": stock_data.get("riskLevel", "low"),
                "riskScore": stock_data.get("riskScore", 0),
                "news": [],
                "risk": {
                    "risk_level": stock_data.get("riskLevel", "low"),
                    "risk_score": stock_data.get("riskScore", 0),
                    "risk_factors": stock_data.get("riskFactors", {}),
                    "warnings": stock_data.get("warnings", [])
                },
                "overall_score": stock_data.get("sentimentScore", 50),
                "sentiment_summary": stock_data.get("sentimentDetail", {})
            }

            logger.info(f"âœ… ä»ç›‘æ§æ•°æ®è·å–æˆåŠŸ")
            return {
                "success": True,
                "has_data": True,
                "data": comprehensive,
                "loaded_at": stock_data.get("lastUpdate"),
                "from_database": False
            }

        # æ²¡æœ‰æ•°æ®
        logger.info(f"â„¹ï¸ æ²¡æœ‰æ‰¾åˆ° {ts_code} çš„ç¼“å­˜æ•°æ®")
        return {
            "success": True,
            "has_data": False,
            "data": None,
            "message": "æš‚æ— æ•°æ®ï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–"
        }

    except Exception as e:
        logger.error(f"ä»æ•°æ®åº“è·å–ç»¼åˆæ•°æ®å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/stock/cached/{ts_code}")
@log_api_call("è·å–è‚¡ç¥¨ç¼“å­˜æ•°æ®")
async def get_stock_cached(ts_code: str):
    """
    è·å–è‚¡ç¥¨çš„ç¼“å­˜æ•°æ®ï¼ˆç”¨äºå‰ç«¯å¿«é€ŸåŠ è½½ï¼‰

    Args:
        ts_code: è‚¡ç¥¨ä»£ç 
    """
    try:
        cache_key = f"comprehensive_{ts_code}"

        if cache_key in data_cache:
            cached_data = data_cache[cache_key]
            return {
                "success": True,
                "has_data": True,
                "comprehensive": cached_data.get('data', {}),
                "news": cached_data.get('data', {}).get('news', []),
                "cached_at": cached_data.get('cached_at')
            }

        return {
            "success": True,
            "has_data": False,
            "message": "æ— ç¼“å­˜æ•°æ®"
        }

    except Exception as e:
        logger.error(f"è·å–ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/monitored-stocks")
@log_api_call("è·å–ç›‘æ§è‚¡ç¥¨åˆ—è¡¨")
async def get_monitored_stocks():
    """
    è·å–å½“å‰ç›‘æ§çš„è‚¡ç¥¨åˆ—è¡¨
    """
    try:
        stocks = []
        for code, data in monitored_stocks.items():
            stocks.append({
                "code": code,
                "name": data.get("name", "æœªçŸ¥"),
                "sentimentScore": data.get("sentimentScore", 50),
                "riskLevel": data.get("riskLevel", "low"),
                "latestNews": data.get("latestNews", ""),
                "updateFrequency": data.get("frequency", "1h"),
                "lastUpdate": data.get("lastUpdate"),
                "pendingTasks": data.get("pendingTasks", 0)
            })
        
        return {
            "success": True,
            "stocks": stocks
        }
        
    except Exception as e:
        logger.error(f"è·å–ç›‘æ§è‚¡ç¥¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sources/status")
@log_api_call("è·å–æ•°æ®æºçŠ¶æ€")
async def get_data_sources_status():
    """
    è·å–æ‰€æœ‰æ•°æ®æºçš„çŠ¶æ€ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
    """
    try:
        # è‡ªåŠ¨æ£€æµ‹æ•°æ®æºçŠ¶æ€
        await _check_all_data_sources()

        sources = list(data_sources_status.values())
        return {
            "success": True,
            "sources": sources
        }

    except Exception as e:
        logger.error(f"è·å–æ•°æ®æºçŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


async def _check_all_data_sources():
    """æ£€æµ‹æ‰€æœ‰æ•°æ®æºçŠ¶æ€"""
    try:
        # æ£€æµ‹AKShare
        try:
            import akshare as ak
            # å°è¯•è·å–ä¸€ä¸ªç®€å•çš„æ•°æ®
            df = ak.stock_zh_a_spot_em()
            if df is not None and not df.empty:
                data_sources_status["akshare"]["status"] = "online"
                data_sources_status["akshare"]["lastUpdate"] = datetime.now().isoformat()
                data_sources_status["akshare"]["error"] = None
            else:
                data_sources_status["akshare"]["status"] = "error"
                data_sources_status["akshare"]["error"] = "æ— æ³•è·å–æ•°æ®"
        except Exception as e:
            data_sources_status["akshare"]["status"] = "error"
            data_sources_status["akshare"]["error"] = str(e)

        # æ£€æµ‹Tushare
        try:
            import tushare as ts
            # æ£€æŸ¥æ˜¯å¦æœ‰token
            token = os.getenv('TUSHARE_TOKEN')
            if token:
                ts.set_token(token)
                df = ts.daily(ts_code='000001.SZ', start_date='20240101', end_date='20240102')
                if df is not None and not df.empty:
                    data_sources_status["tushare"]["status"] = "online"
                    data_sources_status["tushare"]["lastUpdate"] = datetime.now().isoformat()
                    data_sources_status["tushare"]["error"] = None
                else:
                    data_sources_status["tushare"]["status"] = "error"
                    data_sources_status["tushare"]["error"] = "æ— æ³•è·å–æ•°æ®"
            else:
                data_sources_status["tushare"]["status"] = "offline"
                data_sources_status["tushare"]["error"] = "æœªé…ç½®TUSHARE_TOKEN"
        except Exception as e:
            data_sources_status["tushare"]["status"] = "error"
            data_sources_status["tushare"]["error"] = str(e)

        # æ£€æµ‹å…¶ä»–æ•°æ®æº
        for source in ["eastmoney", "juhe"]:
            if data_sources_status[source]["status"] == "offline":
                try:
                    # ç®€å•çš„ç½‘ç»œæµ‹è¯•
                    import requests
                    if source == "eastmoney":
                        response = requests.get("https://push2.eastmoney.com/api/qt/stock/get", timeout=5)
                    else:  # juhe
                        response = requests.get("https://apis.juhe.cn/1.0/api/v1/stock/news", timeout=5)

                    if response.status_code == 200:
                        data_sources_status[source]["status"] = "online"
                        data_sources_status[source]["lastUpdate"] = datetime.now().isoformat()
                        data_sources_status[source]["error"] = None
                except Exception as e:
                    data_sources_status[source]["status"] = "error"
                    data_sources_status[source]["error"] = str(e)

    except Exception as e:
        logger.error(f"æ£€æµ‹æ•°æ®æºå¤±è´¥: {e}")


@router.post("/sources/check")
@log_api_call("æ£€æµ‹æ•°æ®æºè¿æ¥")
async def check_data_sources():
    """
    æ£€æµ‹æ‰€æœ‰æ•°æ®æºçš„è¿æ¥çŠ¶æ€
    """
    try:
        # TODO: å®ç°çœŸå®çš„æ•°æ®æºè¿æ¥æ£€æµ‹
        # è¿™é‡Œå…ˆç”¨æ¨¡æ‹Ÿæ•°æ®
        
        # Tushareæ£€æµ‹
        try:
            import tushare as ts
            data_sources_status["tushare"]["status"] = "online"
            data_sources_status["tushare"]["lastUpdate"] = datetime.now().isoformat()
            data_sources_status["tushare"]["error"] = None
        except Exception as e:
            data_sources_status["tushare"]["status"] = "error"
            data_sources_status["tushare"]["error"] = str(e)
        
        # AKShareæ£€æµ‹
        try:
            import akshare as ak
            data_sources_status["akshare"]["status"] = "online"
            data_sources_status["akshare"]["lastUpdate"] = datetime.now().isoformat()
            data_sources_status["akshare"]["error"] = None
        except Exception as e:
            data_sources_status["akshare"]["status"] = "error"
            data_sources_status["akshare"]["error"] = str(e)
        
        # å…¶ä»–æ•°æ®æºè®¾ç½®ä¸ºåœ¨çº¿ï¼ˆç®€åŒ–ï¼‰
        for source_id in ["eastmoney", "juhe"]:
            data_sources_status[source_id]["status"] = "online"
            data_sources_status[source_id]["lastUpdate"] = datetime.now().isoformat()
        
        return {
            "success": True,
            "message": "æ•°æ®æºæ£€æµ‹å®Œæˆ"
        }
        
    except Exception as e:
        logger.error(f"æ£€æµ‹æ•°æ®æºå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/news")
@log_api_call("è·å–æ–°é—»åˆ—è¡¨")
async def get_news(source: Optional[str] = None, limit: int = 50):
    """
    è·å–æ–°é—»åˆ—è¡¨
    
    Args:
        source: æ•°æ®æºç­›é€‰ï¼ˆå¯é€‰ï¼‰
        limit: è¿”å›æ•°é‡é™åˆ¶
    """
    try:
        filtered_news = news_list
        
        if source and source != "all":
            filtered_news = [n for n in news_list if n.get("source") == source]
        
        filtered_news = filtered_news[:limit]
        
        return {
            "success": True,
            "news": filtered_news,
            "total": len(filtered_news)
        }
        
    except Exception as e:
        logger.error(f"è·å–æ–°é—»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/stock/news/{ts_code}")
@log_api_call("è·å–è‚¡ç¥¨æ–°é—»")
async def get_stock_news(ts_code: str, limit: int = 20):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨çš„æ–°é—»
    """
    try:
        logger.info(f"è·å–{ts_code}çš„æ–°é—»...")
        aggregator = get_news_aggregator()
        
        # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å‚æ•°å limit_per_source
        result = aggregator.aggregate_news(
            ts_code=ts_code,
            limit_per_source=limit,  # ä¿®å¤å‚æ•°å
            include_tushare=False,  # Tushareéœ€è¦5000ç§¯åˆ†ï¼Œé»˜è®¤ä¸å¼€å¯
            include_akshare=True,
            include_market_news=False
        )
        
        # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å­—æ®µå merged_news
        news_list = result.get('merged_news', [])
        
        logger.info(f"âœ… è¿”å›{len(news_list)}æ¡æ–°é—»")
        
        return {
            "success": True,
            "news": news_list,
            "total": result.get('total_count', 0),
            "sources": result.get('sources', {})
        }
        
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨æ–°é—»å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/stock/sentiment/{ts_code}")
@log_api_call("è·å–è‚¡ç¥¨æƒ…ç»ªåˆ†æ")
async def get_stock_sentiment(ts_code: str, limit: int = 20):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨çš„æƒ…ç»ªåˆ†æ
    """
    try:
        logger.info(f"è·å–{ts_code}çš„æƒ…ç»ªåˆ†æ...")
        
        # å…ˆè·å–æ–°é—»
        aggregator = get_news_aggregator()
        news_result = aggregator.aggregate_news(
            ts_code=ts_code,
            limit_per_source=limit,  # ä¿®å¤å‚æ•°å
            include_tushare=False,
            include_akshare=True,
            include_market_news=False
        )
        
        news_list = news_result.get('merged_news', [])  # ä¿®å¤å­—æ®µå
        
        # æƒ…ç»ªåˆ†æ
        engine = get_sentiment_engine()
        sentiment_result = engine.analyze_news_list(news_list)
        
        return {
            "success": True,
            **sentiment_result
        }
        
    except Exception as e:
        logger.error(f"æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/stock/risk/{ts_code}")
@log_api_call("è·å–è‚¡ç¥¨é£é™©åˆ†æ")
async def get_stock_risk(ts_code: str):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨çš„é£é™©åˆ†æ
    """
    try:
        logger.info(f"è·å–{ts_code}çš„é£é™©åˆ†æ...")
        
        # è°ƒç”¨é£é™©åˆ†æå‡½æ•°
        risk_result = analyze_stock_risk(ts_code)
        
        return {
            "success": True,
            **risk_result
        }
        
    except Exception as e:
        logger.error(f"é£é™©åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/stock/comprehensive/{ts_code}")
@log_api_call("è·å–è‚¡ç¥¨ç»¼åˆæ•°æ®")
async def get_stock_comprehensive(ts_code: str, force_update: bool = False):
    """
    è·å–è‚¡ç¥¨çš„æ‰€æœ‰ç»¼åˆæ•°æ®
    åŒ…æ‹¬ï¼šå®æ—¶è¡Œæƒ…ã€åœå¤ç‰Œã€STçŠ¶æ€ã€è´¢åŠ¡æ•°æ®ã€å®¡è®¡æ„è§ã€
          ä¸šç»©é¢„å‘Šã€åˆ†çº¢é€è‚¡ã€é™å”®è§£ç¦ã€è‚¡æƒè´¨æŠ¼ã€
          è‚¡ä¸œå¢å‡æŒã€é¾™è™æ¦œã€æ–°é—»ç­‰

    Args:
        ts_code: è‚¡ç¥¨ä»£ç 
        force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
    """
    try:
        logger.info(f"ğŸ“Š å¼€å§‹è·å– {ts_code} çš„ç»¼åˆæ•°æ®...")

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"comprehensive_{ts_code}"
        current_time = datetime.now()

        # å¦‚æœç¼“å­˜å­˜åœ¨ä¸”ä¸è¶…è¿‡5åˆ†é’Ÿï¼Œç›´æ¥è¿”å›
        if not force_update and cache_key in data_cache:
            cached_data = data_cache[cache_key]
            cache_time = datetime.fromisoformat(cached_data.get('cached_at', '1970-01-01'))
            if (current_time - cache_time).total_seconds() < 300:  # 5åˆ†é’Ÿç¼“å­˜
                logger.info(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ•°æ® ({(current_time - cache_time).total_seconds():.1f}så‰)")
                # æ¸…ç†éæ³•floatå€¼ï¼ˆinf, -inf, nanï¼‰
                sanitized_data = sanitize_float_values(cached_data['data'])
                return {
                    "success": True,
                    "cached": True,
                    **sanitized_data
                }

        # è·å–æ–°æ•°æ®
        logger.info(f"ğŸ”„ è·å–æ–°æ•°æ®...")
        service = get_comprehensive_service()
        result = service.get_all_stock_data(ts_code)

        # æ¸…ç†éæ³•floatå€¼ï¼ˆinf, -inf, nanï¼‰
        result = sanitize_float_values(result)

        # ä¿å­˜åˆ°ç¼“å­˜
        data_cache[cache_key] = {
            'cached_at': current_time.isoformat(),
            'data': result
        }

        return {
            "success": True,
            "cached": False,
            **result
        }

    except Exception as e:
        logger.error(f"ç»¼åˆæ•°æ®è·å–å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


from fastapi.responses import StreamingResponse
import json

@router.get("/stock/comprehensive/{ts_code}/stream")
async def get_stock_comprehensive_stream(ts_code: str):
    """
    æµå¼è·å–è‚¡ç¥¨ç»¼åˆæ•°æ®ï¼ˆSSEï¼‰
    å‰ç«¯å¯ä»¥è¾¹è·å–è¾¹æ¸²æŸ“ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
    """
    async def generate():
        try:
            # å‘é€å¼€å§‹ä¿¡å·
            yield f"data: {json.dumps({'type': 'start', 'ts_code': ts_code})}\n\n"

            # è·å–ç»¼åˆæ•°æ®æœåŠ¡
            service = get_comprehensive_service()

            # å®šä¹‰æ•°æ®åˆ†ç±»
            categories = {
                'basic': {'name': 'åŸºç¡€ä¿¡æ¯', 'fields': ['realtime', 'st_status', 'suspend']},
                'financial': {'name': 'è´¢åŠ¡æ•°æ®', 'fields': ['financial', 'forecast', 'dividend', 'audit']},
                'risk': {'name': 'é£é™©æ•°æ®', 'fields': ['pledge', 'restricted', 'holder_trade']},
                'market': {'name': 'å¸‚åœºæ•°æ®', 'fields': ['dragon_tiger', 'block_trade', 'margin']},
                'news': {'name': 'æ–°é—»èˆ†æƒ…', 'fields': ['news_sina', 'announcements', 'news']},
                'company': {'name': 'å…¬å¸ä¿¡æ¯', 'fields': ['company_info', 'managers', 'main_business']},
            }

            # è·å–å®Œæ•´æ•°æ®
            logger.info(f"ğŸ“Š å¼€å§‹æµå¼è·å– {ts_code} çš„ç»¼åˆæ•°æ®...")
            result = service.get_all_stock_data(ts_code)

            # æ¸…ç†éæ³•floatå€¼ï¼ˆinf, -inf, nanï¼‰
            result = sanitize_float_values(result)

            # æŒ‰åˆ†ç±»å‘é€æ•°æ®
            success_count = 0
            total_count = 0

            for category_key, category_info in categories.items():
                category_data = {}
                category_success = 0
                category_total = 0

                for field in category_info['fields']:
                    if field in result:
                        category_data[field] = result[field]
                        category_total += 1
                        if isinstance(result[field], dict) and result[field].get('status') in ['success', 'has_suspend', 'normal']:
                            category_success += 1

                total_count += category_total
                success_count += category_success

                # å‘é€åˆ†ç±»æ•°æ®ï¼ˆæ•°æ®å·²ç»è¢«sanitizeè¿‡ï¼‰
                yield f"data: {json.dumps({'type': 'category', 'category': category_key, 'data': {'name': category_info['name'], 'data': category_data, 'success_count': category_success, 'total_count': category_total}}, ensure_ascii=False)}\n\n"

                # çŸ­æš‚å»¶è¿Ÿï¼Œè®©å‰ç«¯æœ‰æ—¶é—´å¤„ç†
                await asyncio.sleep(0.1)

            # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆå·²æ¸…ç†çš„æ•°æ®ï¼‰
            cache_key = f"comprehensive_{ts_code}"
            data_cache[cache_key] = {
                'cached_at': datetime.now().isoformat(),
                'data': result
            }

            # å‘é€å®Œæˆä¿¡å·
            yield f"data: {json.dumps({'type': 'complete', 'success_count': success_count, 'total_count': total_count, 'success_rate': f'{success_count/total_count*100:.1f}%' if total_count > 0 else '0%', 'total_time': 0}, ensure_ascii=False)}\n\n"

        except Exception as e:
            logger.error(f"æµå¼è·å–æ•°æ®å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )


@router.post("/monitor/add")
@log_api_call("æ·»åŠ ç›‘æ§è‚¡ç¥¨")
async def add_monitor(request: MonitorStockRequest, background_tasks: BackgroundTasks):
    """
    æ·»åŠ è‚¡ç¥¨ç›‘æ§
    """
    try:
        code = request.code

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if code in monitored_stocks:
            raise HTTPException(status_code=400, detail="è¯¥è‚¡ç¥¨å·²åœ¨ç›‘æ§åˆ—è¡¨ä¸­")

        # è·å–è‚¡ç¥¨åç§°ï¼ˆä½¿ç”¨æ•°æ®æºç®¡ç†å™¨è·å–çœŸå®åç§°ï¼‰
        stock_name = code.split('.')[0]  # é»˜è®¤ä½¿ç”¨ä»£ç 
        try:
            from backend.dataflows.data_source_manager import get_data_source_manager
            manager = get_data_source_manager()
            stock_info = manager.get_stock_info(code)
            if stock_info and stock_info.get('name'):
                stock_name = stock_info['name']
                logger.info(f"âœ… è·å–è‚¡ç¥¨åç§°æˆåŠŸ: {code} -> {stock_name}")
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–è‚¡ç¥¨åç§°å¤±è´¥ï¼Œä½¿ç”¨ä»£ç ä½œä¸ºåç§°: {e}")

        # æ·»åŠ åˆ°ç›‘æ§åˆ—è¡¨
        monitored_stocks[code] = {
            "name": stock_name,
            "code": code,
            "frequency": request.frequency,
            "items": request.items,
            "sentimentScore": 50,
            "riskLevel": "low",
            "latestNews": "",
            "lastUpdate": datetime.now().isoformat(),
            "pendingTasks": 0
        }

        # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
        _save_monitored_stocks()

        # æ·»åŠ åå°ä»»åŠ¡ï¼šç«‹å³æ‰§è¡Œä¸€æ¬¡æ•°æ®æ›´æ–°
        background_tasks.add_task(update_stock_data, code)

        logger.info(f"æ·»åŠ ç›‘æ§è‚¡ç¥¨: {code} ({stock_name})")

        return {
            "success": True,
            "message": f"å·²æ·»åŠ ç›‘æ§: {stock_name}({code})",
            "code": code,
            "name": stock_name
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ·»åŠ ç›‘æ§å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/monitor/remove")
@log_api_call("ç§»é™¤ç›‘æ§è‚¡ç¥¨")
async def remove_monitor(request: RemoveMonitorRequest):
    """
    ç§»é™¤è‚¡ç¥¨ç›‘æ§
    """
    try:
        code = request.code
        
        if code not in monitored_stocks:
            raise HTTPException(status_code=404, detail="è¯¥è‚¡ç¥¨ä¸åœ¨ç›‘æ§åˆ—è¡¨ä¸­")

        del monitored_stocks[code]

        # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
        _save_monitored_stocks()

        logger.info(f"ç§»é™¤ç›‘æ§è‚¡ç¥¨: {code}")
        
        return {
            "success": True,
            "message": f"å·²ç§»é™¤ç›‘æ§: {code}"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç§»é™¤ç›‘æ§å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/monitor/update")
@log_api_call("ç«‹å³æ›´æ–°è‚¡ç¥¨æ•°æ®")
async def update_monitor(request: UpdateMonitorRequest, background_tasks: BackgroundTasks):
    """
    ç«‹å³æ›´æ–°æŒ‡å®šè‚¡ç¥¨çš„æ•°æ®
    """
    try:
        code = request.code
        
        if code not in monitored_stocks:
            raise HTTPException(status_code=404, detail="è¯¥è‚¡ç¥¨ä¸åœ¨ç›‘æ§åˆ—è¡¨ä¸­")
        
        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(update_stock_data, code)
        
        return {
            "success": True,
            "message": f"æ›´æ–°ä»»åŠ¡å·²æäº¤: {code}"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/stock/realtime/{ts_code}")
@log_api_call("è·å–è‚¡ç¥¨å®æ—¶æ•°æ®")
async def get_stock_realtime(ts_code: str):
    """
    è·å–è‚¡ç¥¨å®æ—¶æ•°æ®
    """
    try:
        realtime_data = get_stock_realtime_quote(ts_code)

        if realtime_data:
            return {
                "success": True,
                "data": realtime_data
            }
        else:
            return {
                "success": False,
                "error": "æœªèƒ½è·å–å®æ—¶æ•°æ®"
            }

    except Exception as e:
        logger.error(f"è·å–å®æ—¶æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/stock/suspend/{ts_code}")
@log_api_call("æ£€æŸ¥è‚¡ç¥¨åœå¤ç‰ŒçŠ¶æ€")
async def get_stock_suspend(ts_code: str):
    """
    æ£€æŸ¥è‚¡ç¥¨åœå¤ç‰ŒçŠ¶æ€
    """
    try:
        suspend_status = check_suspend_status(ts_code)

        return {
            "success": True,
            "data": suspend_status
        }

    except Exception as e:
        logger.error(f"æ£€æŸ¥åœå¤ç‰Œå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ==================== åå°ä»»åŠ¡ ====================

async def update_stock_data(code: str):
    """
    æ›´æ–°è‚¡ç¥¨æ•°æ®ï¼ˆåå°ä»»åŠ¡ï¼‰
    
    åŒ…æ‹¬ï¼š
    1. è·å–æœ€æ–°æ–°é—»
    2. è¿›è¡Œæƒ…ç»ªåˆ†æ
    3. è¿›è¡Œé£é™©è¯„ä¼°
    4. æ›´æ–°ç›‘æ§çŠ¶æ€
    """
    try:
        logger.info(f"å¼€å§‹æ›´æ–°è‚¡ç¥¨æ•°æ®: {code}")
        
        if code not in monitored_stocks:
            return
        
        stock_data = monitored_stocks[code]
        items = stock_data.get("items", {})
        
        # 1. è·å–æ–°é—»ï¼ˆä½¿ç”¨çœŸå®çš„å¤šæºæ–°é—»èšåˆå™¨ï¼‰
        news_list_local = []
        if items.get("news", False):
            try:
                logger.info(f"ğŸ“° è·å–{code}çš„æ–°é—»...")
                news_aggregator = get_news_aggregator()
                news_data = news_aggregator.aggregate_news(
                    code,
                    include_tushare=False,  # Tushareæ–°é—»éœ€è¦5000ç§¯åˆ†
                    include_akshare=True,
                    limit_per_source=10
                )
                
                news_list_local = news_data.get('merged_news', [])
                stock_data["newsCount"] = news_data.get('total_count', 0)
                stock_data["latestNews"] = news_list_local[0]['title'] if news_list_local else ""
                
                # å…³é”®ä¿®å¤ï¼šå°†æ–°é—»æ·»åŠ åˆ°å…¨å±€news_listä¸­
                global news_list
                for news_item in news_list_local:
                    # æ·»åŠ ç›¸å…³è‚¡ç¥¨ä¿¡æ¯
                    news_with_stock = {
                        'id': f"{code}_{news_item.get('pub_time', '')}",
                        'title': news_item.get('title', ''),
                        'summary': news_item.get('content', '')[:200] if news_item.get('content') else '',
                        'publishTime': news_item.get('pub_time', ''),
                        'source': news_item.get('source', ''),
                        'relatedStocks': [code],
                        'sentiment': 0  # å°†åœ¨æƒ…ç»ªåˆ†æåæ›´æ–°
                    }
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…é‡å¤ï¼‰
                    if not any(n.get('id') == news_with_stock['id'] for n in news_list):
                        news_list.append(news_with_stock)
                
                # ä¿æŒæœ€è¿‘100æ¡æ–°é—»
                if len(news_list) > 100:
                    news_list = news_list[-100:]
                
                logger.info(f"âœ… è·å–æ–°é—»æˆåŠŸ: {len(news_list_local)}æ¡ï¼Œå…¨å±€æ–°é—»æ€»æ•°: {len(news_list)}")
                
            except Exception as e:
                logger.error(f"âŒ è·å–æ–°é—»å¤±è´¥: {e}")
                await asyncio.sleep(0.1)  # ä¿æŒå¼‚æ­¥
        
        # 2. æƒ…ç»ªåˆ†æï¼ˆä½¿ç”¨çœŸå®çš„æƒ…ç»ªåˆ†æå¼•æ“ï¼‰
        sentiment_score = 50  # é»˜è®¤ä¸­æ€§
        if items.get("sentiment", False) and news_list_local:
            try:
                logger.info(f"ğŸ’­ åˆ†æ{code}çš„æƒ…ç»ª...")
                sentiment_engine = get_sentiment_engine()
                sentiment_result = sentiment_engine.analyze_news_list(news_list_local)
                
                sentiment_score = sentiment_result.get('overall_score', 50)
                stock_data["sentimentScore"] = sentiment_score
                stock_data["sentimentDetail"] = {
                    'overall': sentiment_result.get('overall_sentiment', 'neutral'),
                    'positive': sentiment_result.get('positive_count', 0),
                    'negative': sentiment_result.get('negative_count', 0),
                    'neutral': sentiment_result.get('neutral_count', 0)
                }
                
                # æ›´æ–°å…¨å±€news_listä¸­çš„æƒ…ç»ªåˆ†æ•°
                news_sentiments = sentiment_result.get('news_sentiments', [])
                for i, news_sentiment in enumerate(news_sentiments):
                    news_id = f"{code}_{news_list_local[i].get('pub_time', '')}"
                    for news_item in news_list:
                        if news_item.get('id') == news_id:
                            news_item['sentiment'] = news_sentiment.get('score', 50)
                            break
                
                logger.info(f"âœ… æƒ…ç»ªåˆ†æå®Œæˆ: {sentiment_score:.2f}åˆ† ({sentiment_result.get('overall_sentiment')})")
                logger.info(f"   æ­£é¢:{sentiment_result.get('positive_count')} ä¸­æ€§:{sentiment_result.get('neutral_count')} è´Ÿé¢:{sentiment_result.get('negative_count')}")
                
            except Exception as e:
                logger.error(f"âŒ æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
                sentiment_score = 50
        elif items.get("sentiment", False):
            logger.warning(f"âš ï¸ æ— æ–°é—»æ•°æ®ï¼Œè·³è¿‡æƒ…ç»ªåˆ†æ")
            stock_data["sentimentScore"] = sentiment_score
        
        # 3. é£é™©åˆ†æï¼ˆä½¿ç”¨çœŸå®çš„é£é™©åˆ†æå¼•æ“ï¼‰
        if items.get("risk", False):
            try:
                logger.info(f"ğŸ” å¼€å§‹åˆ†æ{code}çš„é£é™©...")
                risk_result = analyze_stock_risk(
                    code, 
                    sentiment_score=sentiment_score
                )
                
                stock_data["riskLevel"] = risk_result.get("risk_level", "low")
                stock_data["riskScore"] = risk_result.get("risk_score", 0)
                stock_data["riskFactors"] = risk_result.get("risk_factors", {})
                stock_data["warnings"] = risk_result.get("warnings", [])
                
                logger.info(f"âœ… {code} é£é™©åˆ†æå®Œæˆ: {stock_data['riskLevel']} (å¾—åˆ†:{stock_data['riskScore']})")
                
            except Exception as e:
                logger.error(f"âŒ é£é™©åˆ†æå¤±è´¥ {code}: {e}")
                stock_data["riskLevel"] = "unknown"
        
        # 4. åœå¤ç‰Œç›‘æ§
        if items.get("suspend", False):
            try:
                logger.info(f"æ£€æŸ¥{code}çš„åœå¤ç‰ŒçŠ¶æ€...")
                suspend_status = check_suspend_status(code)
                
                stock_data["isSuspended"] = suspend_status.get("is_suspended", False)
                stock_data["suspendInfo"] = suspend_status
                
                if suspend_status.get("is_suspended"):
                    logger.warning(f"âš ï¸ {code} å½“å‰å¤„äºåœç‰ŒçŠ¶æ€")
                    
            except Exception as e:
                logger.error(f"âŒ åœå¤ç‰Œæ£€æŸ¥å¤±è´¥ {code}: {e}")
        
        # æ›´æ–°æ—¶é—´
        stock_data["lastUpdate"] = datetime.now().isoformat()
        
        logger.info(f"âœ… å®Œæˆæ›´æ–°è‚¡ç¥¨æ•°æ®: {code}")
        
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°è‚¡ç¥¨æ•°æ®å¤±è´¥ {code}: {e}")


# ==================== å®šæ—¶ä»»åŠ¡ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰ ====================

async def scheduled_update_task():
    """
    å®šæ—¶æ›´æ–°ä»»åŠ¡ï¼ˆåº”è¯¥åœ¨åå°è¿è¡Œï¼‰
    """
    while True:
        try:
            current_time = datetime.now()
            
            for code, data in monitored_stocks.items():
                frequency = data.get("frequency", "1h")
                last_update = data.get("lastUpdate")
                
                if not last_update:
                    continue
                
                last_time = datetime.fromisoformat(last_update)
                
                # æ ¹æ®é¢‘ç‡è®¡ç®—æ˜¯å¦éœ€è¦æ›´æ–°
                intervals = {
                    "5m": 5,
                    "15m": 15,
                    "30m": 30,
                    "1h": 60,
                    "1d": 1440
                }
                
                interval_minutes = intervals.get(frequency, 60)
                
                if (current_time - last_time).total_seconds() >= interval_minutes * 60:
                    await update_stock_data(code)
            
            # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            await asyncio.sleep(60)
            
        except Exception as e:
            logger.error(f"å®šæ—¶ä»»åŠ¡å‡ºé”™: {e}")
            await asyncio.sleep(60)
