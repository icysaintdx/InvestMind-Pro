# -*- coding: utf-8 -*-
"""
Êñ∞ÈóªÁõëÊéß‰∏≠ÂøÉ
ÊîØÊåÅ‰∏§Áßç‰∏öÂä°Âú∫ÊôØÔºö
1. Â∏ÇÂú∫Êñ∞ÈóªÔºàÊñ∞Èóª‰∏≠ÂøÉ/ÂÆûÊó∂Êñ∞ÈóªÊµÅÔºâ- ‰∏çÂ∏¶‰∏™ËÇ°ÂèÇÊï∞ÔºåËé∑ÂèñÂÖ®Â∏ÇÂú∫Êñ∞Èóª
2. ‰∏™ËÇ°Êñ∞ÈóªÔºàÊô∫ËÉΩÂàÜÊûê/‰∏™ËÇ°ÁõëÊéßÔºâ- Â∏¶‰∏™ËÇ°ÂèÇÊï∞ÔºåËé∑ÂèñÁâπÂÆöËÇ°Á•®Áõ∏ÂÖ≥Êñ∞Èóª
"""
import asyncio
import logging
import threading
import time
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass
from enum import Enum

from .news_cache import NewsCache, CachedNews, get_news_cache
from .stock_relation_analyzer import StockRelationAnalyzer, get_stock_relation_analyzer
from .impact_assessor import ImpactAssessor, get_impact_assessor
from .news_config import get_news_config_manager, NewsSourceType

logger = logging.getLogger(__name__)

# WebSocket Êé®ÈÄÅÂáΩÊï∞ (Âª∂ËøüÂØºÂÖ•ÈÅøÂÖçÂæ™ÁéØ‰æùËµñ)
_ws_notify_news = None
_ws_notify_urgent = None

def _get_ws_notifiers():
    global _ws_notify_news, _ws_notify_urgent
    if _ws_notify_news is None:
        try:
            from backend.api.websocket_api import notify_news_update, notify_urgent_news
            _ws_notify_news = notify_news_update
            _ws_notify_urgent = notify_urgent_news
        except Exception as e:
            logger.warning(f"Failed to import WebSocket notifiers: {e}")
    return _ws_notify_news, _ws_notify_urgent

class DataSourceType(str, Enum):
    CLS = "cls"
    EASTMONEY = "eastmoney"
    SINA = "sina"
    CNINFO = "cninfo"
    BAIDU = "baidu"
    CCTV = "cctv"

@dataclass
class DataSourceConfig:
    name: str
    source_type: DataSourceType
    interval: int
    enabled: bool = True
    priority: int = 1
    last_fetch: str = ""
    fetch_count: int = 0
    error_count: int = 0

class NewsMonitorCenter:
    """
    Êñ∞ÈóªÁõëÊéß‰∏≠ÂøÉ

    ‰∏öÂä°Âú∫ÊôØÂå∫ÂàÜÔºö
    - fetch_market_news(): Áî®‰∫éÊñ∞Èóª‰∏≠ÂøÉ/ÂÆûÊó∂Êñ∞ÈóªÊµÅÔºåËé∑ÂèñÂÖ®Â∏ÇÂú∫Êñ∞ÈóªÔºå‰∏çË∞ÉÁî®‰∏™ËÇ°Êé•Âè£
    - fetch_stock_news(stock_code): Áî®‰∫éÊô∫ËÉΩÂàÜÊûê/‰∏™ËÇ°ÁõëÊéßÔºåËé∑ÂèñÁâπÂÆöËÇ°Á•®Êñ∞Èóª
    """
    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._initialized = False
            return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self._initialized = True
        self._cache = get_news_cache()
        self._stock_analyzer = get_stock_relation_analyzer()
        self._impact_assessor = get_impact_assessor()
        self._sentiment_engine = None
        self._config_manager = get_news_config_manager()
        self._init_sentiment_engine()
        self._sources: Dict[str, DataSourceConfig] = {
            "cls": DataSourceConfig("Ë¥¢ËÅîÁ§æÁîµÊä•", DataSourceType.CLS, 30, priority=10),
            "eastmoney": DataSourceConfig("‰∏úÊñπË¥¢ÂØå", DataSourceType.EASTMONEY, 60, priority=8),
            "sina": DataSourceConfig("Êñ∞Êµ™Ë¥¢Áªè", DataSourceType.SINA, 90, priority=7),
            "cninfo": DataSourceConfig("Â∑®ÊΩÆÂÖ¨Âëä", DataSourceType.CNINFO, 300, priority=6),
        }
        self._running = False
        self._executor: Optional[ThreadPoolExecutor] = None
        self._fetch_tasks: Dict[str, asyncio.Task] = {}
        self._on_new_news: List[Callable] = []
        self._on_urgent_news: List[Callable] = []
        self._stats = {"total_fetched": 0, "total_processed": 0, "total_duplicates": 0, "start_time": None, "last_fetch_time": None}
        logger.info("NewsMonitorCenter initialized with config manager")
    
    def _init_sentiment_engine(self):
        try:
            from backend.dataflows.news.sentiment_engine import get_sentiment_engine
            self._sentiment_engine = get_sentiment_engine()
        except Exception as e:
            logger.warning(f"Failed to load sentiment engine: {e}")
    
    async def start(self):
        if self._running:
            return
        self._running = True
        self._stats["start_time"] = datetime.now().isoformat()
        # Â¢ûÂä†Á∫øÁ®ãÊ±†Â§ßÂ∞è‰ª•ÈÅøÂÖçÈòªÂ°û
        self._executor = ThreadPoolExecutor(max_workers=8, thread_name_prefix="news_")
        for source_id, config in self._sources.items():
            if config.enabled:
                task = asyncio.create_task(self._fetch_loop(source_id))
                self._fetch_tasks[source_id] = task
        logger.info(f"NewsMonitorCenter started with {len(self._fetch_tasks)} sources")
    
    async def stop(self):
        self._running = False
        for task in self._fetch_tasks.values():
            task.cancel()
        self._fetch_tasks.clear()
        if self._executor:
            self._executor.shutdown(wait=False)
            self._executor = None
        self._cache.save_to_file()
        logger.info("NewsMonitorCenter stopped")
    
    async def _fetch_loop(self, source_id: str):
        config = self._sources.get(source_id)
        if not config:
            return
        while self._running:
            try:
                await self._fetch_source(source_id)
                config.last_fetch = datetime.now().isoformat()
                config.fetch_count += 1
            except Exception as e:
                config.error_count += 1
                logger.error(f"Fetch error for {source_id}: {e}")
            await asyncio.sleep(config.interval)

    async def _fetch_source(self, source_id: str):
        config = self._sources.get(source_id)
        if not config:
            return
        news_list = []
        try:
            if config.source_type == DataSourceType.CLS:
                news_list = await self._fetch_cls()
            elif config.source_type == DataSourceType.EASTMONEY:
                news_list = await self._fetch_eastmoney()
            elif config.source_type == DataSourceType.SINA:
                news_list = await self._fetch_sina()
            elif config.source_type == DataSourceType.CNINFO:
                news_list = await self._fetch_cninfo()
        except Exception as e:
            logger.error(f"Fetch {source_id} failed: {e}")
            return
        if news_list:
            await self._process_news(news_list, source_id)
    
    async def _fetch_cls(self) -> List[Dict]:
        """Ëé∑ÂèñË¥¢ËÅîÁ§æÁîµÊä•"""
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []

            # Ë¥¢ËÅîÁ§æÂÖ®ÁêÉËµÑËÆØ stock_info_global_cls
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_cls)
                if df is not None and not df.empty:
                    for _, row in df.iterrows():
                        title = str(row.get("Ê†áÈ¢ò", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("ÂÜÖÂÆπ", ""))[:1000],
                                "pub_time": str(row.get("ÂèëÂ∏ÉÊó•Êúü", "")) + " " + str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                "source": "Ë¥¢ËÅîÁ§æ",
                                "url": ""
                            })
                    logger.info(f"Ë¥¢ËÅîÁ§æÁîµÊä•Ëé∑Âèñ: {len(news_list)}Êù°")
            except Exception as e:
                logger.debug(f"Ë¥¢ËÅîÁ§æÂ§±Ë¥•: {e}")

            return news_list
        except Exception as e:
            logger.error(f"Fetch CLS failed: {e}")
            return []

    async def _fetch_eastmoney(self) -> List[Dict]:
        """
        Ëé∑Âèñ‰∏úÊñπË¥¢ÂØåÊñ∞Èóª - ÂåÖÂê´Â§ö‰∏™Êé•Âè£:
        1. stock_info_global_em - ‰∏úÊñπË¥¢ÂØåÂÖ®ÁêÉËµÑËÆØ
        2. stock_news_em - ‰∏™ËÇ°Êñ∞Èóª(Â§öÂè™ËÇ°Á•®)
        3. stock_info_cjzc_em - Ë¥¢ÁªèÊó©È§ê
        4. stock_info_global_futu - ÂØåÈÄîÁâõÁâõ
        5. stock_info_global_ths - ÂêåËä±È°∫
        6. stock_info_global_sina - Êñ∞Êµ™Ë¥¢Áªè
        7. stock_js_weibo_report - ÂæÆÂçöÁÉ≠ËÆÆ
        8. news_cctv - Êñ∞ÈóªËÅîÊí≠
        9. news_economic_baidu - ÁôæÂ∫¶Ë¥¢Áªè
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []

            # 1. ‰∏úÊñπË¥¢ÂØåÂÖ®ÁêÉËµÑËÆØ stock_info_global_em
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_em)
                if df is not None and not df.empty:
                    for _, row in df.iterrows():
                        title = str(row.get("Ê†áÈ¢ò", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("ÊëòË¶Å", row.get("ÂÜÖÂÆπ", "")))[:1000],
                                "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                "source": "‰∏úÊñπË¥¢ÂØå",
                                "url": str(row.get("ÈìæÊé•", ""))
                            })
                    logger.info(f"‰∏úÊñπË¥¢ÂØåÂÖ®ÁêÉËµÑËÆØ: {len(news_list)}Êù°")
            except Exception as e:
                logger.debug(f"stock_info_global_emÂ§±Ë¥•: {e}")

            # 2. ‰∏™ËÇ°Êñ∞Èóª stock_news_em - Â§öÂè™ÁÉ≠Èó®ËÇ°Á•®
            hot_stocks = [
                "000001", "600519", "000858", "601318", "600036", "000333", "002594", "300750",
                "600000", "601166", "000002", "600030", "601398", "600016", "601288", "000651",
                "600276", "000725", "601012", "600887", "000568", "002415", "600309", "601888",
                "002304", "000063", "601601", "600900", "000100", "002475"
            ]
            stock_news_count = 0
            for symbol in hot_stocks:
                try:
                    df = await loop.run_in_executor(self._executor, lambda s=symbol: ak.stock_news_em(symbol=s))
                    if df is not None and not df.empty:
                        for _, row in df.iterrows():
                            title = str(row.get("Êñ∞ÈóªÊ†áÈ¢ò", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("Êñ∞ÈóªÂÜÖÂÆπ", ""))[:1000],
                                    "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                    "source": f"‰∏úË¥¢‰∏™ËÇ°",
                                    "url": str(row.get("Êñ∞ÈóªÈìæÊé•", ""))
                                })
                                stock_news_count += 1
                except Exception as e:
                    logger.debug(f"stock_news_em({symbol})Â§±Ë¥•: {e}")
                    continue
            if stock_news_count > 0:
                logger.info(f"‰∏úË¥¢‰∏™ËÇ°Êñ∞Èóª: {stock_news_count}Êù°")

            # 3. Ë¥¢ÁªèÊó©È§ê stock_info_cjzc_em
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_cjzc_em)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("Ê†áÈ¢ò", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("ÂÜÖÂÆπ", ""))[:1000],
                                "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                "source": "Ë¥¢ÁªèÊó©È§ê",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"Ë¥¢ÁªèÊó©È§ê: {count}Êù°")
            except Exception as e:
                logger.debug(f"stock_info_cjzc_emÂ§±Ë¥•: {e}")

            # 4. ÂØåÈÄîÁâõÁâõ stock_info_global_futu
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_futu)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("Ê†áÈ¢ò", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("ÂÜÖÂÆπ", ""))[:1000],
                                "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                "source": "ÂØåÈÄîÁâõÁâõ",
                                "url": str(row.get("ÈìæÊé•", ""))
                            })
                            count += 1
                    logger.info(f"ÂØåÈÄîÁâõÁâõ: {count}Êù°")
            except Exception as e:
                logger.debug(f"stock_info_global_futuÂ§±Ë¥•: {e}")

            # 5. ÂêåËä±È°∫ stock_info_global_ths
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_ths)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("Ê†áÈ¢ò", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("ÂÜÖÂÆπ", ""))[:1000],
                                "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                "source": "ÂêåËä±È°∫",
                                "url": str(row.get("ÈìæÊé•", ""))
                            })
                            count += 1
                    logger.info(f"ÂêåËä±È°∫: {count}Êù°")
            except Exception as e:
                logger.debug(f"stock_info_global_thsÂ§±Ë¥•: {e}")

            # 6. Êñ∞Êµ™Ë¥¢Áªè stock_info_global_sina - ÂàóÂêç: ['Êó∂Èó¥', 'ÂÜÖÂÆπ']
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_sina)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        # Êñ∞Êµ™Ë¥¢ÁªèËøîÂõûÁöÑÂàóÊòØ ['Êó∂Èó¥', 'ÂÜÖÂÆπ']ÔºåÊ≤°ÊúâÊ†áÈ¢òÂ≠óÊÆµ
                        content = str(row.get("ÂÜÖÂÆπ", ""))
                        if content:
                            # ‰ΩøÁî®ÂÜÖÂÆπÂâç50Â≠óÁ¨¶‰Ωú‰∏∫Ê†áÈ¢ò
                            title = content[:50] + "..." if len(content) > 50 else content
                            news_list.append({
                                "title": title,
                                "content": content[:1000],
                                "pub_time": str(row.get("Êó∂Èó¥", "")),
                                "source": "Êñ∞Êµ™Ë¥¢Áªè",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"Êñ∞Êµ™Ë¥¢Áªè: {count}Êù°")
            except Exception as e:
                logger.debug(f"stock_info_global_sinaÂ§±Ë¥•: {e}")

            # 7. ÂæÆÂçöÁÉ≠ËÆÆ stock_js_weibo_report
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_js_weibo_report)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        # ÂæÆÂçöÁÉ≠ËÆÆÊ†ºÂºè: name(ËÇ°Á•®ÂêçÁß∞), rate(Ê∂®Ë∑åÂπÖ)
                        stock_name = str(row.get("name", row.get("ËÇ°Á•®", "")))
                        rate = row.get("rate", row.get("Ê∂®Ë∑åÂπÖ", 0))
                        if stock_name:
                            # Ê†ºÂºèÂåñÊ∂®Ë∑åÂπÖ
                            try:
                                rate_val = float(rate)
                                rate_str = f"+{rate_val:.2f}%" if rate_val >= 0 else f"{rate_val:.2f}%"
                            except:
                                rate_str = str(rate)
                            news_list.append({
                                "title": f"[ÂæÆÂçöÁÉ≠ËÆÆ] {stock_name} {rate_str}",
                                "content": f"ÂæÆÂçöËÇ°Á•®ÁÉ≠ËÆÆÊ¶úÔºåÂΩìÂâçÊ∂®Ë∑åÂπÖ: {rate_str}",
                                "pub_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "source": "ÂæÆÂçöÁÉ≠ËÆÆ",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"ÂæÆÂçöÁÉ≠ËÆÆ: {count}Êù°")
            except Exception as e:
                logger.debug(f"stock_js_weibo_reportÂ§±Ë¥•: {e}")

            # 8. Êñ∞ÈóªËÅîÊí≠ news_cctv
            try:
                today = datetime.now().strftime('%Y%m%d')
                df = await loop.run_in_executor(self._executor, lambda: ak.news_cctv(date=today))
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("title", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("content", ""))[:1000],
                                "pub_time": str(row.get("date", today)),
                                "source": "Êñ∞ÈóªËÅîÊí≠",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"Êñ∞ÈóªËÅîÊí≠: {count}Êù°")
            except Exception as e:
                logger.debug(f"news_cctvÂ§±Ë¥•: {e}")

            # 9. ÁôæÂ∫¶Ë¥¢Áªè news_economic_baidu - ÂàóÂêç: ['ÂõΩÂÆ∂', 'Êó∂Èó¥', 'Âú∞Âå∫', '‰∫ã‰ª∂', '‰ªäÂÄº', 'È¢ÑÊúü', 'ÂâçÂÄº', 'ÈáçË¶ÅÊÄß']
            try:
                df = await loop.run_in_executor(self._executor, ak.news_economic_baidu)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        # ÁôæÂ∫¶Ë¥¢ÁªèËøîÂõûÁöÑÊòØÁªèÊµéÊó•ÂéÜÊï∞ÊçÆÔºå‰ΩøÁî®'‰∫ã‰ª∂'‰Ωú‰∏∫Ê†áÈ¢ò
                        event = str(row.get("‰∫ã‰ª∂", ""))
                        if event:
                            country = str(row.get("ÂõΩÂÆ∂", ""))
                            title = f"[{country}] {event}" if country else event
                            # ÁªÑÂêà‰ªäÂÄº/È¢ÑÊúü/ÂâçÂÄº/ÈáçË¶ÅÊÄß‰Ωú‰∏∫ÂÜÖÂÆπ
                            today_val = row.get("‰ªäÂÄº", "")
                            expect_val = row.get("È¢ÑÊúü", "")
                            prev_val = row.get("ÂâçÂÄº", "")
                            importance = row.get("ÈáçË¶ÅÊÄß", "")
                            content = f"‰ªäÂÄº: {today_val} | È¢ÑÊúü: {expect_val} | ÂâçÂÄº: {prev_val} | ÈáçË¶ÅÊÄß: {importance}"
                            news_list.append({
                                "title": title,
                                "content": content,
                                "pub_time": str(row.get("Êó∂Èó¥", "")),
                                "source": "ÁôæÂ∫¶Ë¥¢Áªè",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"ÁôæÂ∫¶Ë¥¢Áªè: {count}Êù°")
            except Exception as e:
                logger.debug(f"news_economic_baiduÂ§±Ë¥•: {e}")

            logger.info(f"‰∏úÊñπË¥¢ÂØåÊ∫êÊÄªËÆ°: {len(news_list)}Êù°")
            return news_list
        except Exception as e:
            logger.error(f"Fetch eastmoney failed: {e}")
            return []

    async def _fetch_sina(self) -> List[Dict]:
        """
        Ëé∑ÂèñÊñ∞Êµ™Ë¥¢ÁªèÊñ∞Èóª - ÂåÖÂê´:
        1. Êõ¥Â§ö‰∏™ËÇ°Êñ∞Èóª
        2. ‰∏úÊñπË¥¢ÂØåÂÖ¨Âëä
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []

            # 1. Êõ¥Â§ö‰∏™ËÇ°Êñ∞Èóª
            more_stocks = [
                "600519", "000858", "601318", "000001", "600036",
                "601166", "000002", "600030", "601398", "600016",
                "601288", "000651", "600276", "000725", "601012",
                "300059", "002230", "600104", "000538", "002352"
            ]
            stock_news_count = 0
            for symbol in more_stocks:
                try:
                    df = await loop.run_in_executor(self._executor, lambda s=symbol: ak.stock_news_em(symbol=s))
                    if df is not None and not df.empty:
                        for _, row in df.iterrows():
                            title = str(row.get("Êñ∞ÈóªÊ†áÈ¢ò", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("Êñ∞ÈóªÂÜÖÂÆπ", ""))[:1000],
                                    "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                    "source": f"Êñ∞Êµ™‰∏™ËÇ°",
                                    "url": str(row.get("Êñ∞ÈóªÈìæÊé•", ""))
                                })
                                stock_news_count += 1
                except Exception as e:
                    logger.debug(f"Êñ∞Êµ™‰∏™ËÇ°({symbol})Â§±Ë¥•: {e}")
                    continue
            if stock_news_count > 0:
                logger.info(f"Êñ∞Êµ™‰∏™ËÇ°Êñ∞Èóª: {stock_news_count}Êù°")

            # 2. ‰∏úÊñπË¥¢ÂØåÂÖ¨Âëä (‰Ωú‰∏∫Êñ∞Êµ™Ê∫êÁöÑË°•ÂÖÖ)
            try:
                # Â∞ùËØïËé∑ÂèñÂÖ¨ÂëäÊï∞ÊçÆ
                df = await loop.run_in_executor(self._executor, lambda: ak.stock_notice_report(symbol="ÂÖ®ÈÉ®", date="20241230"))
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("ÂÖ¨ÂëäÊ†áÈ¢ò", row.get("Ê†áÈ¢ò", "")))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("ÂÖ¨ÂëäÂÜÖÂÆπ", ""))[:1000],
                                "pub_time": str(row.get("ÂÖ¨ÂëäÊó•Êúü", "")),
                                "source": "‰∏úË¥¢ÂÖ¨Âëä",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"‰∏úË¥¢ÂÖ¨Âëä: {count}Êù°")
            except Exception as e:
                logger.debug(f"‰∏úË¥¢ÂÖ¨ÂëäÂ§±Ë¥•: {e}")

            logger.info(f"Êñ∞Êµ™Ë¥¢ÁªèÊ∫êÊÄªËÆ°: {len(news_list)}Êù°")
            return news_list
        except Exception as e:
            logger.error(f"Fetch sina failed: {e}")
            return []

    async def _fetch_eastmoney_global(self) -> List[Dict]:
        """Ëé∑Âèñ‰∏úË¥¢ÂÖ®ÁêÉËµÑËÆØ - Â∑≤Âú® _fetch_eastmoney ‰∏≠ÂÆûÁé∞ÔºåËøôÈáå‰Ωú‰∏∫Ë°•ÂÖÖ"""
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []

            # Êñ∞Êµ™Ë¥¢ÁªèÊñ∞Èóª
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_news_em, "000001")
                if df is not None and not df.empty:
                    for _, row in df.iterrows():
                        title = str(row.get("Êñ∞ÈóªÊ†áÈ¢ò", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("Êñ∞ÈóªÂÜÖÂÆπ", ""))[:1000],
                                "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                "source": "‰∏úË¥¢ÂÖ®ÁêÉ",
                                "url": str(row.get("Êñ∞ÈóªÈìæÊé•", ""))
                            })
                    logger.info(f"‰∏úË¥¢ÂÖ®ÁêÉËé∑Âèñ: {len(news_list)}Êù°")
            except Exception as e:
                logger.debug(f"‰∏úË¥¢ÂÖ®ÁêÉËé∑ÂèñÂ§±Ë¥•: {e}")

            return news_list
        except Exception as e:
            logger.error(f"Fetch eastmoney global failed: {e}")
            return []

    async def _fetch_cninfo(self) -> List[Dict]:
        """Ëé∑ÂèñÂ∑®ÊΩÆËµÑËÆØÁΩëÊï∞ÊçÆÔºà‰ΩøÁî®ÂÆòÊñπAPI - ÂÖçË¥πÊé•Âè£Ôºâ"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            # Ê£ÄÊü•ÊòØÂê¶ÈÖçÁΩÆ‰∫ÜÂ∑®ÊΩÆAPI
            if not CninfoConfig.is_configured():
                logger.debug("Â∑®ÊΩÆAPIÊú™ÈÖçÁΩÆÔºåË∑≥ËøáËé∑Âèñ")
                return []

            client = get_cninfo_api_client()
            news_list = []

            # 1. Ëé∑ÂèñÊúÄÊñ∞ÂÖ¨Âëä‰ø°ÊÅØ (p_info3015) - ÂÖçË¥πÂèØÁî®
            try:
                # Ëé∑ÂèñÂΩìÂ§©ÁöÑÂÖ¨Âëä
                today = datetime.now().strftime('%Y-%m-%d')
                announcement_result = await client.get_announcement_info(
                    start_date=today,
                    end_date=today,
                    page_size=1000
                )
                if announcement_result.get('success') and announcement_result.get('data'):
                    for item in announcement_result['data']:  # ‰∏çÈôêÂà∂
                        title = item.get('F002V', '')  # ÂÖ¨ÂëäÊ†áÈ¢ò
                        if not title:
                            continue
                        pub_date = item.get('F001D', '')  # ÂÖ¨ÂëäÊó•Êúü
                        pdf_url = item.get('F003V', '')  # PDFÂú∞ÂùÄ
                        stock_code = item.get('SECCODE', '')
                        stock_name = item.get('SECNAME', '')
                        market = item.get('F010V', '')  # Â∏ÇÂú∫ÂêçÁß∞
                        category = item.get('F006V', '')  # ‰ø°ÊÅØÂàÜÁ±ª

                        # Âà§Êñ≠ÂÖ¨ÂëäÈáçË¶ÅÊÄß
                        importance = 'low'
                        urgency = 'low'
                        if any(kw in title for kw in ['‰∏öÁª©È¢ÑÂëä', '‰∏öÁª©Âø´Êä•', 'ÈáçÂ§ß', 'ÂÅúÁâå', 'Â§çÁâå', 'È£éÈô©ÊèêÁ§∫']):
                            importance = 'high'
                            urgency = 'high'
                        elif any(kw in title for kw in ['Âπ¥Êä•', 'Â≠£Êä•', '‰∏≠Êä•', 'ÂàÜÁ∫¢', 'Â¢ûÊåÅ', 'ÂáèÊåÅ']):
                            importance = 'medium'
                            urgency = 'medium'

                        news_list.append({
                            "title": f"[{stock_name or 'ÂÖ¨Âëä'}] {title}",
                            "content": f"ËØÅÂà∏‰ª£Á†Å: {stock_code} | Â∏ÇÂú∫: {market} | ÂàÜÁ±ª: {category}",
                            "pub_time": pub_date,
                            "source": "Â∑®ÊΩÆÂÖ¨Âëä",
                            "url": pdf_url,
                            "announcement_type": "announcement",
                            "importance": importance,
                            "urgency": urgency,
                            "related_stocks": [stock_code] if stock_code else []
                        })
            except Exception as e:
                logger.warning(f"Ëé∑ÂèñÂÖ¨Âëä‰ø°ÊÅØÂ§±Ë¥•: {e}")

            # 2. Ëé∑Âèñ‰∏äÂ∏ÇÁä∂ÊÄÅÂèòÂä® (p_stock2117) - ÂÖçË¥πÂèØÁî®ÔºåÈáçË¶Å‰ø°ÊÅØ
            # Ê≥®ÊÑèÔºöÊ≠§Êé•Âè£ËøîÂõûÊâÄÊúâÂéÜÂè≤Êï∞ÊçÆÔºåÂè™ÂèñÊúÄËøë100Êù°
            try:
                status_result = await client.get_listing_status_changes()
                if status_result.get('success') and status_result.get('data'):
                    # Âè™ÂèñÊúÄËøë100Êù°ÔºàÊåâÊó∂Èó¥ÂÄíÂ∫èÔºâ
                    data = status_result['data'][:100]
                    for item in data:
                        stock_code = item.get('SECCODE', '')
                        stock_name = item.get('SECNAME', '')
                        org_name = item.get('ORGNAME', '')
                        change_date = item.get('VARYDATE', '')
                        status = item.get('F002V', '')  # ‰∏äÂ∏ÇÁä∂ÊÄÅ
                        change_type = item.get('F006V', '')  # ÂèòÊõ¥Á±ªÂûã
                        reason = item.get('F004V', '')  # ÂèòÊõ¥ÂéüÂõ†

                        if not stock_code or not change_type:
                            continue

                        # Âà§Êñ≠ÈáçË¶ÅÊÄß
                        urgency = 'medium'
                        if any(kw in str(change_type) for kw in ['ÈÄÄÂ∏Ç', 'ÊöÇÂÅú‰∏äÂ∏Ç', 'ÁªàÊ≠¢‰∏äÂ∏Ç']):
                            urgency = 'critical'
                        elif any(kw in str(change_type) for kw in ['ST', 'È£éÈô©Ë≠¶Á§∫', 'ÂÅúÁâå']):
                            urgency = 'high'

                        news_list.append({
                            "title": f"[‰∏äÂ∏ÇÁä∂ÊÄÅ] {stock_name}({stock_code}) {change_type}",
                            "content": f"ÂÖ¨Âè∏: {org_name} | Áä∂ÊÄÅ: {status} | ÂéüÂõ†: {reason or 'Êó†'}",
                            "pub_time": change_date,
                            "source": "Â∑®ÊΩÆÁä∂ÊÄÅÂèòÂä®",
                            "url": "",
                            "announcement_type": "status_change",
                            "importance": "high" if urgency in ['critical', 'high'] else "medium",
                            "urgency": urgency,
                            "related_stocks": [stock_code] if stock_code else []
                        })
            except Exception as e:
                logger.warning(f"Ëé∑Âèñ‰∏äÂ∏ÇÁä∂ÊÄÅÂèòÂä®Â§±Ë¥•: {e}")

            if news_list:
                logger.info(f"‰ªéÂ∑®ÊΩÆÂÆòÊñπAPIËé∑Âèñ {len(news_list)} Êù°Êï∞ÊçÆ")
            return news_list

        except Exception as e:
            logger.error(f"Fetch cninfo failed: {e}")
            return []

    def _get_monitored_stocks(self) -> List[str]:
        """Ëé∑ÂèñÂΩìÂâçÁõëÊéßÁöÑËÇ°Á•®ÂàóË°®"""
        try:
            # Â∞ùËØï‰ªéÁõëÊéßÊúçÂä°Ëé∑Âèñ
            from backend.services.realtime_monitor_service import get_realtime_monitor_service
            monitor = get_realtime_monitor_service()
            if hasattr(monitor, 'config') and monitor.config:
                stocks = monitor.config.get('stocks', [])
                if stocks:
                    return stocks
        except:
            pass
        # ÈªòËÆ§ËøîÂõû‰∏Ä‰∫õÁÉ≠Èó®ËÇ°Á•®
        return ["600519.SH", "000858.SZ", "601318.SH", "000001.SZ", "600036.SH"]

    def _get_monitored_stock_codes(self) -> Dict[str, str]:
        """Ëé∑ÂèñÁõëÊéßËÇ°Á•®‰ª£Á†ÅÊò†Â∞Ñ {Á∫Ø‰ª£Á†Å: ts_code}"""
        try:
            from backend.services.alert_service import get_alert_service
            alert_service = get_alert_service()
            monitored = alert_service.get_monitored_stocks()
            # ÊûÑÂª∫Êò†Â∞Ñ: 600519 -> 600519.SH
            code_map = {}
            for ts_code, info in monitored.items():
                pure_code = ts_code.split('.')[0]
                code_map[pure_code] = ts_code
                # ‰πüÊ∑ªÂä†ËÇ°Á•®ÂêçÁß∞Êò†Â∞Ñ
                if info.get('name'):
                    code_map[info['name']] = ts_code
            return code_map
        except Exception as e:
            logger.debug(f"Failed to get monitored stock codes: {e}")
            return {}

    def _match_monitored_stocks(self, related_stocks: List[str], monitored_codes: Dict[str, str]) -> List[Dict]:
        """ÂåπÈÖçÊñ∞ÈóªÂÖ≥ËÅîÁöÑËÇ°Á•®‰∏éÁõëÊéßËÇ°Á•®"""
        matched = []
        for stock in related_stocks:
            # Ê∏ÖÁêÜËÇ°Á•®‰ª£Á†Å
            clean_code = str(stock).replace('.SH', '').replace('.SZ', '').replace('.BJ', '')
            clean_code = clean_code.replace('SH', '').replace('SZ', '').replace('BJ', '')

            if clean_code in monitored_codes:
                ts_code = monitored_codes[clean_code]
                matched.append({
                    'ts_code': ts_code,
                    'code': clean_code
                })
        return matched

    async def _create_alerts_for_monitored_stocks(self, news_list: List[Dict]):
        """‰∏∫ÁõëÊéßËÇ°Á•®ÂàõÂª∫È¢ÑË≠¶"""
        try:
            from backend.services.alert_service import get_alert_service
            alert_service = get_alert_service()

            for news in news_list:
                matched_stocks = news.get('matched_monitored_stocks', [])
                urgency = news.get('urgency', 'low')

                # Âè™‰∏∫‰∏≠Á≠â‰ª•‰∏äÁ¥ßÊÄ•Á®ãÂ∫¶ÁöÑÊñ∞ÈóªÂàõÂª∫È¢ÑË≠¶
                if urgency not in ['critical', 'high', 'medium']:
                    continue

                for stock_info in matched_stocks:
                    ts_code = stock_info.get('ts_code', '')
                    stock_data = alert_service.get_stock_info(ts_code)
                    stock_name = stock_data.get('name', '') if stock_data else ''

                    await alert_service.create_alert_from_news(
                        news=news,
                        stock_code=ts_code,
                        stock_name=stock_name
                    )

            logger.info(f"Created alerts for {len(news_list)} monitored stock news")

        except Exception as e:
            logger.error(f"Failed to create alerts for monitored stocks: {e}")
    
    async def _process_news(self, news_list: List[Dict], source_id: str):
        """Â§ÑÁêÜÊñ∞ÈóªÂàóË°® - Â∞ÜCPUÂØÜÈõÜÂûãÊìç‰ΩúÁßªÂà∞Á∫øÁ®ãÊ±†ÈÅøÂÖçÈòªÂ°û"""
        new_count = 0
        urgent_news = []
        monitored_stock_news = []  # ‰∏éÁõëÊéßËÇ°Á•®Áõ∏ÂÖ≥ÁöÑÊñ∞Èóª
        loop = asyncio.get_event_loop()

        # Ëé∑ÂèñÁõëÊéßËÇ°Á•®ÂàóË°®
        monitored_codes = self._get_monitored_stock_codes()

        for news_data in news_list:
            title = news_data.get("title", "")
            content = news_data.get("content", "")
            if not title:
                continue
            if self._cache.is_duplicate(title, news_data.get("pub_time", "")):
                self._stats["total_duplicates"] += 1
                continue

            # Â∞ÜCPUÂØÜÈõÜÂûãÊìç‰ΩúÁßªÂà∞Á∫øÁ®ãÊ±†‰∏≠ÊâßË°å
            try:
                sentiment_result, related_stocks, impact = await loop.run_in_executor(
                    self._executor,
                    self._analyze_news_sync,
                    title,
                    content
                )
            except Exception as e:
                logger.debug(f"News analysis failed: {e}")
                sentiment_result = {"sentiment": "neutral", "score": 50, "urgency": "low"}
                related_stocks = []
                impact = type('Impact', (), {'urgency': 'low', 'score': 0})()

            enriched_news = {**news_data, "sentiment": sentiment_result.get("sentiment", "neutral"), "sentiment_score": sentiment_result.get("score", 50), "urgency": impact.urgency, "keywords": sentiment_result.get("keywords", []), "related_stocks": related_stocks, "impact_score": impact.score}
            result = self._cache.add_news_batch([enriched_news])
            if result["added"] > 0:
                new_count += 1
                self._stats["total_processed"] += 1
                if impact.urgency in ["critical", "high"]:
                    urgent_news.append(enriched_news)

                # Ê£ÄÊü•ÊòØÂê¶‰∏éÁõëÊéßËÇ°Á•®Áõ∏ÂÖ≥
                if monitored_codes and related_stocks:
                    matched_codes = self._match_monitored_stocks(related_stocks, monitored_codes)
                    if matched_codes:
                        enriched_news['matched_monitored_stocks'] = matched_codes
                        monitored_stock_news.append(enriched_news)

        self._stats["total_fetched"] += len(news_list)
        self._stats["last_fetch_time"] = datetime.now().isoformat()
        if new_count > 0:
            logger.info(f"[{source_id}] Processed {new_count} new news")
            for callback in self._on_new_news:
                try:
                    callback(new_count, source_id)
                except:
                    pass
        if urgent_news:
            logger.warning(f"[{source_id}] Found {len(urgent_news)} urgent news!")
            for callback in self._on_urgent_news:
                try:
                    callback(urgent_news)
                except:
                    pass
            # WebSocket Êé®ÈÄÅÁ¥ßÊÄ•Êñ∞Èóª
            ws_notify, ws_urgent = _get_ws_notifiers()
            if ws_urgent:
                try:
                    asyncio.create_task(ws_urgent(urgent_news))
                except:
                    pass
            # ÂèëÈÄÅÈÄöÁü•Ôºà‰ºÅ‰∏öÂæÆ‰ø°/ÈíâÈíâ/ÈÇÆ‰ª∂Á≠âÔºâ
            try:
                asyncio.create_task(self._send_urgent_notification(urgent_news))
            except:
                pass

        # Â§ÑÁêÜ‰∏éÁõëÊéßËÇ°Á•®Áõ∏ÂÖ≥ÁöÑÊñ∞Èóª - ÂàõÂª∫È¢ÑË≠¶
        if monitored_stock_news:
            logger.info(f"[{source_id}] Found {len(monitored_stock_news)} news related to monitored stocks")
            asyncio.create_task(self._create_alerts_for_monitored_stocks(monitored_stock_news))

    def _analyze_news_sync(self, title: str, content: str):
        """ÂêåÊ≠•ÂàÜÊûêÊñ∞ÈóªÔºàÂú®Á∫øÁ®ãÊ±†‰∏≠ÊâßË°åÔºâ"""
        sentiment_result = {"sentiment": "neutral", "score": 50, "urgency": "low"}
        if self._sentiment_engine:
            try:
                sentiment_result = self._sentiment_engine.analyze(title, content)
            except:
                pass
        related_stocks = self._stock_analyzer.get_related_codes(title, content)
        impact = self._impact_assessor.assess(title, content, sentiment_result.get("score", 50))
        return sentiment_result, related_stocks, impact

    async def _send_urgent_notification(self, urgent_news: List[Dict]):
        """ÂèëÈÄÅÁ¥ßÊÄ•Êñ∞ÈóªÈÄöÁü•Âà∞ÈÖçÁΩÆÁöÑÊ∏†ÈÅì"""
        try:
            from backend.services.notification_service import get_notification_service
            notification_service = get_notification_service()

            # ËΩ¨Êç¢‰∏∫È¢ÑË≠¶Ê†ºÂºè
            alerts = []
            for news in urgent_news[:5]:  # ÊúÄÂ§ö5Êù°
                urgency = news.get('urgency', 'medium')
                level = 'critical' if urgency == 'critical' else 'high' if urgency == 'high' else 'medium'
                alerts.append({
                    'title': f"üì∞ {news.get('title', 'ÈáçË¶ÅÊñ∞Èóª')[:50]}",
                    'message': news.get('content', '')[:200] if news.get('content') else news.get('title', ''),
                    'level': level,
                    'stock_code': ', '.join(news.get('related_stocks', [])[:3]) or 'Â∏ÇÂú∫',
                    'suggestion': f"Êù•Ê∫ê: {news.get('source', 'Êú™Áü•')} | ÊÉÖÁª™: {news.get('sentiment', 'neutral')}"
                })

            if alerts:
                result = await notification_service.send_alert_notification(alerts)
                if result.get('success'):
                    logger.info(f"‚úÖ Á¥ßÊÄ•Êñ∞ÈóªÈÄöÁü•ÂèëÈÄÅÊàêÂäü: {len(alerts)}Êù°")
                elif '0/0' in result.get('message', ''):
                    # Ê≤°ÊúâÈÖçÁΩÆÈÄöÁü•Ê∏†ÈÅìÔºåËøôÊòØÊ≠£Â∏∏ÊÉÖÂÜµÔºå‰∏çÈúÄË¶ÅË≠¶Âëä
                    logger.debug(f"Á¥ßÊÄ•Êñ∞ÈóªÈÄöÁü•: Êú™ÈÖçÁΩÆÈÄöÁü•Ê∏†ÈÅìÔºåË∑≥ËøáÂèëÈÄÅ")
                else:
                    logger.warning(f"‚ö†Ô∏è Á¥ßÊÄ•Êñ∞ÈóªÈÄöÁü•ÂèëÈÄÅÈÉ®ÂàÜÂ§±Ë¥•: {result.get('message')}")
        except Exception as e:
            logger.error(f"ÂèëÈÄÅÁ¥ßÊÄ•Êñ∞ÈóªÈÄöÁü•Â§±Ë¥•: {e}")

    def get_latest_news(self, limit: int = 100, **filters) -> List[Dict]:
        news_list = self._cache.get_latest_news(limit, **filters)
        return [n.to_dict() for n in news_list]
    
    def get_urgent_news(self, limit: int = 20) -> List[Dict]:
        news_list = self._cache.get_urgent_news(limit)
        return [n.to_dict() for n in news_list]
    
    def get_news_for_stock(self, stock_code: str, limit: int = 30) -> List[Dict]:
        news_list = self._cache.get_news_for_stock(stock_code, limit)
        return [n.to_dict() for n in news_list]
    
    def get_stats(self) -> Dict[str, Any]:
        cache_stats = self._cache.get_stats()
        source_stats = {sid: {"name": cfg.name, "interval": cfg.interval, "enabled": cfg.enabled, "last_fetch": cfg.last_fetch, "fetch_count": cfg.fetch_count, "error_count": cfg.error_count} for sid, cfg in self._sources.items()}
        return {**self._stats, "cache": cache_stats, "sources": source_stats, "running": self._running}
    
    def set_source_interval(self, source_id: str, interval: int):
        if source_id in self._sources:
            self._sources[source_id].interval = max(10, interval)
            logger.info(f"Set {source_id} interval to {interval}s")
    
    def enable_source(self, source_id: str, enabled: bool = True):
        if source_id in self._sources:
            self._sources[source_id].enabled = enabled
            logger.info(f"Set {source_id} enabled={enabled}")
    
    def on_new_news(self, callback: Callable):
        self._on_new_news.append(callback)
    
    def on_urgent_news(self, callback: Callable):
        self._on_urgent_news.append(callback)
    
    async def fetch_now(self, source_id: str = None):
        if source_id:
            await self._fetch_source(source_id)
        else:
            for sid in self._sources:
                await self._fetch_source(sid)
    
    def cleanup(self):
        return self._cache.cleanup_expired()

    # ==================== Â∏ÇÂú∫Êñ∞ÈóªËé∑ÂèñÔºàÊñ∞Èóª‰∏≠ÂøÉ/ÂÆûÊó∂Êñ∞ÈóªÊµÅÔºâ====================

    async def fetch_market_news(self) -> List[Dict]:
        """
        Ëé∑ÂèñÂ∏ÇÂú∫Êñ∞ÈóªÔºàÁî®‰∫éÊñ∞Èóª‰∏≠ÂøÉ/ÂÆûÊó∂Êñ∞ÈóªÊµÅÔºâ
        Âè™Ë∞ÉÁî®Â∏ÇÂú∫Á∫ßÂà´ÁöÑÊñ∞ÈóªÊé•Âè£Ôºå‰∏çË∞ÉÁî®‰∏™ËÇ°Êñ∞ÈóªÊé•Âè£

        ÂåÖÂê´Êé•Âè£Ôºö
        1. stock_info_global_em - ‰∏úÊñπË¥¢ÂØåÂÖ®ÁêÉËµÑËÆØ
        2. stock_info_global_cls - Ë¥¢ËÅîÁ§æÂÖ®ÁêÉËµÑËÆØ
        3. stock_info_global_futu - ÂØåÈÄîÁâõÁâõ
        4. stock_info_global_ths - ÂêåËä±È°∫
        5. stock_info_global_sina - Êñ∞Êµ™Ë¥¢Áªè
        6. stock_js_weibo_report - ÂæÆÂçöÁÉ≠ËÆÆ
        7. stock_info_cjzc_em - Ë¥¢ÁªèÊó©È§ê
        8. news_cctv - Êñ∞ÈóªËÅîÊí≠
        9. news_economic_baidu - ÁôæÂ∫¶Ë¥¢Áªè
        10. Â∑®ÊΩÆÂ∏ÇÂú∫ÂÖ¨ÂëäÔºà‰∏çÂ∏¶‰∏™ËÇ°ÂèÇÊï∞Ôºâ
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []
            config = self._config_manager.config

            # 1. ‰∏úÊñπË¥¢ÂØåÂÖ®ÁêÉËµÑËÆØ
            source_cfg = config.market_sources.get(NewsSourceType.EASTMONEY_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_em)
                    if df is not None and not df.empty:
                        for _, row in df.iterrows():
                            title = str(row.get("Ê†áÈ¢ò", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("ÊëòË¶Å", row.get("ÂÜÖÂÆπ", "")))[:1000],
                                    "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                    "source": source_cfg.name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                                    "url": str(row.get("ÈìæÊé•", ""))
                                })
                        logger.info(f"‰∏úÊñπË¥¢ÂØåÂÖ®ÁêÉËµÑËÆØ: {len([n for n in news_list if n['source'] == source_cfg.name])}Êù°")
                except Exception as e:
                    logger.debug(f"stock_info_global_emÂ§±Ë¥•: {e}")

            # 2. Ë¥¢ËÅîÁ§æÂÖ®ÁêÉËµÑËÆØ
            source_cfg = config.market_sources.get(NewsSourceType.CLS_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_cls)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("Ê†áÈ¢ò", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("ÂÜÖÂÆπ", ""))[:1000],
                                    "pub_time": str(row.get("ÂèëÂ∏ÉÊó•Êúü", "")) + " " + str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                    "source": source_cfg.name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"Ë¥¢ËÅîÁ§æÁîµÊä•: {count}Êù°")
                except Exception as e:
                    logger.debug(f"stock_info_global_clsÂ§±Ë¥•: {e}")

            # 3. ÂØåÈÄîÁâõÁâõ
            source_cfg = config.market_sources.get(NewsSourceType.FUTU_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_futu)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("Ê†áÈ¢ò", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("ÂÜÖÂÆπ", ""))[:1000],
                                    "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                    "source": source_cfg.name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                                    "url": str(row.get("ÈìæÊé•", ""))
                                })
                                count += 1
                        logger.info(f"ÂØåÈÄîÁâõÁâõ: {count}Êù°")
                except Exception as e:
                    logger.debug(f"stock_info_global_futuÂ§±Ë¥•: {e}")

            # 4. ÂêåËä±È°∫
            source_cfg = config.market_sources.get(NewsSourceType.THS_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_ths)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("Ê†áÈ¢ò", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("ÂÜÖÂÆπ", ""))[:1000],
                                    "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                    "source": source_cfg.name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                                    "url": str(row.get("ÈìæÊé•", ""))
                                })
                                count += 1
                        logger.info(f"ÂêåËä±È°∫: {count}Êù°")
                except Exception as e:
                    logger.debug(f"stock_info_global_thsÂ§±Ë¥•: {e}")

            # 5. Êñ∞Êµ™Ë¥¢Áªè - ÂàóÂêç: ['Êó∂Èó¥', 'ÂÜÖÂÆπ']
            source_cfg = config.market_sources.get(NewsSourceType.SINA_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_sina)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            content = str(row.get("ÂÜÖÂÆπ", ""))
                            if content:
                                # Êñ∞Êµ™Ë¥¢ÁªèÂè™ÊúâÂÜÖÂÆπÔºåÊ≤°ÊúâÊ†áÈ¢òÔºåÊà™ÂèñÂâç50Â≠ó‰Ωú‰∏∫Ê†áÈ¢ò
                                title = content[:50] + "..." if len(content) > 50 else content
                                news_list.append({
                                    "title": title,
                                    "content": content[:1000],
                                    "pub_time": str(row.get("Êó∂Èó¥", "")),
                                    "source": source_cfg.name,
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"Êñ∞Êµ™Ë¥¢Áªè: {count}Êù°")
                except Exception as e:
                    logger.debug(f"stock_info_global_sinaÂ§±Ë¥•: {e}")

            # 6. ÂæÆÂçöÁÉ≠ËÆÆ
            source_cfg = config.market_sources.get(NewsSourceType.WEIBO_HOT.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_js_weibo_report)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            stock_name = str(row.get("name", row.get("ËÇ°Á•®", "")))
                            rate = row.get("rate", row.get("Ê∂®Ë∑åÂπÖ", 0))
                            if stock_name:
                                # Ê†ºÂºèÂåñÊ∂®Ë∑åÂπÖ
                                try:
                                    rate_val = float(rate)
                                    rate_str = f"+{rate_val:.2f}%" if rate_val >= 0 else f"{rate_val:.2f}%"
                                except:
                                    rate_str = str(rate)
                                news_list.append({
                                    "title": f"[ÂæÆÂçöÁÉ≠ËÆÆ] {stock_name} {rate_str}",
                                    "content": f"ÂæÆÂçöËÇ°Á•®ÁÉ≠ËÆÆÊ¶úÔºåÂΩìÂâçÊ∂®Ë∑åÂπÖ: {rate_str}",
                                    "pub_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "source": source_cfg.name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"ÂæÆÂçöÁÉ≠ËÆÆ: {count}Êù°")
                except Exception as e:
                    logger.debug(f"stock_js_weibo_reportÂ§±Ë¥•: {e}")

            # 7. Ë¥¢ÁªèÊó©È§ê
            source_cfg = config.market_sources.get(NewsSourceType.CJZC.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_cjzc_em)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("Ê†áÈ¢ò", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("ÂÜÖÂÆπ", ""))[:1000],
                                    "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                    "source": source_cfg.name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"Ë¥¢ÁªèÊó©È§ê: {count}Êù°")
                except Exception as e:
                    logger.debug(f"stock_info_cjzc_emÂ§±Ë¥•: {e}")

            # 8. Êñ∞ÈóªËÅîÊí≠
            source_cfg = config.market_sources.get(NewsSourceType.CCTV.value)
            if source_cfg and source_cfg.enabled:
                try:
                    today = datetime.now().strftime('%Y%m%d')
                    df = await loop.run_in_executor(self._executor, lambda: ak.news_cctv(date=today))
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("title", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("content", ""))[:1000],
                                    "pub_time": str(row.get("date", today)),
                                    "source": source_cfg.name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"Êñ∞ÈóªËÅîÊí≠: {count}Êù°")
                except Exception as e:
                    logger.debug(f"news_cctvÂ§±Ë¥•: {e}")

            # 9. ÁôæÂ∫¶Ë¥¢Áªè - ÂàóÂêç: ['ÂõΩÂÆ∂', 'Êó∂Èó¥', 'Âú∞Âå∫', '‰∫ã‰ª∂', '‰ªäÂÄº', 'È¢ÑÊúü', 'ÂâçÂÄº', 'ÈáçË¶ÅÊÄß']
            source_cfg = config.market_sources.get(NewsSourceType.BAIDU.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.news_economic_baidu)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            event = str(row.get("‰∫ã‰ª∂", ""))
                            if event:
                                # ÊûÑÂª∫Ê†áÈ¢òÔºöÂú∞Âå∫ + ‰∫ã‰ª∂
                                country = str(row.get("ÂõΩÂÆ∂", ""))
                                region = str(row.get("Âú∞Âå∫", ""))
                                title = f"[{country}] {event}" if country else event
                                # ÊûÑÂª∫ÂÜÖÂÆπÔºö‰ªäÂÄº„ÄÅÈ¢ÑÊúü„ÄÅÂâçÂÄº
                                today_val = row.get("‰ªäÂÄº", "")
                                expect_val = row.get("È¢ÑÊúü", "")
                                prev_val = row.get("ÂâçÂÄº", "")
                                importance = row.get("ÈáçË¶ÅÊÄß", "")
                                content = f"‰ªäÂÄº: {today_val} | È¢ÑÊúü: {expect_val} | ÂâçÂÄº: {prev_val} | ÈáçË¶ÅÊÄß: {importance}"
                                news_list.append({
                                    "title": title,
                                    "content": content,
                                    "pub_time": str(row.get("Êó∂Èó¥", "")),
                                    "source": source_cfg.name,
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"ÁôæÂ∫¶Ë¥¢Áªè: {count}Êù°")
                except Exception as e:
                    logger.debug(f"news_economic_baiduÂ§±Ë¥•: {e}")

            # 10. Â∑®ÊΩÆÂ∏ÇÂú∫ÂÖ¨ÂëäÔºà‰∏çÂ∏¶‰∏™ËÇ°ÂèÇÊï∞Ôºâ
            source_cfg = config.market_sources.get(NewsSourceType.CNINFO_MARKET.value)
            if source_cfg and source_cfg.enabled:
                cninfo_news = await self._fetch_cninfo_market()
                news_list.extend(cninfo_news)

            # 11. Â∑®ÊΩÆÊñ∞ÈóªÊï∞ÊçÆÔºàp_info3030Ôºâ
            source_cfg = config.market_sources.get(NewsSourceType.CNINFO_NEWS.value)
            if source_cfg and source_cfg.enabled:
                cninfo_news_data = await self._fetch_cninfo_news(days_back=source_cfg.days_back)
                news_list.extend(cninfo_news_data)

            # 12. Â∑®ÊΩÆÁ†îÊä•ÊëòË¶ÅÔºàp_info3097_incÔºâ- VIPÊé•Âè£
            source_cfg = config.market_sources.get(NewsSourceType.CNINFO_RESEARCH.value)
            if source_cfg and source_cfg.enabled:
                research_data = await self._fetch_cninfo_research(limit=source_cfg.limit)
                news_list.extend(research_data)

            # 13. Â∑®ÊΩÆÈ´òÁÆ°ÂèòÂä®Ôºàp_stock2102Ôºâ
            source_cfg = config.market_sources.get(NewsSourceType.CNINFO_MANAGEMENT.value)
            if source_cfg and source_cfg.enabled:
                management_data = await self._fetch_cninfo_management(limit=source_cfg.limit)
                news_list.extend(management_data)

            # ÂØπÊâÄÊúâÊñ∞ÈóªËøõË°åÊÉÖÁª™ÂàÜÊûê
            if news_list and self._sentiment_engine:
                for news_item in news_list:
                    if not news_item.get('sentiment'):  # Âè™ÂàÜÊûêÊ≤°ÊúâÊÉÖÁª™ÁöÑÊñ∞Èóª
                        try:
                            title = news_item.get('title', '')
                            content = news_item.get('content', '')
                            sentiment_result = self._sentiment_engine.analyze(title, content)
                            news_item['sentiment'] = sentiment_result.get('sentiment', 'neutral')
                            news_item['sentiment_score'] = sentiment_result.get('score', 50)
                        except Exception as e:
                            news_item['sentiment'] = 'neutral'
                            news_item['sentiment_score'] = 50

            # ‰øùÂ≠òÂà∞Êï∞ÊçÆÂ∫ì
            if news_list:
                try:
                    from .news_storage import get_news_storage
                    storage = get_news_storage()
                    save_result = storage.save_news_batch(news_list)
                    logger.info(f"Êñ∞ÈóªÂ∑≤‰øùÂ≠òÂà∞Êï∞ÊçÆÂ∫ì: Êñ∞Â¢û{save_result['saved']}Êù°, Ë∑≥Ëøá{save_result['skipped']}Êù°")
                except Exception as e:
                    logger.warning(f"‰øùÂ≠òÊñ∞ÈóªÂà∞Êï∞ÊçÆÂ∫ìÂ§±Ë¥•: {e}")

            logger.info(f"Â∏ÇÂú∫Êñ∞ÈóªËé∑ÂèñÂÆåÊàêÔºåÂÖ± {len(news_list)} Êù°")
            return news_list

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂ∏ÇÂú∫Êñ∞ÈóªÂ§±Ë¥•: {e}")
            return []

    async def _fetch_cninfo_management(self, limit: int = 100) -> List[Dict]:
        """Ëé∑ÂèñÂ∑®ÊΩÆÈ´òÁÆ°ÂèòÂä®Ôºàp_stock2102Ôºâ"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("Â∑®ÊΩÆAPIÊú™ÈÖçÁΩÆÔºåË∑≥ËøáËé∑Âèñ")
                return []

            client = get_cninfo_api_client()
            news_list = []

            # Ëé∑ÂèñÊï∞ÊçÆÊ∫êÈÖçÁΩÆÂêçÁß∞
            source_cfg = self._config_manager.config.market_sources.get(NewsSourceType.CNINFO_MANAGEMENT.value)
            source_name = source_cfg.name if source_cfg else "Â∑®ÊΩÆÈ´òÁÆ°ÂèòÂä®"

            try:
                # Ëé∑ÂèñÁÉ≠Èó®ËÇ°Á•®ÁöÑÈ´òÁÆ°ÂèòÂä®‰ø°ÊÅØ
                hot_stocks = self._config_manager.config.hot_stocks[:20]  # ÂèñÂâç20Âè™ÁÉ≠Èó®ËÇ°Á•®
                if not hot_stocks:
                    hot_stocks = ["000001", "600519", "000858", "601318", "600036"]

                result = await client.get_management_personnel(hot_stocks, state=1)
                if result.get('success') and result.get('data'):
                    # ÊåâÂÖ¨ÂëäÊó•ÊúüÊéíÂ∫èÔºåÂèñÊúÄËøëÁöÑÂèòÂä®
                    data = result['data']
                    # ËøáÊª§Âá∫ÊúÄËøëÁöÑ‰ªªËÅåÂèòÂä®ÔºàÊúâÁ¶ªËÅåÊó•ÊúüÊàñÊúÄËøë‰ªªËÅåÁöÑÔºâ
                    recent_changes = []
                    for item in data:
                        declare_date = item.get('DECLAREDATE', '')
                        leave_date = item.get('F008D', '')
                        join_date = item.get('F007D', '')

                        # Â¶ÇÊûúÊúâÁ¶ªËÅåÊó•ÊúüÔºåËØ¥ÊòéÊòØÁ¶ªËÅåÂèòÂä®
                        if leave_date:
                            recent_changes.append({
                                'item': item,
                                'change_type': 'Á¶ªËÅå',
                                'date': leave_date
                            })
                        # Â¶ÇÊûú‰ªªËÅåÊó•ÊúüÂú®ÊúÄËøë30Â§©ÂÜÖÔºåËØ¥ÊòéÊòØÊñ∞‰ªªËÅå
                        elif join_date:
                            try:
                                from datetime import datetime
                                join_dt = datetime.strptime(str(join_date)[:10], '%Y-%m-%d')
                                if (datetime.now() - join_dt).days <= 30:
                                    recent_changes.append({
                                        'item': item,
                                        'change_type': '‰ªªËÅå',
                                        'date': join_date
                                    })
                            except:
                                pass

                    # ÂèñÊúÄËøëÁöÑÂèòÂä®
                    for change in recent_changes[:limit]:
                        item = change['item']
                        change_type = change['change_type']
                        stock_code = item.get('SECCODE', '')
                        stock_name = item.get('SECNAME', '')
                        org_name = item.get('ORGNAME', '')
                        person_name = item.get('F002V', '')
                        position = item.get('F009V', '')
                        join_date = item.get('F007D', '')
                        leave_date = item.get('F008D', '')
                        gender = item.get('F010V', '')
                        education = item.get('F011V', '')
                        resume = item.get('F019V', '')

                        if not person_name or not position:
                            continue

                        # ÊûÑÂª∫Ê†áÈ¢ò
                        if change_type == 'Á¶ªËÅå':
                            title = f"[È´òÁÆ°ÂèòÂä®] {stock_name}({stock_code}) {person_name} Á¶ª‰ªª{position}"
                        else:
                            title = f"[È´òÁÆ°ÂèòÂä®] {stock_name}({stock_code}) {person_name} Â∞±‰ªª{position}"

                        # ÊûÑÂª∫ÂÜÖÂÆπ
                        content_parts = [f"ÂÖ¨Âè∏: {org_name}"]
                        if join_date:
                            content_parts.append(f"‰ªªËÅåÊó•Êúü: {join_date}")
                        if leave_date:
                            content_parts.append(f"Á¶ªËÅåÊó•Êúü: {leave_date}")
                        if gender:
                            content_parts.append(f"ÊÄßÂà´: {gender}")
                        if education:
                            content_parts.append(f"Â≠¶ÂéÜ: {education}")
                        if resume:
                            content_parts.append(f"ÁÆÄÂéÜ: {resume[:200]}...")

                        news_list.append({
                            "title": title,
                            "content": " | ".join(content_parts),
                            "pub_time": change['date'],
                            "source": source_name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                            "url": "",
                            "importance": "high",
                            "urgency": "medium",
                            "related_stocks": [stock_code] if stock_code else []
                        })

                    logger.info(f"Â∑®ÊΩÆÈ´òÁÆ°ÂèòÂä®: {len(news_list)}Êù°")
            except Exception as e:
                logger.warning(f"Ëé∑ÂèñÂ∑®ÊΩÆÈ´òÁÆ°ÂèòÂä®Â§±Ë¥•: {e}")

            return news_list

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂ∑®ÊΩÆÈ´òÁÆ°ÂèòÂä®Â§±Ë¥•: {e}")
            return []

    async def _fetch_cninfo_news(self, days_back: int = 1, stock_code: str = '') -> List[Dict]:
        """Ëé∑ÂèñÂ∑®ÊΩÆÊñ∞ÈóªÊï∞ÊçÆÔºàp_info3030Ôºâ"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("Â∑®ÊΩÆAPIÊú™ÈÖçÁΩÆÔºåË∑≥ËøáËé∑Âèñ")
                return []

            client = get_cninfo_api_client()
            news_list = []

            # Ëé∑ÂèñÊï∞ÊçÆÊ∫êÈÖçÁΩÆÂêçÁß∞
            source_cfg = self._config_manager.config.market_sources.get(NewsSourceType.CNINFO_NEWS.value)
            source_name = source_cfg.name if source_cfg else "Â∑®ÊΩÆÊñ∞ÈóªÊï∞ÊçÆ(VIP)"

            try:
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=days_back-1)).strftime('%Y-%m-%d')

                result = await client.get_news_list(
                    stock_code=stock_code,
                    start_date=start_date,
                    end_date=end_date
                )
                if result.get('success') and result.get('data'):
                    for item in result['data']:
                        title = item.get('F004V', '')
                        if not title:
                            continue
                        pub_time = item.get('DECLAREDATE', '')
                        news_id = item.get('TEXTID', '')
                        sec_code = item.get('SECCODE', '')
                        keywords = item.get('F002V', '')
                        news_type = item.get('F003V', '')
                        author = item.get('F005V', '')

                        news_list.append({
                            "title": title,
                            "content": f"ÂÖ≥ÈîÆËØç: {keywords}" if keywords else "",
                            "pub_time": pub_time,
                            "source": source_name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                            "url": "",
                            "news_id": news_id,
                            "news_type": news_type,
                            "author": author,
                            "related_stocks": [sec_code] if sec_code else []
                        })
                    logger.info(f"Â∑®ÊΩÆÊñ∞ÈóªÊï∞ÊçÆ: {len(news_list)}Êù°")
            except Exception as e:
                logger.warning(f"Ëé∑ÂèñÂ∑®ÊΩÆÊñ∞ÈóªÊï∞ÊçÆÂ§±Ë¥•: {e}")

            return news_list

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂ∑®ÊΩÆÊñ∞ÈóªÊï∞ÊçÆÂ§±Ë¥•: {e}")
            return []

    async def _fetch_cninfo_research(self, limit: int = 500) -> List[Dict]:
        """Ëé∑ÂèñÂ∑®ÊΩÆÁ†îÊä•ÊëòË¶ÅÔºàp_info3097_incÔºâ"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("Â∑®ÊΩÆAPIÊú™ÈÖçÁΩÆÔºåË∑≥ËøáËé∑Âèñ")
                return []

            client = get_cninfo_api_client()
            news_list = []

            # Ëé∑ÂèñÊï∞ÊçÆÊ∫êÈÖçÁΩÆÂêçÁß∞
            source_cfg = self._config_manager.config.market_sources.get(NewsSourceType.CNINFO_RESEARCH.value)
            source_name = source_cfg.name if source_cfg else "Â∑®ÊΩÆÁ†îÊä•ÊëòË¶Å(VIP)"

            try:
                result = await client.get_research_report_summary(
                    object_id=0,
                    row_count=min(limit, 2000)
                )
                if result.get('success') and result.get('data'):
                    for item in result['data']:
                        title = item.get('F002V', '')
                        if not title:
                            continue
                        content = item.get('F003V', '')
                        pub_date = item.get('F001D', '')
                        sec_code = item.get('SECCODE', '')
                        sec_name = item.get('SECNAME', '')
                        institution = item.get('F004V', '')
                        report_date = item.get('F005D', '')
                        category = item.get('F007V', '')

                        news_list.append({
                            "title": f"[Á†îÊä•] {title}",
                            "content": content[:500] if content else f"Êú∫ÊûÑ: {institution}",
                            "pub_time": pub_date,
                            "source": source_name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                            "url": "",
                            "report_date": report_date,
                            "category": category,
                            "importance": "medium",
                            "related_stocks": [sec_code] if sec_code else []
                        })
                    logger.info(f"Â∑®ÊΩÆÁ†îÊä•ÊëòË¶Å: {len(news_list)}Êù°")
            except Exception as e:
                logger.warning(f"Ëé∑ÂèñÂ∑®ÊΩÆÁ†îÊä•ÊëòË¶ÅÂ§±Ë¥•: {e}")

            return news_list

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂ∑®ÊΩÆÁ†îÊä•ÊëòË¶ÅÂ§±Ë¥•: {e}")
            return []

    async def _fetch_cninfo_market(self) -> List[Dict]:
        """Ëé∑ÂèñÂ∑®ÊΩÆÂ∏ÇÂú∫ÂÖ¨ÂëäÔºà‰∏çÂ∏¶‰∏™ËÇ°ÂèÇÊï∞Ôºâ"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("Â∑®ÊΩÆAPIÊú™ÈÖçÁΩÆÔºåË∑≥ËøáËé∑Âèñ")
                return []

            client = get_cninfo_api_client()
            news_list = []
            config = self._config_manager.config.cninfo

            # Ëé∑ÂèñÊï∞ÊçÆÊ∫êÈÖçÁΩÆÂêçÁß∞
            market_source_cfg = self._config_manager.config.market_sources.get(NewsSourceType.CNINFO_MARKET.value)
            source_name = market_source_cfg.name if market_source_cfg else "Â∑®ÊΩÆÂ∏ÇÂú∫ÂÖ¨Âëä"

            # Ëé∑ÂèñÂÖ¨Âëä‰ø°ÊÅØ
            if config.announcement_enabled:
                try:
                    days_back = config.announcement_days_back
                    end_date = datetime.now().strftime('%Y-%m-%d')
                    start_date = (datetime.now() - timedelta(days=days_back-1)).strftime('%Y-%m-%d')

                    announcement_result = await client.get_announcement_info(
                        start_date=start_date,
                        end_date=end_date,
                        page_size=config.announcement_page_size
                    )
                    if announcement_result.get('success') and announcement_result.get('data'):
                        for item in announcement_result['data']:
                            title = item.get('F002V', '')
                            if not title:
                                continue
                            pub_date = item.get('F001D', '')
                            pdf_url = item.get('F003V', '')
                            stock_code = item.get('SECCODE', '')
                            stock_name = item.get('SECNAME', '')
                            market = item.get('F010V', '')
                            category = item.get('F006V', '')

                            importance = 'low'
                            urgency = 'low'
                            if any(kw in title for kw in ['‰∏öÁª©È¢ÑÂëä', '‰∏öÁª©Âø´Êä•', 'ÈáçÂ§ß', 'ÂÅúÁâå', 'Â§çÁâå', 'È£éÈô©ÊèêÁ§∫']):
                                importance = 'high'
                                urgency = 'high'
                            elif any(kw in title for kw in ['Âπ¥Êä•', 'Â≠£Êä•', '‰∏≠Êä•', 'ÂàÜÁ∫¢', 'Â¢ûÊåÅ', 'ÂáèÊåÅ']):
                                importance = 'medium'
                                urgency = 'medium'

                            news_list.append({
                                "title": f"[{stock_name or 'ÂÖ¨Âëä'}] {title}",
                                "content": f"ËØÅÂà∏‰ª£Á†Å: {stock_code} | Â∏ÇÂú∫: {market} | ÂàÜÁ±ª: {category}",
                                "pub_time": pub_date,
                                "source": source_name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                                "url": pdf_url,
                                "announcement_type": "announcement",
                                "importance": importance,
                                "urgency": urgency,
                                "related_stocks": [stock_code] if stock_code else []
                            })
                        logger.info(f"Â∑®ÊΩÆÂ∏ÇÂú∫ÂÖ¨Âëä: {len(news_list)}Êù°")
                except Exception as e:
                    logger.warning(f"Ëé∑ÂèñÂ∑®ÊΩÆÂÖ¨Âëä‰ø°ÊÅØÂ§±Ë¥•: {e}")

            # Ëé∑Âèñ‰∏äÂ∏ÇÁä∂ÊÄÅÂèòÂä®
            if config.status_change_enabled:
                try:
                    status_result = await client.get_listing_status_changes()
                    if status_result.get('success') and status_result.get('data'):
                        data = status_result['data'][:config.status_change_limit]
                        status_count = 0
                        for item in data:
                            stock_code = item.get('SECCODE', '')
                            stock_name = item.get('SECNAME', '')
                            org_name = item.get('ORGNAME', '')
                            change_date = item.get('VARYDATE', '')
                            status = item.get('F002V', '')
                            change_type = item.get('F006V', '')
                            reason = item.get('F004V', '')

                            if not stock_code or not change_type:
                                continue

                            urgency = 'medium'
                            if any(kw in str(change_type) for kw in ['ÈÄÄÂ∏Ç', 'ÊöÇÂÅú‰∏äÂ∏Ç', 'ÁªàÊ≠¢‰∏äÂ∏Ç']):
                                urgency = 'critical'
                            elif any(kw in str(change_type) for kw in ['ST', 'È£éÈô©Ë≠¶Á§∫', 'ÂÅúÁâå']):
                                urgency = 'high'

                            news_list.append({
                                "title": f"[‰∏äÂ∏ÇÁä∂ÊÄÅ] {stock_name}({stock_code}) {change_type}",
                                "content": f"ÂÖ¨Âè∏: {org_name} | Áä∂ÊÄÅ: {status} | ÂéüÂõ†: {reason or 'Êó†'}",
                                "pub_time": change_date,
                                "source": source_name,  # ‰ΩøÁî®ÈÖçÁΩÆ‰∏≠ÁöÑÂêçÁß∞
                                "url": "",
                                "announcement_type": "status_change",
                                "importance": "high" if urgency in ['critical', 'high'] else "medium",
                                "urgency": urgency,
                                "related_stocks": [stock_code] if stock_code else []
                            })
                            status_count += 1
                        logger.info(f"Â∑®ÊΩÆÁä∂ÊÄÅÂèòÂä®: {status_count}Êù°")
                except Exception as e:
                    logger.warning(f"Ëé∑Âèñ‰∏äÂ∏ÇÁä∂ÊÄÅÂèòÂä®Â§±Ë¥•: {e}")

            return news_list

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂ∑®ÊΩÆÂ∏ÇÂú∫ÂÖ¨ÂëäÂ§±Ë¥•: {e}")
            return []

    # ==================== ‰∏™ËÇ°Êñ∞ÈóªËé∑ÂèñÔºàÊô∫ËÉΩÂàÜÊûê/‰∏™ËÇ°ÁõëÊéßÔºâ====================

    async def fetch_stock_news(self, stock_code: str, stock_name: str = "") -> List[Dict]:
        """
        Ëé∑Âèñ‰∏™ËÇ°Êñ∞ÈóªÔºàÁî®‰∫éÊô∫ËÉΩÂàÜÊûê/‰∏™ËÇ°ÁõëÊéßÔºâ
        Ë∞ÉÁî®‰∏™ËÇ°Êñ∞ÈóªÊé•Âè£ÔºåËé∑ÂèñÁâπÂÆöËÇ°Á•®Áõ∏ÂÖ≥Êñ∞Èóª

        ÂåÖÂê´Êé•Âè£Ôºö
        1. stock_news_em - ‰∏úÊñπË¥¢ÂØå‰∏™ËÇ°Êñ∞Èóª
        2. Â∑®ÊΩÆ‰∏™ËÇ°ÂÖ¨ÂëäÔºàÂ∏¶‰∏™ËÇ°ÂèÇÊï∞Ôºâ

        Args:
            stock_code: ËÇ°Á•®‰ª£Á†ÅÔºà6‰ΩçÊï∞Â≠óÔºåÂ¶Ç 600519Ôºâ
            stock_name: ËÇ°Á•®ÂêçÁß∞ÔºàÂèØÈÄâÔºåÁî®‰∫éÊó•ÂøóÔºâ
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []
            config = self._config_manager.config

            # Ê∏ÖÁêÜËÇ°Á•®‰ª£Á†Å
            clean_code = stock_code.replace('.SH', '').replace('.SZ', '').replace('.BJ', '')

            # 1. ‰∏úÊñπË¥¢ÂØå‰∏™ËÇ°Êñ∞Èóª
            source_cfg = config.stock_sources.get(NewsSourceType.STOCK_NEWS_EM.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(
                        self._executor,
                        lambda: ak.stock_news_em(symbol=clean_code)
                    )
                    if df is not None and not df.empty:
                        limit = source_cfg.limit if source_cfg.limit > 0 else len(df)
                        for _, row in df.head(limit).iterrows():
                            title = str(row.get("Êñ∞ÈóªÊ†áÈ¢ò", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("Êñ∞ÈóªÂÜÖÂÆπ", ""))[:1000],
                                    "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                    "source": "‰∏úË¥¢‰∏™ËÇ°",
                                    "url": str(row.get("Êñ∞ÈóªÈìæÊé•", "")),
                                    "related_stocks": [clean_code]
                                })
                        logger.info(f"‰∏úË¥¢‰∏™ËÇ°Êñ∞Èóª({stock_name or clean_code}): {len(news_list)}Êù°")
                except Exception as e:
                    logger.debug(f"stock_news_em({clean_code})Â§±Ë¥•: {e}")

            # 2. Â∑®ÊΩÆ‰∏™ËÇ°ÂÖ¨Âëä
            source_cfg = config.stock_sources.get(NewsSourceType.CNINFO_STOCK.value)
            if source_cfg and source_cfg.enabled:
                cninfo_news = await self._fetch_cninfo_stock(clean_code, source_cfg.days_back)
                news_list.extend(cninfo_news)

            # 3. Â∑®ÊΩÆ‰∏™ËÇ°Êñ∞ÈóªÔºàp_info3030Â∏¶ËÇ°Á•®‰ª£Á†ÅÔºâ
            source_cfg = config.stock_sources.get(NewsSourceType.CNINFO_STOCK_NEWS.value)
            if source_cfg and source_cfg.enabled:
                cninfo_stock_news = await self._fetch_cninfo_news(
                    days_back=source_cfg.days_back,
                    stock_code=clean_code
                )
                news_list.extend(cninfo_stock_news)

            # ÂØπÊâÄÊúâÊñ∞ÈóªËøõË°åÊÉÖÁª™ÂàÜÊûê
            if news_list and self._sentiment_engine:
                for news_item in news_list:
                    if not news_item.get('sentiment'):
                        try:
                            title = news_item.get('title', '')
                            content = news_item.get('content', '')
                            sentiment_result = self._sentiment_engine.analyze(title, content)
                            news_item['sentiment'] = sentiment_result.get('sentiment', 'neutral')
                            news_item['sentiment_score'] = sentiment_result.get('score', 50)
                        except Exception as e:
                            news_item['sentiment'] = 'neutral'
                            news_item['sentiment_score'] = 50

            logger.info(f"‰∏™ËÇ°Êñ∞ÈóªËé∑ÂèñÂÆåÊàê({stock_name or clean_code})ÔºåÂÖ± {len(news_list)} Êù°")
            return news_list

        except Exception as e:
            logger.error(f"Ëé∑Âèñ‰∏™ËÇ°Êñ∞ÈóªÂ§±Ë¥•({stock_code}): {e}")
            return []

    async def _fetch_cninfo_stock(self, stock_code: str, days_back: int = 30) -> List[Dict]:
        """Ëé∑ÂèñÂ∑®ÊΩÆ‰∏™ËÇ°ÂÖ¨Âëä"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("Â∑®ÊΩÆAPIÊú™ÈÖçÁΩÆÔºåË∑≥ËøáËé∑Âèñ")
                return []

            client = get_cninfo_api_client()
            news_list = []

            try:
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')

                announcement_result = await client.get_announcement_info(
                    stock_code=stock_code,
                    start_date=start_date,
                    end_date=end_date,
                    page_size=100
                )
                if announcement_result.get('success') and announcement_result.get('data'):
                    for item in announcement_result['data']:
                        title = item.get('F002V', '')
                        if not title:
                            continue
                        pub_date = item.get('F001D', '')
                        pdf_url = item.get('F003V', '')
                        stock_name = item.get('SECNAME', '')
                        category = item.get('F006V', '')

                        importance = 'low'
                        urgency = 'low'
                        if any(kw in title for kw in ['‰∏öÁª©È¢ÑÂëä', '‰∏öÁª©Âø´Êä•', 'ÈáçÂ§ß', 'ÂÅúÁâå', 'Â§çÁâå', 'È£éÈô©ÊèêÁ§∫']):
                            importance = 'high'
                            urgency = 'high'
                        elif any(kw in title for kw in ['Âπ¥Êä•', 'Â≠£Êä•', '‰∏≠Êä•', 'ÂàÜÁ∫¢', 'Â¢ûÊåÅ', 'ÂáèÊåÅ']):
                            importance = 'medium'
                            urgency = 'medium'

                        news_list.append({
                            "title": f"[{stock_name or 'ÂÖ¨Âëä'}] {title}",
                            "content": f"ÂàÜÁ±ª: {category}",
                            "pub_time": pub_date,
                            "source": "Â∑®ÊΩÆ‰∏™ËÇ°ÂÖ¨Âëä",
                            "url": pdf_url,
                            "announcement_type": "stock_announcement",
                            "importance": importance,
                            "urgency": urgency,
                            "related_stocks": [stock_code]
                        })
                    logger.info(f"Â∑®ÊΩÆ‰∏™ËÇ°ÂÖ¨Âëä({stock_code}): {len(news_list)}Êù°")
            except Exception as e:
                logger.warning(f"Ëé∑ÂèñÂ∑®ÊΩÆ‰∏™ËÇ°ÂÖ¨ÂëäÂ§±Ë¥•({stock_code}): {e}")

            return news_list

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂ∑®ÊΩÆ‰∏™ËÇ°ÂÖ¨ÂëäÂ§±Ë¥•({stock_code}): {e}")
            return []

    async def fetch_hot_stocks_news(self) -> List[Dict]:
        """
        Ëé∑ÂèñÁÉ≠Èó®ËÇ°Á•®Êñ∞ÈóªÔºàÁî®‰∫éÂ∏ÇÂú∫Êñ∞Èóª‰∏≠Ë°•ÂÖÖ‰∏™ËÇ°Êñ∞ÈóªÔºâ
        ‰ªéÈÖçÁΩÆÁöÑÁÉ≠Èó®ËÇ°Á•®ÂàóË°®‰∏≠Ëé∑ÂèñÊñ∞Èóª
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []
            config = self._config_manager.config

            hot_stocks = config.hot_stocks
            if not hot_stocks:
                return []

            source_cfg = config.stock_sources.get(NewsSourceType.STOCK_NEWS_EM.value)
            if not source_cfg or not source_cfg.enabled:
                return []

            limit_per_stock = source_cfg.limit if source_cfg.limit > 0 else 20

            for symbol in hot_stocks:
                try:
                    df = await loop.run_in_executor(
                        self._executor,
                        lambda s=symbol: ak.stock_news_em(symbol=s)
                    )
                    if df is not None and not df.empty:
                        for _, row in df.head(limit_per_stock).iterrows():
                            title = str(row.get("Êñ∞ÈóªÊ†áÈ¢ò", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("Êñ∞ÈóªÂÜÖÂÆπ", ""))[:1000],
                                    "pub_time": str(row.get("ÂèëÂ∏ÉÊó∂Èó¥", "")),
                                    "source": "‰∏úË¥¢‰∏™ËÇ°",
                                    "url": str(row.get("Êñ∞ÈóªÈìæÊé•", "")),
                                    "related_stocks": [symbol]
                                })
                except Exception as e:
                    logger.debug(f"stock_news_em({symbol})Â§±Ë¥•: {e}")
                    continue

            logger.info(f"ÁÉ≠Èó®ËÇ°Á•®Êñ∞Èóª: {len(news_list)}Êù° (Êù•Ëá™{len(hot_stocks)}Âè™ËÇ°Á•®)")
            return news_list

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÁÉ≠Èó®ËÇ°Á•®Êñ∞ÈóªÂ§±Ë¥•: {e}")
            return []

    # ==================== ÈÖçÁΩÆÁÆ°ÁêÜ ====================

    def get_news_config(self) -> Dict:
        """Ëé∑ÂèñÊñ∞ÈóªÈÖçÁΩÆ"""
        return self._config_manager.get_config()

    def update_news_config(self, data: Dict) -> bool:
        """Êõ¥Êñ∞Êñ∞ÈóªÈÖçÁΩÆ"""
        return self._config_manager.update_config(data)

    def update_source_config(self, source_type: str, updates: Dict) -> bool:
        """Êõ¥Êñ∞Âçï‰∏™Êï∞ÊçÆÊ∫êÈÖçÁΩÆ"""
        return self._config_manager.update_source_config(source_type, updates)

    def update_cninfo_config(self, updates: Dict) -> bool:
        """Êõ¥Êñ∞Â∑®ÊΩÆÈÖçÁΩÆ"""
        return self._config_manager.update_cninfo_config(updates)

    def update_hot_stocks(self, stocks: List[str]) -> bool:
        """Êõ¥Êñ∞ÁÉ≠Èó®ËÇ°Á•®ÂàóË°®"""
        return self._config_manager.update_hot_stocks(stocks)

_monitor_center = None

def get_news_monitor_center() -> NewsMonitorCenter:
    global _monitor_center
    if _monitor_center is None:
        _monitor_center = NewsMonitorCenter()
    return _monitor_center
