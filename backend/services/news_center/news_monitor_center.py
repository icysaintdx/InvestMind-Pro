# -*- coding: utf-8 -*-
"""
æ–°é—»ç›‘æ§ä¸­å¿ƒ
æ”¯æŒä¸¤ç§ä¸šåŠ¡åœºæ™¯ï¼š
1. å¸‚åœºæ–°é—»ï¼ˆæ–°é—»ä¸­å¿ƒ/å®æ—¶æ–°é—»æµï¼‰- ä¸å¸¦ä¸ªè‚¡å‚æ•°ï¼Œè·å–å…¨å¸‚åœºæ–°é—»
2. ä¸ªè‚¡æ–°é—»ï¼ˆæ™ºèƒ½åˆ†æ/ä¸ªè‚¡ç›‘æ§ï¼‰- å¸¦ä¸ªè‚¡å‚æ•°ï¼Œè·å–ç‰¹å®šè‚¡ç¥¨ç›¸å…³æ–°é—»
"""
import asyncio
import logging
import threading
import time
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass
from enum import Enum

from .news_cache import NewsCache, CachedNews, get_news_cache
from .stock_relation_analyzer import StockRelationAnalyzer, get_stock_relation_analyzer
from .impact_assessor import ImpactAssessor, get_impact_assessor
from .news_config import get_news_config_manager, NewsSourceType

logger = logging.getLogger(__name__)

# WebSocket æ¨é€å‡½æ•° (å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–)
_ws_notify_news = None
_ws_notify_urgent = None

def _get_ws_notifiers():
    global _ws_notify_news, _ws_notify_urgent
    if _ws_notify_news is None:
        try:
            from backend.api.websocket_api import notify_news_update, notify_urgent_news
            _ws_notify_news = notify_news_update
            _ws_notify_urgent = notify_urgent_news
        except Exception as e:
            logger.warning(f"Failed to import WebSocket notifiers: {e}")
    return _ws_notify_news, _ws_notify_urgent

class DataSourceType(str, Enum):
    CLS = "cls"
    EASTMONEY = "eastmoney"
    SINA = "sina"
    CNINFO = "cninfo"
    BAIDU = "baidu"
    CCTV = "cctv"

@dataclass
class DataSourceConfig:
    name: str
    source_type: DataSourceType
    interval: int
    enabled: bool = True
    priority: int = 1
    last_fetch: str = ""
    fetch_count: int = 0
    error_count: int = 0

class NewsMonitorCenter:
    """
    æ–°é—»ç›‘æ§ä¸­å¿ƒ

    ä¸šåŠ¡åœºæ™¯åŒºåˆ†ï¼š
    - fetch_market_news(): ç”¨äºæ–°é—»ä¸­å¿ƒ/å®æ—¶æ–°é—»æµï¼Œè·å–å…¨å¸‚åœºæ–°é—»ï¼Œä¸è°ƒç”¨ä¸ªè‚¡æ¥å£
    - fetch_stock_news(stock_code): ç”¨äºæ™ºèƒ½åˆ†æ/ä¸ªè‚¡ç›‘æ§ï¼Œè·å–ç‰¹å®šè‚¡ç¥¨æ–°é—»
    """
    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._initialized = False
            return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self._initialized = True
        self._cache = get_news_cache()
        self._stock_analyzer = get_stock_relation_analyzer()
        self._impact_assessor = get_impact_assessor()
        self._sentiment_engine = None
        self._config_manager = get_news_config_manager()
        self._init_sentiment_engine()
        self._sources: Dict[str, DataSourceConfig] = {
            "cls": DataSourceConfig("è´¢è”ç¤¾ç”µæŠ¥", DataSourceType.CLS, 30, priority=10),
            "eastmoney": DataSourceConfig("ä¸œæ–¹è´¢å¯Œ", DataSourceType.EASTMONEY, 60, priority=8),
            "sina": DataSourceConfig("æ–°æµªè´¢ç»", DataSourceType.SINA, 90, priority=7),
            "cninfo": DataSourceConfig("å·¨æ½®å…¬å‘Š", DataSourceType.CNINFO, 300, priority=6),
        }
        self._running = False
        self._executor: Optional[ThreadPoolExecutor] = None
        self._fetch_tasks: Dict[str, asyncio.Task] = {}
        self._on_new_news: List[Callable] = []
        self._on_urgent_news: List[Callable] = []
        self._stats = {"total_fetched": 0, "total_processed": 0, "total_duplicates": 0, "start_time": None, "last_fetch_time": None}
        logger.info("NewsMonitorCenter initialized with config manager")
    
    def _init_sentiment_engine(self):
        try:
            from backend.dataflows.news.sentiment_engine import get_sentiment_engine
            self._sentiment_engine = get_sentiment_engine()
        except Exception as e:
            logger.warning(f"Failed to load sentiment engine: {e}")
    
    async def start(self):
        if self._running:
            return
        self._running = True
        self._stats["start_time"] = datetime.now().isoformat()
        # å¢åŠ çº¿ç¨‹æ± å¤§å°ä»¥é¿å…é˜»å¡
        self._executor = ThreadPoolExecutor(max_workers=8, thread_name_prefix="news_")
        for source_id, config in self._sources.items():
            if config.enabled:
                task = asyncio.create_task(self._fetch_loop(source_id))
                self._fetch_tasks[source_id] = task
        logger.info(f"NewsMonitorCenter started with {len(self._fetch_tasks)} sources")
    
    async def stop(self):
        self._running = False
        for task in self._fetch_tasks.values():
            task.cancel()
        self._fetch_tasks.clear()
        if self._executor:
            self._executor.shutdown(wait=False)
            self._executor = None
        self._cache.save_to_file()
        logger.info("NewsMonitorCenter stopped")
    
    async def _fetch_loop(self, source_id: str):
        config = self._sources.get(source_id)
        if not config:
            return
        while self._running:
            try:
                await self._fetch_source(source_id)
                config.last_fetch = datetime.now().isoformat()
                config.fetch_count += 1
            except Exception as e:
                config.error_count += 1
                logger.error(f"Fetch error for {source_id}: {e}")
            await asyncio.sleep(config.interval)

    async def _fetch_source(self, source_id: str):
        config = self._sources.get(source_id)
        if not config:
            return
        news_list = []
        try:
            if config.source_type == DataSourceType.CLS:
                news_list = await self._fetch_cls()
            elif config.source_type == DataSourceType.EASTMONEY:
                news_list = await self._fetch_eastmoney()
            elif config.source_type == DataSourceType.SINA:
                news_list = await self._fetch_sina()
            elif config.source_type == DataSourceType.CNINFO:
                news_list = await self._fetch_cninfo()
        except Exception as e:
            logger.error(f"Fetch {source_id} failed: {e}")
            return
        if news_list:
            await self._process_news(news_list, source_id)
    
    async def _fetch_cls(self) -> List[Dict]:
        """è·å–è´¢è”ç¤¾ç”µæŠ¥"""
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []

            # è´¢è”ç¤¾å…¨çƒèµ„è®¯ stock_info_global_cls
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_cls)
                if df is not None and not df.empty:
                    for _, row in df.iterrows():
                        title = str(row.get("æ ‡é¢˜", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("å†…å®¹", ""))[:1000],
                                "pub_time": str(row.get("å‘å¸ƒæ—¥æœŸ", "")) + " " + str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                "source": "è´¢è”ç¤¾",
                                "url": ""
                            })
                    logger.info(f"è´¢è”ç¤¾ç”µæŠ¥è·å–: {len(news_list)}æ¡")
            except Exception as e:
                logger.debug(f"è´¢è”ç¤¾å¤±è´¥: {e}")

            return news_list
        except Exception as e:
            logger.error(f"Fetch CLS failed: {e}")
            return []

    async def _fetch_eastmoney(self) -> List[Dict]:
        """
        è·å–ä¸œæ–¹è´¢å¯Œæ–°é—» - åŒ…å«å¤šä¸ªæ¥å£:
        1. stock_info_global_em - ä¸œæ–¹è´¢å¯Œå…¨çƒèµ„è®¯
        2. stock_news_em - ä¸ªè‚¡æ–°é—»(å¤šåªè‚¡ç¥¨)
        3. stock_info_cjzc_em - è´¢ç»æ—©é¤
        4. stock_info_global_futu - å¯Œé€”ç‰›ç‰›
        5. stock_info_global_ths - åŒèŠ±é¡º
        6. stock_info_global_sina - æ–°æµªè´¢ç»
        7. stock_js_weibo_report - å¾®åšçƒ­è®®
        8. news_cctv - æ–°é—»è”æ’­
        9. news_economic_baidu - ç™¾åº¦è´¢ç»
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []

            # 1. ä¸œæ–¹è´¢å¯Œå…¨çƒèµ„è®¯ stock_info_global_em
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_em)
                if df is not None and not df.empty:
                    for _, row in df.iterrows():
                        title = str(row.get("æ ‡é¢˜", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("æ‘˜è¦", row.get("å†…å®¹", "")))[:1000],
                                "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                "source": "ä¸œæ–¹è´¢å¯Œ",
                                "url": str(row.get("é“¾æ¥", ""))
                            })
                    logger.info(f"ä¸œæ–¹è´¢å¯Œå…¨çƒèµ„è®¯: {len(news_list)}æ¡")
            except Exception as e:
                logger.debug(f"stock_info_global_emå¤±è´¥: {e}")

            # 2. ä¸ªè‚¡æ–°é—» stock_news_em - å¤šåªçƒ­é—¨è‚¡ç¥¨
            hot_stocks = [
                "000001", "600519", "000858", "601318", "600036", "000333", "002594", "300750",
                "600000", "601166", "000002", "600030", "601398", "600016", "601288", "000651",
                "600276", "000725", "601012", "600887", "000568", "002415", "600309", "601888",
                "002304", "000063", "601601", "600900", "000100", "002475"
            ]
            stock_news_count = 0
            for symbol in hot_stocks:
                try:
                    df = await loop.run_in_executor(self._executor, lambda s=symbol: ak.stock_news_em(symbol=s))
                    if df is not None and not df.empty:
                        for _, row in df.iterrows():
                            title = str(row.get("æ–°é—»æ ‡é¢˜", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("æ–°é—»å†…å®¹", ""))[:1000],
                                    "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                    "source": f"ä¸œè´¢ä¸ªè‚¡",
                                    "url": str(row.get("æ–°é—»é“¾æ¥", ""))
                                })
                                stock_news_count += 1
                except Exception as e:
                    logger.debug(f"stock_news_em({symbol})å¤±è´¥: {e}")
                    continue
            if stock_news_count > 0:
                logger.info(f"ä¸œè´¢ä¸ªè‚¡æ–°é—»: {stock_news_count}æ¡")

            # 3. è´¢ç»æ—©é¤ stock_info_cjzc_em
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_cjzc_em)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("æ ‡é¢˜", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("å†…å®¹", ""))[:1000],
                                "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                "source": "è´¢ç»æ—©é¤",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"è´¢ç»æ—©é¤: {count}æ¡")
            except Exception as e:
                logger.debug(f"stock_info_cjzc_emå¤±è´¥: {e}")

            # 4. å¯Œé€”ç‰›ç‰› stock_info_global_futu
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_futu)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("æ ‡é¢˜", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("å†…å®¹", ""))[:1000],
                                "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                "source": "å¯Œé€”ç‰›ç‰›",
                                "url": str(row.get("é“¾æ¥", ""))
                            })
                            count += 1
                    logger.info(f"å¯Œé€”ç‰›ç‰›: {count}æ¡")
            except Exception as e:
                logger.debug(f"stock_info_global_futuå¤±è´¥: {e}")

            # 5. åŒèŠ±é¡º stock_info_global_ths
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_ths)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("æ ‡é¢˜", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("å†…å®¹", ""))[:1000],
                                "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                "source": "åŒèŠ±é¡º",
                                "url": str(row.get("é“¾æ¥", ""))
                            })
                            count += 1
                    logger.info(f"åŒèŠ±é¡º: {count}æ¡")
            except Exception as e:
                logger.debug(f"stock_info_global_thså¤±è´¥: {e}")

            # 6. æ–°æµªè´¢ç» stock_info_global_sina - åˆ—å: ['æ—¶é—´', 'å†…å®¹']
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_info_global_sina)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        # æ–°æµªè´¢ç»è¿”å›çš„åˆ—æ˜¯ ['æ—¶é—´', 'å†…å®¹']ï¼Œæ²¡æœ‰æ ‡é¢˜å­—æ®µ
                        content = str(row.get("å†…å®¹", ""))
                        if content:
                            # ä½¿ç”¨å†…å®¹å‰50å­—ç¬¦ä½œä¸ºæ ‡é¢˜
                            title = content[:50] + "..." if len(content) > 50 else content
                            news_list.append({
                                "title": title,
                                "content": content[:1000],
                                "pub_time": str(row.get("æ—¶é—´", "")),
                                "source": "æ–°æµªè´¢ç»",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"æ–°æµªè´¢ç»: {count}æ¡")
            except Exception as e:
                logger.debug(f"stock_info_global_sinaå¤±è´¥: {e}")

            # 7. å¾®åšçƒ­è®® stock_js_weibo_report
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_js_weibo_report)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        # å¾®åšçƒ­è®®æ ¼å¼: name(è‚¡ç¥¨åç§°), rate(æ¶¨è·Œå¹…)
                        stock_name = str(row.get("name", row.get("è‚¡ç¥¨", "")))
                        rate = row.get("rate", row.get("æ¶¨è·Œå¹…", 0))
                        if stock_name:
                            # æ ¼å¼åŒ–æ¶¨è·Œå¹…
                            try:
                                rate_val = float(rate)
                                rate_str = f"+{rate_val:.2f}%" if rate_val >= 0 else f"{rate_val:.2f}%"
                            except:
                                rate_str = str(rate)
                            news_list.append({
                                "title": f"[å¾®åšçƒ­è®®] {stock_name} {rate_str}",
                                "content": f"å¾®åšè‚¡ç¥¨çƒ­è®®æ¦œï¼Œå½“å‰æ¶¨è·Œå¹…: {rate_str}",
                                "pub_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "source": "å¾®åšçƒ­è®®",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"å¾®åšçƒ­è®®: {count}æ¡")
            except Exception as e:
                logger.debug(f"stock_js_weibo_reportå¤±è´¥: {e}")

            # 8. æ–°é—»è”æ’­ news_cctv
            try:
                today = datetime.now().strftime('%Y%m%d')
                df = await loop.run_in_executor(self._executor, lambda: ak.news_cctv(date=today))
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("title", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("content", ""))[:1000],
                                "pub_time": str(row.get("date", today)),
                                "source": "æ–°é—»è”æ’­",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"æ–°é—»è”æ’­: {count}æ¡")
            except Exception as e:
                logger.debug(f"news_cctvå¤±è´¥: {e}")

            # 9. ç™¾åº¦è´¢ç» news_economic_baidu - åˆ—å: ['å›½å®¶', 'æ—¶é—´', 'åœ°åŒº', 'äº‹ä»¶', 'ä»Šå€¼', 'é¢„æœŸ', 'å‰å€¼', 'é‡è¦æ€§']
            try:
                df = await loop.run_in_executor(self._executor, ak.news_economic_baidu)
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        # ç™¾åº¦è´¢ç»è¿”å›çš„æ˜¯ç»æµæ—¥å†æ•°æ®ï¼Œä½¿ç”¨'äº‹ä»¶'ä½œä¸ºæ ‡é¢˜
                        event = str(row.get("äº‹ä»¶", ""))
                        if event:
                            country = str(row.get("å›½å®¶", ""))
                            title = f"[{country}] {event}" if country else event
                            # ç»„åˆä»Šå€¼/é¢„æœŸ/å‰å€¼/é‡è¦æ€§ä½œä¸ºå†…å®¹
                            today_val = row.get("ä»Šå€¼", "")
                            expect_val = row.get("é¢„æœŸ", "")
                            prev_val = row.get("å‰å€¼", "")
                            importance = row.get("é‡è¦æ€§", "")
                            content = f"ä»Šå€¼: {today_val} | é¢„æœŸ: {expect_val} | å‰å€¼: {prev_val} | é‡è¦æ€§: {importance}"
                            news_list.append({
                                "title": title,
                                "content": content,
                                "pub_time": str(row.get("æ—¶é—´", "")),
                                "source": "ç™¾åº¦è´¢ç»",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"ç™¾åº¦è´¢ç»: {count}æ¡")
            except Exception as e:
                logger.debug(f"news_economic_baiduå¤±è´¥: {e}")

            logger.info(f"ä¸œæ–¹è´¢å¯Œæºæ€»è®¡: {len(news_list)}æ¡")
            return news_list
        except Exception as e:
            logger.error(f"Fetch eastmoney failed: {e}")
            return []

    async def _fetch_sina(self) -> List[Dict]:
        """
        è·å–æ–°æµªè´¢ç»æ–°é—» - åŒ…å«:
        1. æ›´å¤šä¸ªè‚¡æ–°é—»
        2. ä¸œæ–¹è´¢å¯Œå…¬å‘Š
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []

            # 1. æ›´å¤šä¸ªè‚¡æ–°é—»
            more_stocks = [
                "600519", "000858", "601318", "000001", "600036",
                "601166", "000002", "600030", "601398", "600016",
                "601288", "000651", "600276", "000725", "601012",
                "300059", "002230", "600104", "000538", "002352"
            ]
            stock_news_count = 0
            for symbol in more_stocks:
                try:
                    df = await loop.run_in_executor(self._executor, lambda s=symbol: ak.stock_news_em(symbol=s))
                    if df is not None and not df.empty:
                        for _, row in df.iterrows():
                            title = str(row.get("æ–°é—»æ ‡é¢˜", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("æ–°é—»å†…å®¹", ""))[:1000],
                                    "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                    "source": f"æ–°æµªä¸ªè‚¡",
                                    "url": str(row.get("æ–°é—»é“¾æ¥", ""))
                                })
                                stock_news_count += 1
                except Exception as e:
                    logger.debug(f"æ–°æµªä¸ªè‚¡({symbol})å¤±è´¥: {e}")
                    continue
            if stock_news_count > 0:
                logger.info(f"æ–°æµªä¸ªè‚¡æ–°é—»: {stock_news_count}æ¡")

            # 2. ä¸œæ–¹è´¢å¯Œå…¬å‘Š (ä½œä¸ºæ–°æµªæºçš„è¡¥å……)
            try:
                # å°è¯•è·å–å…¬å‘Šæ•°æ®
                df = await loop.run_in_executor(self._executor, lambda: ak.stock_notice_report(symbol="å…¨éƒ¨", date="20241230"))
                if df is not None and not df.empty:
                    count = 0
                    for _, row in df.iterrows():
                        title = str(row.get("å…¬å‘Šæ ‡é¢˜", row.get("æ ‡é¢˜", "")))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("å…¬å‘Šå†…å®¹", ""))[:1000],
                                "pub_time": str(row.get("å…¬å‘Šæ—¥æœŸ", "")),
                                "source": "ä¸œè´¢å…¬å‘Š",
                                "url": ""
                            })
                            count += 1
                    logger.info(f"ä¸œè´¢å…¬å‘Š: {count}æ¡")
            except Exception as e:
                logger.debug(f"ä¸œè´¢å…¬å‘Šå¤±è´¥: {e}")

            logger.info(f"æ–°æµªè´¢ç»æºæ€»è®¡: {len(news_list)}æ¡")
            return news_list
        except Exception as e:
            logger.error(f"Fetch sina failed: {e}")
            return []

    async def _fetch_eastmoney_global(self) -> List[Dict]:
        """è·å–ä¸œè´¢å…¨çƒèµ„è®¯ - å·²åœ¨ _fetch_eastmoney ä¸­å®ç°ï¼Œè¿™é‡Œä½œä¸ºè¡¥å……"""
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []

            # æ–°æµªè´¢ç»æ–°é—»
            try:
                df = await loop.run_in_executor(self._executor, ak.stock_news_em, "000001")
                if df is not None and not df.empty:
                    for _, row in df.iterrows():
                        title = str(row.get("æ–°é—»æ ‡é¢˜", ""))
                        if title:
                            news_list.append({
                                "title": title,
                                "content": str(row.get("æ–°é—»å†…å®¹", ""))[:1000],
                                "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                "source": "ä¸œè´¢å…¨çƒ",
                                "url": str(row.get("æ–°é—»é“¾æ¥", ""))
                            })
                    logger.info(f"ä¸œè´¢å…¨çƒè·å–: {len(news_list)}æ¡")
            except Exception as e:
                logger.debug(f"ä¸œè´¢å…¨çƒè·å–å¤±è´¥: {e}")

            return news_list
        except Exception as e:
            logger.error(f"Fetch eastmoney global failed: {e}")
            return []

    async def _fetch_cninfo(self) -> List[Dict]:
        """è·å–å·¨æ½®èµ„è®¯ç½‘æ•°æ®ï¼ˆä½¿ç”¨å®˜æ–¹API - å…è´¹æ¥å£ï¼‰"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            # æ£€æŸ¥æ˜¯å¦é…ç½®äº†å·¨æ½®API
            if not CninfoConfig.is_configured():
                logger.debug("å·¨æ½®APIæœªé…ç½®ï¼Œè·³è¿‡è·å–")
                return []

            client = get_cninfo_api_client()
            news_list = []

            # 1. è·å–æœ€æ–°å…¬å‘Šä¿¡æ¯ (p_info3015) - å…è´¹å¯ç”¨
            try:
                # è·å–å½“å¤©çš„å…¬å‘Š
                today = datetime.now().strftime('%Y-%m-%d')
                announcement_result = await client.get_announcement_info(
                    start_date=today,
                    end_date=today,
                    page_size=1000
                )
                if announcement_result.get('success') and announcement_result.get('data'):
                    for item in announcement_result['data']:  # ä¸é™åˆ¶
                        title = item.get('F002V', '')  # å…¬å‘Šæ ‡é¢˜
                        if not title:
                            continue
                        pub_date = item.get('F001D', '')  # å…¬å‘Šæ—¥æœŸ
                        pdf_url = item.get('F003V', '')  # PDFåœ°å€
                        stock_code = item.get('SECCODE', '')
                        stock_name = item.get('SECNAME', '')
                        market = item.get('F010V', '')  # å¸‚åœºåç§°
                        category = item.get('F006V', '')  # ä¿¡æ¯åˆ†ç±»

                        # åˆ¤æ–­å…¬å‘Šé‡è¦æ€§
                        importance = 'low'
                        urgency = 'low'
                        if any(kw in title for kw in ['ä¸šç»©é¢„å‘Š', 'ä¸šç»©å¿«æŠ¥', 'é‡å¤§', 'åœç‰Œ', 'å¤ç‰Œ', 'é£é™©æç¤º']):
                            importance = 'high'
                            urgency = 'high'
                        elif any(kw in title for kw in ['å¹´æŠ¥', 'å­£æŠ¥', 'ä¸­æŠ¥', 'åˆ†çº¢', 'å¢æŒ', 'å‡æŒ']):
                            importance = 'medium'
                            urgency = 'medium'

                        news_list.append({
                            "title": f"[{stock_name or 'å…¬å‘Š'}] {title}",
                            "content": f"è¯åˆ¸ä»£ç : {stock_code} | å¸‚åœº: {market} | åˆ†ç±»: {category}",
                            "pub_time": pub_date,
                            "source": "å·¨æ½®å…¬å‘Š",
                            "url": pdf_url,
                            "announcement_type": "announcement",
                            "importance": importance,
                            "urgency": urgency,
                            "related_stocks": [stock_code] if stock_code else []
                        })
            except Exception as e:
                logger.warning(f"è·å–å…¬å‘Šä¿¡æ¯å¤±è´¥: {e}")

            # 2. è·å–ä¸Šå¸‚çŠ¶æ€å˜åŠ¨ (p_stock2117) - å…è´¹å¯ç”¨ï¼Œé‡è¦ä¿¡æ¯
            # æ³¨æ„ï¼šæ­¤æ¥å£è¿”å›æ‰€æœ‰å†å²æ•°æ®ï¼Œåªå–æœ€è¿‘100æ¡
            try:
                status_result = await client.get_listing_status_changes()
                if status_result.get('success') and status_result.get('data'):
                    # åªå–æœ€è¿‘100æ¡ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
                    data = status_result['data'][:100]
                    for item in data:
                        stock_code = item.get('SECCODE', '')
                        stock_name = item.get('SECNAME', '')
                        org_name = item.get('ORGNAME', '')
                        change_date = item.get('VARYDATE', '')
                        status = item.get('F002V', '')  # ä¸Šå¸‚çŠ¶æ€
                        change_type = item.get('F006V', '')  # å˜æ›´ç±»å‹
                        reason = item.get('F004V', '')  # å˜æ›´åŸå› 

                        if not stock_code or not change_type:
                            continue

                        # åˆ¤æ–­é‡è¦æ€§
                        urgency = 'medium'
                        if any(kw in str(change_type) for kw in ['é€€å¸‚', 'æš‚åœä¸Šå¸‚', 'ç»ˆæ­¢ä¸Šå¸‚']):
                            urgency = 'critical'
                        elif any(kw in str(change_type) for kw in ['ST', 'é£é™©è­¦ç¤º', 'åœç‰Œ']):
                            urgency = 'high'

                        news_list.append({
                            "title": f"[ä¸Šå¸‚çŠ¶æ€] {stock_name}({stock_code}) {change_type}",
                            "content": f"å…¬å¸: {org_name} | çŠ¶æ€: {status} | åŸå› : {reason or 'æ— '}",
                            "pub_time": change_date,
                            "source": "å·¨æ½®çŠ¶æ€å˜åŠ¨",
                            "url": "",
                            "announcement_type": "status_change",
                            "importance": "high" if urgency in ['critical', 'high'] else "medium",
                            "urgency": urgency,
                            "related_stocks": [stock_code] if stock_code else []
                        })
            except Exception as e:
                logger.warning(f"è·å–ä¸Šå¸‚çŠ¶æ€å˜åŠ¨å¤±è´¥: {e}")

            if news_list:
                logger.info(f"ä»å·¨æ½®å®˜æ–¹APIè·å– {len(news_list)} æ¡æ•°æ®")
            return news_list

        except Exception as e:
            logger.error(f"Fetch cninfo failed: {e}")
            return []

    def _get_monitored_stocks(self) -> List[str]:
        """è·å–å½“å‰ç›‘æ§çš„è‚¡ç¥¨åˆ—è¡¨"""
        try:
            # å°è¯•ä»ç›‘æ§æœåŠ¡è·å–
            from backend.services.realtime_monitor_service import get_realtime_monitor_service
            monitor = get_realtime_monitor_service()
            if hasattr(monitor, 'config') and monitor.config:
                stocks = monitor.config.get('stocks', [])
                if stocks:
                    return stocks
        except:
            pass
        # é»˜è®¤è¿”å›ä¸€äº›çƒ­é—¨è‚¡ç¥¨
        return ["600519.SH", "000858.SZ", "601318.SH", "000001.SZ", "600036.SH"]
    
    async def _process_news(self, news_list: List[Dict], source_id: str):
        """å¤„ç†æ–°é—»åˆ—è¡¨ - å°†CPUå¯†é›†å‹æ“ä½œç§»åˆ°çº¿ç¨‹æ± é¿å…é˜»å¡"""
        new_count = 0
        urgent_news = []
        loop = asyncio.get_event_loop()

        for news_data in news_list:
            title = news_data.get("title", "")
            content = news_data.get("content", "")
            if not title:
                continue
            if self._cache.is_duplicate(title, news_data.get("pub_time", "")):
                self._stats["total_duplicates"] += 1
                continue

            # å°†CPUå¯†é›†å‹æ“ä½œç§»åˆ°çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
            try:
                sentiment_result, related_stocks, impact = await loop.run_in_executor(
                    self._executor,
                    self._analyze_news_sync,
                    title,
                    content
                )
            except Exception as e:
                logger.debug(f"News analysis failed: {e}")
                sentiment_result = {"sentiment": "neutral", "score": 50, "urgency": "low"}
                related_stocks = []
                impact = type('Impact', (), {'urgency': 'low', 'score': 0})()

            enriched_news = {**news_data, "sentiment": sentiment_result.get("sentiment", "neutral"), "sentiment_score": sentiment_result.get("score", 50), "urgency": impact.urgency, "keywords": sentiment_result.get("keywords", []), "related_stocks": related_stocks, "impact_score": impact.score}
            result = self._cache.add_news_batch([enriched_news])
            if result["added"] > 0:
                new_count += 1
                self._stats["total_processed"] += 1
                if impact.urgency in ["critical", "high"]:
                    urgent_news.append(enriched_news)
        self._stats["total_fetched"] += len(news_list)
        self._stats["last_fetch_time"] = datetime.now().isoformat()
        if new_count > 0:
            logger.info(f"[{source_id}] Processed {new_count} new news")
            for callback in self._on_new_news:
                try:
                    callback(new_count, source_id)
                except:
                    pass
        if urgent_news:
            logger.warning(f"[{source_id}] Found {len(urgent_news)} urgent news!")
            for callback in self._on_urgent_news:
                try:
                    callback(urgent_news)
                except:
                    pass
            # WebSocket æ¨é€ç´§æ€¥æ–°é—»
            ws_notify, ws_urgent = _get_ws_notifiers()
            if ws_urgent:
                try:
                    asyncio.create_task(ws_urgent(urgent_news))
                except:
                    pass
            # å‘é€é€šçŸ¥ï¼ˆä¼ä¸šå¾®ä¿¡/é’‰é’‰/é‚®ä»¶ç­‰ï¼‰
            try:
                asyncio.create_task(self._send_urgent_notification(urgent_news))
            except:
                pass

    def _analyze_news_sync(self, title: str, content: str):
        """åŒæ­¥åˆ†ææ–°é—»ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
        sentiment_result = {"sentiment": "neutral", "score": 50, "urgency": "low"}
        if self._sentiment_engine:
            try:
                sentiment_result = self._sentiment_engine.analyze(title, content)
            except:
                pass
        related_stocks = self._stock_analyzer.get_related_codes(title, content)
        impact = self._impact_assessor.assess(title, content, sentiment_result.get("score", 50))
        return sentiment_result, related_stocks, impact

    async def _send_urgent_notification(self, urgent_news: List[Dict]):
        """å‘é€ç´§æ€¥æ–°é—»é€šçŸ¥åˆ°é…ç½®çš„æ¸ é“"""
        try:
            from backend.services.notification_service import get_notification_service
            notification_service = get_notification_service()

            # è½¬æ¢ä¸ºé¢„è­¦æ ¼å¼
            alerts = []
            for news in urgent_news[:5]:  # æœ€å¤š5æ¡
                urgency = news.get('urgency', 'medium')
                level = 'critical' if urgency == 'critical' else 'high' if urgency == 'high' else 'medium'
                alerts.append({
                    'title': f"ğŸ“° {news.get('title', 'é‡è¦æ–°é—»')[:50]}",
                    'message': news.get('content', '')[:200] if news.get('content') else news.get('title', ''),
                    'level': level,
                    'stock_code': ', '.join(news.get('related_stocks', [])[:3]) or 'å¸‚åœº',
                    'suggestion': f"æ¥æº: {news.get('source', 'æœªçŸ¥')} | æƒ…ç»ª: {news.get('sentiment', 'neutral')}"
                })

            if alerts:
                result = await notification_service.send_alert_notification(alerts)
                if result.get('success'):
                    logger.info(f"âœ… ç´§æ€¥æ–°é—»é€šçŸ¥å‘é€æˆåŠŸ: {len(alerts)}æ¡")
                elif '0/0' in result.get('message', ''):
                    # æ²¡æœ‰é…ç½®é€šçŸ¥æ¸ é“ï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µï¼Œä¸éœ€è¦è­¦å‘Š
                    logger.debug(f"ç´§æ€¥æ–°é—»é€šçŸ¥: æœªé…ç½®é€šçŸ¥æ¸ é“ï¼Œè·³è¿‡å‘é€")
                else:
                    logger.warning(f"âš ï¸ ç´§æ€¥æ–°é—»é€šçŸ¥å‘é€éƒ¨åˆ†å¤±è´¥: {result.get('message')}")
        except Exception as e:
            logger.error(f"å‘é€ç´§æ€¥æ–°é—»é€šçŸ¥å¤±è´¥: {e}")

    def get_latest_news(self, limit: int = 100, **filters) -> List[Dict]:
        news_list = self._cache.get_latest_news(limit, **filters)
        return [n.to_dict() for n in news_list]
    
    def get_urgent_news(self, limit: int = 20) -> List[Dict]:
        news_list = self._cache.get_urgent_news(limit)
        return [n.to_dict() for n in news_list]
    
    def get_news_for_stock(self, stock_code: str, limit: int = 30) -> List[Dict]:
        news_list = self._cache.get_news_for_stock(stock_code, limit)
        return [n.to_dict() for n in news_list]
    
    def get_stats(self) -> Dict[str, Any]:
        cache_stats = self._cache.get_stats()
        source_stats = {sid: {"name": cfg.name, "interval": cfg.interval, "enabled": cfg.enabled, "last_fetch": cfg.last_fetch, "fetch_count": cfg.fetch_count, "error_count": cfg.error_count} for sid, cfg in self._sources.items()}
        return {**self._stats, "cache": cache_stats, "sources": source_stats, "running": self._running}
    
    def set_source_interval(self, source_id: str, interval: int):
        if source_id in self._sources:
            self._sources[source_id].interval = max(10, interval)
            logger.info(f"Set {source_id} interval to {interval}s")
    
    def enable_source(self, source_id: str, enabled: bool = True):
        if source_id in self._sources:
            self._sources[source_id].enabled = enabled
            logger.info(f"Set {source_id} enabled={enabled}")
    
    def on_new_news(self, callback: Callable):
        self._on_new_news.append(callback)
    
    def on_urgent_news(self, callback: Callable):
        self._on_urgent_news.append(callback)
    
    async def fetch_now(self, source_id: str = None):
        if source_id:
            await self._fetch_source(source_id)
        else:
            for sid in self._sources:
                await self._fetch_source(sid)
    
    def cleanup(self):
        return self._cache.cleanup_expired()

    # ==================== å¸‚åœºæ–°é—»è·å–ï¼ˆæ–°é—»ä¸­å¿ƒ/å®æ—¶æ–°é—»æµï¼‰====================

    async def fetch_market_news(self) -> List[Dict]:
        """
        è·å–å¸‚åœºæ–°é—»ï¼ˆç”¨äºæ–°é—»ä¸­å¿ƒ/å®æ—¶æ–°é—»æµï¼‰
        åªè°ƒç”¨å¸‚åœºçº§åˆ«çš„æ–°é—»æ¥å£ï¼Œä¸è°ƒç”¨ä¸ªè‚¡æ–°é—»æ¥å£

        åŒ…å«æ¥å£ï¼š
        1. stock_info_global_em - ä¸œæ–¹è´¢å¯Œå…¨çƒèµ„è®¯
        2. stock_info_global_cls - è´¢è”ç¤¾å…¨çƒèµ„è®¯
        3. stock_info_global_futu - å¯Œé€”ç‰›ç‰›
        4. stock_info_global_ths - åŒèŠ±é¡º
        5. stock_info_global_sina - æ–°æµªè´¢ç»
        6. stock_js_weibo_report - å¾®åšçƒ­è®®
        7. stock_info_cjzc_em - è´¢ç»æ—©é¤
        8. news_cctv - æ–°é—»è”æ’­
        9. news_economic_baidu - ç™¾åº¦è´¢ç»
        10. å·¨æ½®å¸‚åœºå…¬å‘Šï¼ˆä¸å¸¦ä¸ªè‚¡å‚æ•°ï¼‰
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []
            config = self._config_manager.config

            # 1. ä¸œæ–¹è´¢å¯Œå…¨çƒèµ„è®¯
            source_cfg = config.market_sources.get(NewsSourceType.EASTMONEY_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_em)
                    if df is not None and not df.empty:
                        for _, row in df.iterrows():
                            title = str(row.get("æ ‡é¢˜", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("æ‘˜è¦", row.get("å†…å®¹", "")))[:1000],
                                    "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                    "source": source_cfg.name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                                    "url": str(row.get("é“¾æ¥", ""))
                                })
                        logger.info(f"ä¸œæ–¹è´¢å¯Œå…¨çƒèµ„è®¯: {len([n for n in news_list if n['source'] == source_cfg.name])}æ¡")
                except Exception as e:
                    logger.debug(f"stock_info_global_emå¤±è´¥: {e}")

            # 2. è´¢è”ç¤¾å…¨çƒèµ„è®¯
            source_cfg = config.market_sources.get(NewsSourceType.CLS_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_cls)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("æ ‡é¢˜", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("å†…å®¹", ""))[:1000],
                                    "pub_time": str(row.get("å‘å¸ƒæ—¥æœŸ", "")) + " " + str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                    "source": source_cfg.name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"è´¢è”ç¤¾ç”µæŠ¥: {count}æ¡")
                except Exception as e:
                    logger.debug(f"stock_info_global_clså¤±è´¥: {e}")

            # 3. å¯Œé€”ç‰›ç‰›
            source_cfg = config.market_sources.get(NewsSourceType.FUTU_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_futu)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("æ ‡é¢˜", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("å†…å®¹", ""))[:1000],
                                    "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                    "source": source_cfg.name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                                    "url": str(row.get("é“¾æ¥", ""))
                                })
                                count += 1
                        logger.info(f"å¯Œé€”ç‰›ç‰›: {count}æ¡")
                except Exception as e:
                    logger.debug(f"stock_info_global_futuå¤±è´¥: {e}")

            # 4. åŒèŠ±é¡º
            source_cfg = config.market_sources.get(NewsSourceType.THS_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_ths)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("æ ‡é¢˜", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("å†…å®¹", ""))[:1000],
                                    "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                    "source": source_cfg.name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                                    "url": str(row.get("é“¾æ¥", ""))
                                })
                                count += 1
                        logger.info(f"åŒèŠ±é¡º: {count}æ¡")
                except Exception as e:
                    logger.debug(f"stock_info_global_thså¤±è´¥: {e}")

            # 5. æ–°æµªè´¢ç» - åˆ—å: ['æ—¶é—´', 'å†…å®¹']
            source_cfg = config.market_sources.get(NewsSourceType.SINA_GLOBAL.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_global_sina)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            content = str(row.get("å†…å®¹", ""))
                            if content:
                                # æ–°æµªè´¢ç»åªæœ‰å†…å®¹ï¼Œæ²¡æœ‰æ ‡é¢˜ï¼Œæˆªå–å‰50å­—ä½œä¸ºæ ‡é¢˜
                                title = content[:50] + "..." if len(content) > 50 else content
                                news_list.append({
                                    "title": title,
                                    "content": content[:1000],
                                    "pub_time": str(row.get("æ—¶é—´", "")),
                                    "source": source_cfg.name,
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"æ–°æµªè´¢ç»: {count}æ¡")
                except Exception as e:
                    logger.debug(f"stock_info_global_sinaå¤±è´¥: {e}")

            # 6. å¾®åšçƒ­è®®
            source_cfg = config.market_sources.get(NewsSourceType.WEIBO_HOT.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_js_weibo_report)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            stock_name = str(row.get("name", row.get("è‚¡ç¥¨", "")))
                            rate = row.get("rate", row.get("æ¶¨è·Œå¹…", 0))
                            if stock_name:
                                # æ ¼å¼åŒ–æ¶¨è·Œå¹…
                                try:
                                    rate_val = float(rate)
                                    rate_str = f"+{rate_val:.2f}%" if rate_val >= 0 else f"{rate_val:.2f}%"
                                except:
                                    rate_str = str(rate)
                                news_list.append({
                                    "title": f"[å¾®åšçƒ­è®®] {stock_name} {rate_str}",
                                    "content": f"å¾®åšè‚¡ç¥¨çƒ­è®®æ¦œï¼Œå½“å‰æ¶¨è·Œå¹…: {rate_str}",
                                    "pub_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "source": source_cfg.name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"å¾®åšçƒ­è®®: {count}æ¡")
                except Exception as e:
                    logger.debug(f"stock_js_weibo_reportå¤±è´¥: {e}")

            # 7. è´¢ç»æ—©é¤
            source_cfg = config.market_sources.get(NewsSourceType.CJZC.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.stock_info_cjzc_em)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("æ ‡é¢˜", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("å†…å®¹", ""))[:1000],
                                    "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                    "source": source_cfg.name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"è´¢ç»æ—©é¤: {count}æ¡")
                except Exception as e:
                    logger.debug(f"stock_info_cjzc_emå¤±è´¥: {e}")

            # 8. æ–°é—»è”æ’­
            source_cfg = config.market_sources.get(NewsSourceType.CCTV.value)
            if source_cfg and source_cfg.enabled:
                try:
                    today = datetime.now().strftime('%Y%m%d')
                    df = await loop.run_in_executor(self._executor, lambda: ak.news_cctv(date=today))
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            title = str(row.get("title", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("content", ""))[:1000],
                                    "pub_time": str(row.get("date", today)),
                                    "source": source_cfg.name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"æ–°é—»è”æ’­: {count}æ¡")
                except Exception as e:
                    logger.debug(f"news_cctvå¤±è´¥: {e}")

            # 9. ç™¾åº¦è´¢ç» - åˆ—å: ['å›½å®¶', 'æ—¶é—´', 'åœ°åŒº', 'äº‹ä»¶', 'ä»Šå€¼', 'é¢„æœŸ', 'å‰å€¼', 'é‡è¦æ€§']
            source_cfg = config.market_sources.get(NewsSourceType.BAIDU.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(self._executor, ak.news_economic_baidu)
                    if df is not None and not df.empty:
                        count = 0
                        for _, row in df.iterrows():
                            event = str(row.get("äº‹ä»¶", ""))
                            if event:
                                # æ„å»ºæ ‡é¢˜ï¼šåœ°åŒº + äº‹ä»¶
                                country = str(row.get("å›½å®¶", ""))
                                region = str(row.get("åœ°åŒº", ""))
                                title = f"[{country}] {event}" if country else event
                                # æ„å»ºå†…å®¹ï¼šä»Šå€¼ã€é¢„æœŸã€å‰å€¼
                                today_val = row.get("ä»Šå€¼", "")
                                expect_val = row.get("é¢„æœŸ", "")
                                prev_val = row.get("å‰å€¼", "")
                                importance = row.get("é‡è¦æ€§", "")
                                content = f"ä»Šå€¼: {today_val} | é¢„æœŸ: {expect_val} | å‰å€¼: {prev_val} | é‡è¦æ€§: {importance}"
                                news_list.append({
                                    "title": title,
                                    "content": content,
                                    "pub_time": str(row.get("æ—¶é—´", "")),
                                    "source": source_cfg.name,
                                    "url": ""
                                })
                                count += 1
                        logger.info(f"ç™¾åº¦è´¢ç»: {count}æ¡")
                except Exception as e:
                    logger.debug(f"news_economic_baiduå¤±è´¥: {e}")

            # 10. å·¨æ½®å¸‚åœºå…¬å‘Šï¼ˆä¸å¸¦ä¸ªè‚¡å‚æ•°ï¼‰
            source_cfg = config.market_sources.get(NewsSourceType.CNINFO_MARKET.value)
            if source_cfg and source_cfg.enabled:
                cninfo_news = await self._fetch_cninfo_market()
                news_list.extend(cninfo_news)

            # 11. å·¨æ½®æ–°é—»æ•°æ®ï¼ˆp_info3030ï¼‰
            source_cfg = config.market_sources.get(NewsSourceType.CNINFO_NEWS.value)
            if source_cfg and source_cfg.enabled:
                cninfo_news_data = await self._fetch_cninfo_news(days_back=source_cfg.days_back)
                news_list.extend(cninfo_news_data)

            # 12. å·¨æ½®ç ”æŠ¥æ‘˜è¦ï¼ˆp_info3097_incï¼‰- VIPæ¥å£
            source_cfg = config.market_sources.get(NewsSourceType.CNINFO_RESEARCH.value)
            if source_cfg and source_cfg.enabled:
                research_data = await self._fetch_cninfo_research(limit=source_cfg.limit)
                news_list.extend(research_data)

            # 13. å·¨æ½®é«˜ç®¡å˜åŠ¨ï¼ˆp_stock2102ï¼‰
            source_cfg = config.market_sources.get(NewsSourceType.CNINFO_MANAGEMENT.value)
            if source_cfg and source_cfg.enabled:
                management_data = await self._fetch_cninfo_management(limit=source_cfg.limit)
                news_list.extend(management_data)

            # å¯¹æ‰€æœ‰æ–°é—»è¿›è¡Œæƒ…ç»ªåˆ†æ
            if news_list and self._sentiment_engine:
                for news_item in news_list:
                    if not news_item.get('sentiment'):  # åªåˆ†ææ²¡æœ‰æƒ…ç»ªçš„æ–°é—»
                        try:
                            title = news_item.get('title', '')
                            content = news_item.get('content', '')
                            sentiment_result = self._sentiment_engine.analyze(title, content)
                            news_item['sentiment'] = sentiment_result.get('sentiment', 'neutral')
                            news_item['sentiment_score'] = sentiment_result.get('score', 50)
                        except Exception as e:
                            news_item['sentiment'] = 'neutral'
                            news_item['sentiment_score'] = 50

            # ä¿å­˜åˆ°æ•°æ®åº“
            if news_list:
                try:
                    from .news_storage import get_news_storage
                    storage = get_news_storage()
                    save_result = storage.save_news_batch(news_list)
                    logger.info(f"æ–°é—»å·²ä¿å­˜åˆ°æ•°æ®åº“: æ–°å¢{save_result['saved']}æ¡, è·³è¿‡{save_result['skipped']}æ¡")
                except Exception as e:
                    logger.warning(f"ä¿å­˜æ–°é—»åˆ°æ•°æ®åº“å¤±è´¥: {e}")

            logger.info(f"å¸‚åœºæ–°é—»è·å–å®Œæˆï¼Œå…± {len(news_list)} æ¡")
            return news_list

        except Exception as e:
            logger.error(f"è·å–å¸‚åœºæ–°é—»å¤±è´¥: {e}")
            return []

    async def _fetch_cninfo_management(self, limit: int = 100) -> List[Dict]:
        """è·å–å·¨æ½®é«˜ç®¡å˜åŠ¨ï¼ˆp_stock2102ï¼‰"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("å·¨æ½®APIæœªé…ç½®ï¼Œè·³è¿‡è·å–")
                return []

            client = get_cninfo_api_client()
            news_list = []

            # è·å–æ•°æ®æºé…ç½®åç§°
            source_cfg = self._config_manager.config.market_sources.get(NewsSourceType.CNINFO_MANAGEMENT.value)
            source_name = source_cfg.name if source_cfg else "å·¨æ½®é«˜ç®¡å˜åŠ¨"

            try:
                # è·å–çƒ­é—¨è‚¡ç¥¨çš„é«˜ç®¡å˜åŠ¨ä¿¡æ¯
                hot_stocks = self._config_manager.config.hot_stocks[:20]  # å–å‰20åªçƒ­é—¨è‚¡ç¥¨
                if not hot_stocks:
                    hot_stocks = ["000001", "600519", "000858", "601318", "600036"]

                result = await client.get_management_personnel(hot_stocks, state=1)
                if result.get('success') and result.get('data'):
                    # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼Œå–æœ€è¿‘çš„å˜åŠ¨
                    data = result['data']
                    # è¿‡æ»¤å‡ºæœ€è¿‘çš„ä»»èŒå˜åŠ¨ï¼ˆæœ‰ç¦»èŒæ—¥æœŸæˆ–æœ€è¿‘ä»»èŒçš„ï¼‰
                    recent_changes = []
                    for item in data:
                        declare_date = item.get('DECLAREDATE', '')
                        leave_date = item.get('F008D', '')
                        join_date = item.get('F007D', '')

                        # å¦‚æœæœ‰ç¦»èŒæ—¥æœŸï¼Œè¯´æ˜æ˜¯ç¦»èŒå˜åŠ¨
                        if leave_date:
                            recent_changes.append({
                                'item': item,
                                'change_type': 'ç¦»èŒ',
                                'date': leave_date
                            })
                        # å¦‚æœä»»èŒæ—¥æœŸåœ¨æœ€è¿‘30å¤©å†…ï¼Œè¯´æ˜æ˜¯æ–°ä»»èŒ
                        elif join_date:
                            try:
                                from datetime import datetime
                                join_dt = datetime.strptime(str(join_date)[:10], '%Y-%m-%d')
                                if (datetime.now() - join_dt).days <= 30:
                                    recent_changes.append({
                                        'item': item,
                                        'change_type': 'ä»»èŒ',
                                        'date': join_date
                                    })
                            except:
                                pass

                    # å–æœ€è¿‘çš„å˜åŠ¨
                    for change in recent_changes[:limit]:
                        item = change['item']
                        change_type = change['change_type']
                        stock_code = item.get('SECCODE', '')
                        stock_name = item.get('SECNAME', '')
                        org_name = item.get('ORGNAME', '')
                        person_name = item.get('F002V', '')
                        position = item.get('F009V', '')
                        join_date = item.get('F007D', '')
                        leave_date = item.get('F008D', '')
                        gender = item.get('F010V', '')
                        education = item.get('F011V', '')
                        resume = item.get('F019V', '')

                        if not person_name or not position:
                            continue

                        # æ„å»ºæ ‡é¢˜
                        if change_type == 'ç¦»èŒ':
                            title = f"[é«˜ç®¡å˜åŠ¨] {stock_name}({stock_code}) {person_name} ç¦»ä»»{position}"
                        else:
                            title = f"[é«˜ç®¡å˜åŠ¨] {stock_name}({stock_code}) {person_name} å°±ä»»{position}"

                        # æ„å»ºå†…å®¹
                        content_parts = [f"å…¬å¸: {org_name}"]
                        if join_date:
                            content_parts.append(f"ä»»èŒæ—¥æœŸ: {join_date}")
                        if leave_date:
                            content_parts.append(f"ç¦»èŒæ—¥æœŸ: {leave_date}")
                        if gender:
                            content_parts.append(f"æ€§åˆ«: {gender}")
                        if education:
                            content_parts.append(f"å­¦å†: {education}")
                        if resume:
                            content_parts.append(f"ç®€å†: {resume[:200]}...")

                        news_list.append({
                            "title": title,
                            "content": " | ".join(content_parts),
                            "pub_time": change['date'],
                            "source": source_name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                            "url": "",
                            "importance": "high",
                            "urgency": "medium",
                            "related_stocks": [stock_code] if stock_code else []
                        })

                    logger.info(f"å·¨æ½®é«˜ç®¡å˜åŠ¨: {len(news_list)}æ¡")
            except Exception as e:
                logger.warning(f"è·å–å·¨æ½®é«˜ç®¡å˜åŠ¨å¤±è´¥: {e}")

            return news_list

        except Exception as e:
            logger.error(f"è·å–å·¨æ½®é«˜ç®¡å˜åŠ¨å¤±è´¥: {e}")
            return []

    async def _fetch_cninfo_news(self, days_back: int = 1, stock_code: str = '') -> List[Dict]:
        """è·å–å·¨æ½®æ–°é—»æ•°æ®ï¼ˆp_info3030ï¼‰"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("å·¨æ½®APIæœªé…ç½®ï¼Œè·³è¿‡è·å–")
                return []

            client = get_cninfo_api_client()
            news_list = []

            # è·å–æ•°æ®æºé…ç½®åç§°
            source_cfg = self._config_manager.config.market_sources.get(NewsSourceType.CNINFO_NEWS.value)
            source_name = source_cfg.name if source_cfg else "å·¨æ½®æ–°é—»æ•°æ®(VIP)"

            try:
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=days_back-1)).strftime('%Y-%m-%d')

                result = await client.get_news_list(
                    stock_code=stock_code,
                    start_date=start_date,
                    end_date=end_date
                )
                if result.get('success') and result.get('data'):
                    for item in result['data']:
                        title = item.get('F004V', '')
                        if not title:
                            continue
                        pub_time = item.get('DECLAREDATE', '')
                        news_id = item.get('TEXTID', '')
                        sec_code = item.get('SECCODE', '')
                        keywords = item.get('F002V', '')
                        news_type = item.get('F003V', '')
                        author = item.get('F005V', '')

                        news_list.append({
                            "title": title,
                            "content": f"å…³é”®è¯: {keywords}" if keywords else "",
                            "pub_time": pub_time,
                            "source": source_name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                            "url": "",
                            "news_id": news_id,
                            "news_type": news_type,
                            "author": author,
                            "related_stocks": [sec_code] if sec_code else []
                        })
                    logger.info(f"å·¨æ½®æ–°é—»æ•°æ®: {len(news_list)}æ¡")
            except Exception as e:
                logger.warning(f"è·å–å·¨æ½®æ–°é—»æ•°æ®å¤±è´¥: {e}")

            return news_list

        except Exception as e:
            logger.error(f"è·å–å·¨æ½®æ–°é—»æ•°æ®å¤±è´¥: {e}")
            return []

    async def _fetch_cninfo_research(self, limit: int = 500) -> List[Dict]:
        """è·å–å·¨æ½®ç ”æŠ¥æ‘˜è¦ï¼ˆp_info3097_incï¼‰"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("å·¨æ½®APIæœªé…ç½®ï¼Œè·³è¿‡è·å–")
                return []

            client = get_cninfo_api_client()
            news_list = []

            # è·å–æ•°æ®æºé…ç½®åç§°
            source_cfg = self._config_manager.config.market_sources.get(NewsSourceType.CNINFO_RESEARCH.value)
            source_name = source_cfg.name if source_cfg else "å·¨æ½®ç ”æŠ¥æ‘˜è¦(VIP)"

            try:
                result = await client.get_research_report_summary(
                    object_id=0,
                    row_count=min(limit, 2000)
                )
                if result.get('success') and result.get('data'):
                    for item in result['data']:
                        title = item.get('F002V', '')
                        if not title:
                            continue
                        content = item.get('F003V', '')
                        pub_date = item.get('F001D', '')
                        sec_code = item.get('SECCODE', '')
                        sec_name = item.get('SECNAME', '')
                        institution = item.get('F004V', '')
                        report_date = item.get('F005D', '')
                        category = item.get('F007V', '')

                        news_list.append({
                            "title": f"[ç ”æŠ¥] {title}",
                            "content": content[:500] if content else f"æœºæ„: {institution}",
                            "pub_time": pub_date,
                            "source": source_name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                            "url": "",
                            "report_date": report_date,
                            "category": category,
                            "importance": "medium",
                            "related_stocks": [sec_code] if sec_code else []
                        })
                    logger.info(f"å·¨æ½®ç ”æŠ¥æ‘˜è¦: {len(news_list)}æ¡")
            except Exception as e:
                logger.warning(f"è·å–å·¨æ½®ç ”æŠ¥æ‘˜è¦å¤±è´¥: {e}")

            return news_list

        except Exception as e:
            logger.error(f"è·å–å·¨æ½®ç ”æŠ¥æ‘˜è¦å¤±è´¥: {e}")
            return []

    async def _fetch_cninfo_market(self) -> List[Dict]:
        """è·å–å·¨æ½®å¸‚åœºå…¬å‘Šï¼ˆä¸å¸¦ä¸ªè‚¡å‚æ•°ï¼‰"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("å·¨æ½®APIæœªé…ç½®ï¼Œè·³è¿‡è·å–")
                return []

            client = get_cninfo_api_client()
            news_list = []
            config = self._config_manager.config.cninfo

            # è·å–æ•°æ®æºé…ç½®åç§°
            market_source_cfg = self._config_manager.config.market_sources.get(NewsSourceType.CNINFO_MARKET.value)
            source_name = market_source_cfg.name if market_source_cfg else "å·¨æ½®å¸‚åœºå…¬å‘Š"

            # è·å–å…¬å‘Šä¿¡æ¯
            if config.announcement_enabled:
                try:
                    days_back = config.announcement_days_back
                    end_date = datetime.now().strftime('%Y-%m-%d')
                    start_date = (datetime.now() - timedelta(days=days_back-1)).strftime('%Y-%m-%d')

                    announcement_result = await client.get_announcement_info(
                        start_date=start_date,
                        end_date=end_date,
                        page_size=config.announcement_page_size
                    )
                    if announcement_result.get('success') and announcement_result.get('data'):
                        for item in announcement_result['data']:
                            title = item.get('F002V', '')
                            if not title:
                                continue
                            pub_date = item.get('F001D', '')
                            pdf_url = item.get('F003V', '')
                            stock_code = item.get('SECCODE', '')
                            stock_name = item.get('SECNAME', '')
                            market = item.get('F010V', '')
                            category = item.get('F006V', '')

                            importance = 'low'
                            urgency = 'low'
                            if any(kw in title for kw in ['ä¸šç»©é¢„å‘Š', 'ä¸šç»©å¿«æŠ¥', 'é‡å¤§', 'åœç‰Œ', 'å¤ç‰Œ', 'é£é™©æç¤º']):
                                importance = 'high'
                                urgency = 'high'
                            elif any(kw in title for kw in ['å¹´æŠ¥', 'å­£æŠ¥', 'ä¸­æŠ¥', 'åˆ†çº¢', 'å¢æŒ', 'å‡æŒ']):
                                importance = 'medium'
                                urgency = 'medium'

                            news_list.append({
                                "title": f"[{stock_name or 'å…¬å‘Š'}] {title}",
                                "content": f"è¯åˆ¸ä»£ç : {stock_code} | å¸‚åœº: {market} | åˆ†ç±»: {category}",
                                "pub_time": pub_date,
                                "source": source_name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                                "url": pdf_url,
                                "announcement_type": "announcement",
                                "importance": importance,
                                "urgency": urgency,
                                "related_stocks": [stock_code] if stock_code else []
                            })
                        logger.info(f"å·¨æ½®å¸‚åœºå…¬å‘Š: {len(news_list)}æ¡")
                except Exception as e:
                    logger.warning(f"è·å–å·¨æ½®å…¬å‘Šä¿¡æ¯å¤±è´¥: {e}")

            # è·å–ä¸Šå¸‚çŠ¶æ€å˜åŠ¨
            if config.status_change_enabled:
                try:
                    status_result = await client.get_listing_status_changes()
                    if status_result.get('success') and status_result.get('data'):
                        data = status_result['data'][:config.status_change_limit]
                        status_count = 0
                        for item in data:
                            stock_code = item.get('SECCODE', '')
                            stock_name = item.get('SECNAME', '')
                            org_name = item.get('ORGNAME', '')
                            change_date = item.get('VARYDATE', '')
                            status = item.get('F002V', '')
                            change_type = item.get('F006V', '')
                            reason = item.get('F004V', '')

                            if not stock_code or not change_type:
                                continue

                            urgency = 'medium'
                            if any(kw in str(change_type) for kw in ['é€€å¸‚', 'æš‚åœä¸Šå¸‚', 'ç»ˆæ­¢ä¸Šå¸‚']):
                                urgency = 'critical'
                            elif any(kw in str(change_type) for kw in ['ST', 'é£é™©è­¦ç¤º', 'åœç‰Œ']):
                                urgency = 'high'

                            news_list.append({
                                "title": f"[ä¸Šå¸‚çŠ¶æ€] {stock_name}({stock_code}) {change_type}",
                                "content": f"å…¬å¸: {org_name} | çŠ¶æ€: {status} | åŸå› : {reason or 'æ— '}",
                                "pub_time": change_date,
                                "source": source_name,  # ä½¿ç”¨é…ç½®ä¸­çš„åç§°
                                "url": "",
                                "announcement_type": "status_change",
                                "importance": "high" if urgency in ['critical', 'high'] else "medium",
                                "urgency": urgency,
                                "related_stocks": [stock_code] if stock_code else []
                            })
                            status_count += 1
                        logger.info(f"å·¨æ½®çŠ¶æ€å˜åŠ¨: {status_count}æ¡")
                except Exception as e:
                    logger.warning(f"è·å–ä¸Šå¸‚çŠ¶æ€å˜åŠ¨å¤±è´¥: {e}")

            return news_list

        except Exception as e:
            logger.error(f"è·å–å·¨æ½®å¸‚åœºå…¬å‘Šå¤±è´¥: {e}")
            return []

    # ==================== ä¸ªè‚¡æ–°é—»è·å–ï¼ˆæ™ºèƒ½åˆ†æ/ä¸ªè‚¡ç›‘æ§ï¼‰====================

    async def fetch_stock_news(self, stock_code: str, stock_name: str = "") -> List[Dict]:
        """
        è·å–ä¸ªè‚¡æ–°é—»ï¼ˆç”¨äºæ™ºèƒ½åˆ†æ/ä¸ªè‚¡ç›‘æ§ï¼‰
        è°ƒç”¨ä¸ªè‚¡æ–°é—»æ¥å£ï¼Œè·å–ç‰¹å®šè‚¡ç¥¨ç›¸å…³æ–°é—»

        åŒ…å«æ¥å£ï¼š
        1. stock_news_em - ä¸œæ–¹è´¢å¯Œä¸ªè‚¡æ–°é—»
        2. å·¨æ½®ä¸ªè‚¡å…¬å‘Šï¼ˆå¸¦ä¸ªè‚¡å‚æ•°ï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼ˆ6ä½æ•°å­—ï¼Œå¦‚ 600519ï¼‰
            stock_name: è‚¡ç¥¨åç§°ï¼ˆå¯é€‰ï¼Œç”¨äºæ—¥å¿—ï¼‰
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []
            config = self._config_manager.config

            # æ¸…ç†è‚¡ç¥¨ä»£ç 
            clean_code = stock_code.replace('.SH', '').replace('.SZ', '').replace('.BJ', '')

            # 1. ä¸œæ–¹è´¢å¯Œä¸ªè‚¡æ–°é—»
            source_cfg = config.stock_sources.get(NewsSourceType.STOCK_NEWS_EM.value)
            if source_cfg and source_cfg.enabled:
                try:
                    df = await loop.run_in_executor(
                        self._executor,
                        lambda: ak.stock_news_em(symbol=clean_code)
                    )
                    if df is not None and not df.empty:
                        limit = source_cfg.limit if source_cfg.limit > 0 else len(df)
                        for _, row in df.head(limit).iterrows():
                            title = str(row.get("æ–°é—»æ ‡é¢˜", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("æ–°é—»å†…å®¹", ""))[:1000],
                                    "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                    "source": "ä¸œè´¢ä¸ªè‚¡",
                                    "url": str(row.get("æ–°é—»é“¾æ¥", "")),
                                    "related_stocks": [clean_code]
                                })
                        logger.info(f"ä¸œè´¢ä¸ªè‚¡æ–°é—»({stock_name or clean_code}): {len(news_list)}æ¡")
                except Exception as e:
                    logger.debug(f"stock_news_em({clean_code})å¤±è´¥: {e}")

            # 2. å·¨æ½®ä¸ªè‚¡å…¬å‘Š
            source_cfg = config.stock_sources.get(NewsSourceType.CNINFO_STOCK.value)
            if source_cfg and source_cfg.enabled:
                cninfo_news = await self._fetch_cninfo_stock(clean_code, source_cfg.days_back)
                news_list.extend(cninfo_news)

            # 3. å·¨æ½®ä¸ªè‚¡æ–°é—»ï¼ˆp_info3030å¸¦è‚¡ç¥¨ä»£ç ï¼‰
            source_cfg = config.stock_sources.get(NewsSourceType.CNINFO_STOCK_NEWS.value)
            if source_cfg and source_cfg.enabled:
                cninfo_stock_news = await self._fetch_cninfo_news(
                    days_back=source_cfg.days_back,
                    stock_code=clean_code
                )
                news_list.extend(cninfo_stock_news)

            # å¯¹æ‰€æœ‰æ–°é—»è¿›è¡Œæƒ…ç»ªåˆ†æ
            if news_list and self._sentiment_engine:
                for news_item in news_list:
                    if not news_item.get('sentiment'):
                        try:
                            title = news_item.get('title', '')
                            content = news_item.get('content', '')
                            sentiment_result = self._sentiment_engine.analyze(title, content)
                            news_item['sentiment'] = sentiment_result.get('sentiment', 'neutral')
                            news_item['sentiment_score'] = sentiment_result.get('score', 50)
                        except Exception as e:
                            news_item['sentiment'] = 'neutral'
                            news_item['sentiment_score'] = 50

            logger.info(f"ä¸ªè‚¡æ–°é—»è·å–å®Œæˆ({stock_name or clean_code})ï¼Œå…± {len(news_list)} æ¡")
            return news_list

        except Exception as e:
            logger.error(f"è·å–ä¸ªè‚¡æ–°é—»å¤±è´¥({stock_code}): {e}")
            return []

    async def _fetch_cninfo_stock(self, stock_code: str, days_back: int = 30) -> List[Dict]:
        """è·å–å·¨æ½®ä¸ªè‚¡å…¬å‘Š"""
        try:
            from backend.dataflows.announcement.cninfo_api import get_cninfo_api_client, CninfoConfig

            if not CninfoConfig.is_configured():
                logger.debug("å·¨æ½®APIæœªé…ç½®ï¼Œè·³è¿‡è·å–")
                return []

            client = get_cninfo_api_client()
            news_list = []

            try:
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')

                announcement_result = await client.get_announcement_info(
                    stock_code=stock_code,
                    start_date=start_date,
                    end_date=end_date,
                    page_size=100
                )
                if announcement_result.get('success') and announcement_result.get('data'):
                    for item in announcement_result['data']:
                        title = item.get('F002V', '')
                        if not title:
                            continue
                        pub_date = item.get('F001D', '')
                        pdf_url = item.get('F003V', '')
                        stock_name = item.get('SECNAME', '')
                        category = item.get('F006V', '')

                        importance = 'low'
                        urgency = 'low'
                        if any(kw in title for kw in ['ä¸šç»©é¢„å‘Š', 'ä¸šç»©å¿«æŠ¥', 'é‡å¤§', 'åœç‰Œ', 'å¤ç‰Œ', 'é£é™©æç¤º']):
                            importance = 'high'
                            urgency = 'high'
                        elif any(kw in title for kw in ['å¹´æŠ¥', 'å­£æŠ¥', 'ä¸­æŠ¥', 'åˆ†çº¢', 'å¢æŒ', 'å‡æŒ']):
                            importance = 'medium'
                            urgency = 'medium'

                        news_list.append({
                            "title": f"[{stock_name or 'å…¬å‘Š'}] {title}",
                            "content": f"åˆ†ç±»: {category}",
                            "pub_time": pub_date,
                            "source": "å·¨æ½®ä¸ªè‚¡å…¬å‘Š",
                            "url": pdf_url,
                            "announcement_type": "stock_announcement",
                            "importance": importance,
                            "urgency": urgency,
                            "related_stocks": [stock_code]
                        })
                    logger.info(f"å·¨æ½®ä¸ªè‚¡å…¬å‘Š({stock_code}): {len(news_list)}æ¡")
            except Exception as e:
                logger.warning(f"è·å–å·¨æ½®ä¸ªè‚¡å…¬å‘Šå¤±è´¥({stock_code}): {e}")

            return news_list

        except Exception as e:
            logger.error(f"è·å–å·¨æ½®ä¸ªè‚¡å…¬å‘Šå¤±è´¥({stock_code}): {e}")
            return []

    async def fetch_hot_stocks_news(self) -> List[Dict]:
        """
        è·å–çƒ­é—¨è‚¡ç¥¨æ–°é—»ï¼ˆç”¨äºå¸‚åœºæ–°é—»ä¸­è¡¥å……ä¸ªè‚¡æ–°é—»ï¼‰
        ä»é…ç½®çš„çƒ­é—¨è‚¡ç¥¨åˆ—è¡¨ä¸­è·å–æ–°é—»
        """
        try:
            import akshare as ak
            loop = asyncio.get_event_loop()
            news_list = []
            config = self._config_manager.config

            hot_stocks = config.hot_stocks
            if not hot_stocks:
                return []

            source_cfg = config.stock_sources.get(NewsSourceType.STOCK_NEWS_EM.value)
            if not source_cfg or not source_cfg.enabled:
                return []

            limit_per_stock = source_cfg.limit if source_cfg.limit > 0 else 20

            for symbol in hot_stocks:
                try:
                    df = await loop.run_in_executor(
                        self._executor,
                        lambda s=symbol: ak.stock_news_em(symbol=s)
                    )
                    if df is not None and not df.empty:
                        for _, row in df.head(limit_per_stock).iterrows():
                            title = str(row.get("æ–°é—»æ ‡é¢˜", ""))
                            if title:
                                news_list.append({
                                    "title": title,
                                    "content": str(row.get("æ–°é—»å†…å®¹", ""))[:1000],
                                    "pub_time": str(row.get("å‘å¸ƒæ—¶é—´", "")),
                                    "source": "ä¸œè´¢ä¸ªè‚¡",
                                    "url": str(row.get("æ–°é—»é“¾æ¥", "")),
                                    "related_stocks": [symbol]
                                })
                except Exception as e:
                    logger.debug(f"stock_news_em({symbol})å¤±è´¥: {e}")
                    continue

            logger.info(f"çƒ­é—¨è‚¡ç¥¨æ–°é—»: {len(news_list)}æ¡ (æ¥è‡ª{len(hot_stocks)}åªè‚¡ç¥¨)")
            return news_list

        except Exception as e:
            logger.error(f"è·å–çƒ­é—¨è‚¡ç¥¨æ–°é—»å¤±è´¥: {e}")
            return []

    # ==================== é…ç½®ç®¡ç† ====================

    def get_news_config(self) -> Dict:
        """è·å–æ–°é—»é…ç½®"""
        return self._config_manager.get_config()

    def update_news_config(self, data: Dict) -> bool:
        """æ›´æ–°æ–°é—»é…ç½®"""
        return self._config_manager.update_config(data)

    def update_source_config(self, source_type: str, updates: Dict) -> bool:
        """æ›´æ–°å•ä¸ªæ•°æ®æºé…ç½®"""
        return self._config_manager.update_source_config(source_type, updates)

    def update_cninfo_config(self, updates: Dict) -> bool:
        """æ›´æ–°å·¨æ½®é…ç½®"""
        return self._config_manager.update_cninfo_config(updates)

    def update_hot_stocks(self, stocks: List[str]) -> bool:
        """æ›´æ–°çƒ­é—¨è‚¡ç¥¨åˆ—è¡¨"""
        return self._config_manager.update_hot_stocks(stocks)

_monitor_center = None

def get_news_monitor_center() -> NewsMonitorCenter:
    global _monitor_center
    if _monitor_center is None:
        _monitor_center = NewsMonitorCenter()
    return _monitor_center
