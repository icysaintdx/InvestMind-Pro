"""
æ–°é—»æ•°æ®æœåŠ¡
æä¾›ç»Ÿä¸€çš„æ–°é—»æ•°æ®å­˜å‚¨ã€æŸ¥è¯¢ã€ç»Ÿè®¡å’Œç®¡ç†åŠŸèƒ½
å‚è€ƒ TradingAgents-CN çš„è®¾è®¡ï¼Œé€‚é… SQLite æ•°æ®åº“
"""

import hashlib
import logging
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any, Union
from dataclasses import dataclass, field
from sqlalchemy.orm import Session
from sqlalchemy import func, desc, and_, or_

from backend.database.models import StockNewsRecord, MonitoredStock
from backend.database.database import get_db
from backend.dataflows.news.news_filter import NewsRelevanceFilter, get_company_name, NEWS_QUALITY_CONFIG
from backend.dataflows.news.sentiment_engine import SentimentEngine

logger = logging.getLogger(__name__)


@dataclass
class NewsQueryParams:
    """æ–°é—»æŸ¥è¯¢å‚æ•°"""
    symbol: Optional[str] = None
    symbols: Optional[List[str]] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    sentiment: Optional[str] = None  # positive/negative/neutral
    urgency: Optional[str] = None  # critical/high/medium/low
    report_type: Optional[str] = None  # financial/announcement/news/policy/research
    source: Optional[str] = None
    keywords: Optional[List[str]] = None
    min_score: Optional[int] = None  # æœ€ä½æƒ…ç»ªåˆ†æ•°
    limit: int = 50
    skip: int = 0
    sort_by: str = "pub_time"
    sort_order: str = "desc"  # asc/desc


@dataclass
class NewsStats:
    """æ–°é—»ç»Ÿè®¡ä¿¡æ¯"""
    total_count: int = 0
    positive_count: int = 0
    negative_count: int = 0
    neutral_count: int = 0
    critical_count: int = 0
    high_count: int = 0
    medium_count: int = 0
    low_count: int = 0
    sources: Dict[str, int] = field(default_factory=dict)
    report_types: Dict[str, int] = field(default_factory=dict)
    avg_sentiment_score: float = 0.0
    sentiment_trend: str = "neutral"  # bullish/bearish/neutral


class NewsDataService:
    """æ–°é—»æ•°æ®æœåŠ¡"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.sentiment_engine = SentimentEngine()

    def _generate_news_id(self, title: str, pub_time: datetime) -> str:
        """ç”Ÿæˆæ–°é—»å”¯ä¸€ID"""
        content = f"{title}_{pub_time.isoformat() if pub_time else ''}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()

    def _assess_source_quality(self, source: str) -> str:
        """è¯„ä¼°æ–°é—»æ¥æºè´¨é‡"""
        if not source:
            return "unknown"

        source_lower = source.lower()

        for high_source in NEWS_QUALITY_CONFIG['high_quality_sources']:
            if high_source.lower() in source_lower:
                return "high"

        for medium_source in NEWS_QUALITY_CONFIG['medium_quality_sources']:
            if medium_source.lower() in source_lower:
                return "medium"

        for low_source in NEWS_QUALITY_CONFIG['low_quality_sources']:
            if low_source.lower() in source_lower:
                return "low"

        return "unknown"

    def save_news(
        self,
        db: Session,
        ts_code: str,
        news_list: List[Dict[str, Any]],
        apply_filter: bool = True,
        min_relevance_score: float = 30
    ) -> Dict[str, int]:
        """
        ä¿å­˜æ–°é—»æ•°æ®

        Args:
            db: æ•°æ®åº“ä¼šè¯
            ts_code: è‚¡ç¥¨ä»£ç 
            news_list: æ–°é—»åˆ—è¡¨
            apply_filter: æ˜¯å¦åº”ç”¨ç›¸å…³æ€§è¿‡æ»¤
            min_relevance_score: æœ€ä½ç›¸å…³æ€§è¯„åˆ†

        Returns:
            ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        """
        if not news_list:
            return {"saved": 0, "skipped": 0, "filtered": 0, "duplicate": 0}

        stats = {"saved": 0, "skipped": 0, "filtered": 0, "duplicate": 0}

        # åˆ›å»ºè¿‡æ»¤å™¨
        news_filter = None
        if apply_filter:
            company_name = get_company_name(ts_code)
            news_filter = NewsRelevanceFilter(ts_code, company_name)

        for news in news_list:
            try:
                title = news.get('title', news.get('æ–°é—»æ ‡é¢˜', ''))
                content = news.get('content', news.get('æ–°é—»å†…å®¹', ''))

                if not title:
                    stats["skipped"] += 1
                    continue

                # åº”ç”¨ç›¸å…³æ€§è¿‡æ»¤
                if news_filter:
                    relevance_score = news_filter.calculate_relevance_score(title, content)
                    if relevance_score < min_relevance_score:
                        stats["filtered"] += 1
                        continue

                # è§£æå‘å¸ƒæ—¶é—´
                pub_time = news.get('pub_time', news.get('å‘å¸ƒæ—¶é—´'))
                if isinstance(pub_time, str):
                    try:
                        pub_time = datetime.fromisoformat(pub_time.replace('Z', '+00:00'))
                    except:
                        pub_time = datetime.utcnow()
                elif not isinstance(pub_time, datetime):
                    pub_time = datetime.utcnow()

                # ç”Ÿæˆæ–°é—»ID
                news_id = self._generate_news_id(title, pub_time)

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = db.query(StockNewsRecord).filter(
                    StockNewsRecord.news_id == news_id
                ).first()

                if existing:
                    stats["duplicate"] += 1
                    continue

                # æƒ…ç»ªåˆ†æ
                sentiment_result = self.sentiment_engine.analyze(title, content)

                # åˆ›å»ºæ–°é—»è®°å½•
                news_record = StockNewsRecord(
                    ts_code=ts_code,
                    news_id=news_id,
                    title=title,
                    content=content[:5000] if content else None,  # é™åˆ¶å†…å®¹é•¿åº¦
                    summary=news.get('summary', news.get('æ‘˜è¦', ''))[:1000] if news.get('summary') or news.get('æ‘˜è¦') else None,
                    source=news.get('source', news.get('æ¥æº', '')),
                    url=news.get('url', news.get('é“¾æ¥', '')),
                    pub_time=pub_time,
                    sentiment=sentiment_result.get('sentiment', 'neutral'),
                    sentiment_score=sentiment_result.get('score', 50),
                    urgency=sentiment_result.get('urgency', 'medium'),
                    report_type=sentiment_result.get('report_type', 'news'),
                    keywords=sentiment_result.get('keywords', [])
                )

                db.add(news_record)
                stats["saved"] += 1

            except Exception as e:
                self.logger.error(f"ä¿å­˜æ–°é—»å¤±è´¥: {e}")
                stats["skipped"] += 1

        try:
            db.commit()
            self.logger.info(f"ğŸ“° æ–°é—»ä¿å­˜å®Œæˆ: {ts_code}, ä¿å­˜={stats['saved']}, è¿‡æ»¤={stats['filtered']}, é‡å¤={stats['duplicate']}")
        except Exception as e:
            db.rollback()
            self.logger.error(f"æäº¤æ–°é—»æ•°æ®å¤±è´¥: {e}")
            raise

        return stats

    def query_news(
        self,
        db: Session,
        params: NewsQueryParams
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥è¯¢æ–°é—»æ•°æ®

        Args:
            db: æ•°æ®åº“ä¼šè¯
            params: æŸ¥è¯¢å‚æ•°

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        query = db.query(StockNewsRecord)

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        if params.symbol:
            query = query.filter(StockNewsRecord.ts_code == params.symbol)
        elif params.symbols:
            query = query.filter(StockNewsRecord.ts_code.in_(params.symbols))

        if params.start_time:
            query = query.filter(StockNewsRecord.pub_time >= params.start_time)
        if params.end_time:
            query = query.filter(StockNewsRecord.pub_time <= params.end_time)

        if params.sentiment:
            query = query.filter(StockNewsRecord.sentiment == params.sentiment)
        if params.urgency:
            query = query.filter(StockNewsRecord.urgency == params.urgency)
        if params.report_type:
            query = query.filter(StockNewsRecord.report_type == params.report_type)
        if params.source:
            query = query.filter(StockNewsRecord.source.like(f"%{params.source}%"))
        if params.min_score:
            query = query.filter(StockNewsRecord.sentiment_score >= params.min_score)

        # å…³é”®è¯æœç´¢
        if params.keywords:
            keyword_filters = []
            for keyword in params.keywords:
                keyword_filters.append(StockNewsRecord.title.like(f"%{keyword}%"))
                keyword_filters.append(StockNewsRecord.content.like(f"%{keyword}%"))
            query = query.filter(or_(*keyword_filters))

        # æ’åº
        if params.sort_by == "pub_time":
            order_col = StockNewsRecord.pub_time
        elif params.sort_by == "sentiment_score":
            order_col = StockNewsRecord.sentiment_score
        elif params.sort_by == "created_at":
            order_col = StockNewsRecord.created_at
        else:
            order_col = StockNewsRecord.pub_time

        if params.sort_order == "desc":
            query = query.order_by(desc(order_col))
        else:
            query = query.order_by(order_col)

        # åˆ†é¡µ
        query = query.offset(params.skip).limit(params.limit)

        # æ‰§è¡ŒæŸ¥è¯¢
        results = query.all()
        return [record.to_dict() for record in results]

    def get_latest_news(
        self,
        db: Session,
        ts_code: Optional[str] = None,
        limit: int = 20,
        hours_back: int = 24
    ) -> List[Dict[str, Any]]:
        """è·å–æœ€æ–°æ–°é—»"""
        start_time = datetime.utcnow() - timedelta(hours=hours_back)

        params = NewsQueryParams(
            symbol=ts_code,
            start_time=start_time,
            limit=limit,
            sort_by="pub_time",
            sort_order="desc"
        )

        return self.query_news(db, params)

    def search_news(
        self,
        db: Session,
        query_text: str,
        ts_code: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """
        å…¨æ–‡æœç´¢æ–°é—»

        Args:
            db: æ•°æ®åº“ä¼šè¯
            query_text: æœç´¢æ–‡æœ¬
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¯é€‰ï¼‰
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        query = db.query(StockNewsRecord)

        if ts_code:
            query = query.filter(StockNewsRecord.ts_code == ts_code)

        # æœç´¢æ ‡é¢˜å’Œå†…å®¹
        search_filter = or_(
            StockNewsRecord.title.like(f"%{query_text}%"),
            StockNewsRecord.content.like(f"%{query_text}%"),
            StockNewsRecord.summary.like(f"%{query_text}%")
        )
        query = query.filter(search_filter)

        # æŒ‰å‘å¸ƒæ—¶é—´æ’åº
        query = query.order_by(desc(StockNewsRecord.pub_time))
        query = query.limit(limit)

        results = query.all()
        return [record.to_dict() for record in results]

    def get_news_statistics(
        self,
        db: Session,
        ts_code: Optional[str] = None,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> NewsStats:
        """
        è·å–æ–°é—»ç»Ÿè®¡ä¿¡æ¯

        Args:
            db: æ•°æ®åº“ä¼šè¯
            ts_code: è‚¡ç¥¨ä»£ç 
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´

        Returns:
            æ–°é—»ç»Ÿè®¡ä¿¡æ¯
        """
        query = db.query(StockNewsRecord)

        if ts_code:
            query = query.filter(StockNewsRecord.ts_code == ts_code)
        if start_time:
            query = query.filter(StockNewsRecord.pub_time >= start_time)
        if end_time:
            query = query.filter(StockNewsRecord.pub_time <= end_time)

        # è·å–æ‰€æœ‰è®°å½•
        records = query.all()

        if not records:
            return NewsStats()

        # ç»Ÿè®¡
        stats = NewsStats()
        stats.total_count = len(records)

        sentiment_scores = []
        for record in records:
            # æƒ…ç»ªç»Ÿè®¡
            if record.sentiment == 'positive':
                stats.positive_count += 1
            elif record.sentiment == 'negative':
                stats.negative_count += 1
            else:
                stats.neutral_count += 1

            # ç´§æ€¥ç¨‹åº¦ç»Ÿè®¡
            if record.urgency == 'critical':
                stats.critical_count += 1
            elif record.urgency == 'high':
                stats.high_count += 1
            elif record.urgency == 'medium':
                stats.medium_count += 1
            else:
                stats.low_count += 1

            # æ¥æºç»Ÿè®¡
            source = record.source or 'unknown'
            stats.sources[source] = stats.sources.get(source, 0) + 1

            # æŠ¥å‘Šç±»å‹ç»Ÿè®¡
            report_type = record.report_type or 'news'
            stats.report_types[report_type] = stats.report_types.get(report_type, 0) + 1

            # æƒ…ç»ªåˆ†æ•°
            if record.sentiment_score:
                sentiment_scores.append(record.sentiment_score)

        # è®¡ç®—å¹³å‡æƒ…ç»ªåˆ†æ•°
        if sentiment_scores:
            stats.avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)

        # åˆ¤æ–­æƒ…ç»ªè¶‹åŠ¿
        if stats.positive_count > stats.negative_count * 1.5:
            stats.sentiment_trend = "bullish"
        elif stats.negative_count > stats.positive_count * 1.5:
            stats.sentiment_trend = "bearish"
        else:
            stats.sentiment_trend = "neutral"

        return stats

    def get_sentiment_trend(
        self,
        db: Session,
        ts_code: str,
        days: int = 7
    ) -> List[Dict[str, Any]]:
        """
        è·å–æƒ…ç»ªè¶‹åŠ¿ï¼ˆæŒ‰å¤©ç»Ÿè®¡ï¼‰

        Args:
            db: æ•°æ®åº“ä¼šè¯
            ts_code: è‚¡ç¥¨ä»£ç 
            days: å¤©æ•°

        Returns:
            æ¯æ—¥æƒ…ç»ªç»Ÿè®¡åˆ—è¡¨
        """
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=days)

        query = db.query(StockNewsRecord).filter(
            StockNewsRecord.ts_code == ts_code,
            StockNewsRecord.pub_time >= start_time,
            StockNewsRecord.pub_time <= end_time
        ).all()

        # æŒ‰å¤©åˆ†ç»„ç»Ÿè®¡
        daily_stats = {}
        for record in query:
            if record.pub_time:
                date_key = record.pub_time.strftime('%Y-%m-%d')
                if date_key not in daily_stats:
                    daily_stats[date_key] = {
                        'date': date_key,
                        'total': 0,
                        'positive': 0,
                        'negative': 0,
                        'neutral': 0,
                        'avg_score': 0,
                        'scores': []
                    }

                daily_stats[date_key]['total'] += 1
                if record.sentiment == 'positive':
                    daily_stats[date_key]['positive'] += 1
                elif record.sentiment == 'negative':
                    daily_stats[date_key]['negative'] += 1
                else:
                    daily_stats[date_key]['neutral'] += 1

                if record.sentiment_score:
                    daily_stats[date_key]['scores'].append(record.sentiment_score)

        # è®¡ç®—æ¯æ—¥å¹³å‡åˆ†æ•°
        result = []
        for date_key in sorted(daily_stats.keys()):
            stats = daily_stats[date_key]
            if stats['scores']:
                stats['avg_score'] = sum(stats['scores']) / len(stats['scores'])
            del stats['scores']
            result.append(stats)

        return result

    def delete_old_news(
        self,
        db: Session,
        days_to_keep: int = 90
    ) -> int:
        """
        åˆ é™¤è¿‡æœŸæ–°é—»

        Args:
            db: æ•°æ®åº“ä¼šè¯
            days_to_keep: ä¿ç•™å¤©æ•°

        Returns:
            åˆ é™¤çš„è®°å½•æ•°é‡
        """
        cutoff_date = datetime.utcnow() - timedelta(days=days_to_keep)

        deleted_count = db.query(StockNewsRecord).filter(
            StockNewsRecord.created_at < cutoff_date
        ).delete()

        db.commit()
        self.logger.info(f"ğŸ—‘ï¸ åˆ é™¤è¿‡æœŸæ–°é—»: {deleted_count}æ¡")

        return deleted_count

    def get_news_by_id(
        self,
        db: Session,
        news_id: str
    ) -> Optional[Dict[str, Any]]:
        """æ ¹æ®IDè·å–æ–°é—»"""
        record = db.query(StockNewsRecord).filter(
            StockNewsRecord.news_id == news_id
        ).first()

        return record.to_dict() if record else None


# å…¨å±€æœåŠ¡å®ä¾‹
_news_data_service = None


def get_news_data_service() -> NewsDataService:
    """è·å–æ–°é—»æ•°æ®æœåŠ¡å®ä¾‹"""
    global _news_data_service
    if _news_data_service is None:
        _news_data_service = NewsDataService()
        logger.info("âœ… æ–°é—»æ•°æ®æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
    return _news_data_service
