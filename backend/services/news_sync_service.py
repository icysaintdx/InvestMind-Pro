"""
æ–°é—»æ•°æ®åŒæ­¥æœåŠ¡
åå°å¼‚æ­¥åŒæ­¥æ–°é—»æ•°æ®ï¼Œæ”¯æŒå¤šæ•°æ®æº
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor
import threading

from backend.database.database import get_db, SessionLocal
from backend.database.models import MonitoredStock, StockNewsRecord
from backend.services.news_data_service import NewsDataService, get_news_data_service
from backend.dataflows.news.multi_source_news_aggregator import MultiSourceNewsAggregator

logger = logging.getLogger(__name__)


@dataclass
class SyncTask:
    """åŒæ­¥ä»»åŠ¡"""
    ts_code: str
    stock_name: str
    status: str = "pending"  # pending/running/completed/failed
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    result: Dict[str, Any] = field(default_factory=dict)
    error: Optional[str] = None


@dataclass
class SyncStats:
    """åŒæ­¥ç»Ÿè®¡"""
    total_tasks: int = 0
    completed_tasks: int = 0
    failed_tasks: int = 0
    total_news_saved: int = 0
    total_news_filtered: int = 0
    total_news_duplicate: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    duration_seconds: float = 0


class NewsSyncService:
    """æ–°é—»åŒæ­¥æœåŠ¡"""

    def __init__(self, max_workers: int = 3):
        """
        åˆå§‹åŒ–åŒæ­¥æœåŠ¡

        Args:
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
        """
        self.logger = logging.getLogger(__name__)
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.news_service = get_news_data_service()

        # åŒæ­¥çŠ¶æ€
        self._is_running = False
        self._current_sync_id = None
        self._tasks: Dict[str, SyncTask] = {}
        self._stats = SyncStats()
        self._lock = threading.Lock()

        # æ•°æ®æºèšåˆå™¨
        self._aggregator = None

    def _get_aggregator(self) -> MultiSourceNewsAggregator:
        """è·å–æ•°æ®æºèšåˆå™¨"""
        if self._aggregator is None:
            self._aggregator = MultiSourceNewsAggregator()
        return self._aggregator

    def _sync_stock_news(self, ts_code: str, stock_name: str) -> Dict[str, Any]:
        """
        åŒæ­¥å•ä¸ªè‚¡ç¥¨çš„æ–°é—»

        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°

        Returns:
            åŒæ­¥ç»“æœ
        """
        result = {
            "ts_code": ts_code,
            "stock_name": stock_name,
            "saved": 0,
            "filtered": 0,
            "duplicate": 0,
            "skipped": 0,
            "error": None
        }

        try:
            # è·å–æ–°é—»æ•°æ®
            aggregator = self._get_aggregator()
            news_list = aggregator.get_stock_news(ts_code, max_news=50)

            if not news_list:
                self.logger.info(f"ğŸ“° {ts_code} æ²¡æœ‰è·å–åˆ°æ–°é—»")
                return result

            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            formatted_news = []
            for news in news_list:
                formatted_news.append({
                    'title': news.get('title', news.get('æ–°é—»æ ‡é¢˜', '')),
                    'content': news.get('content', news.get('æ–°é—»å†…å®¹', '')),
                    'summary': news.get('summary', news.get('æ‘˜è¦', '')),
                    'source': news.get('source', news.get('æ¥æº', '')),
                    'url': news.get('url', news.get('é“¾æ¥', '')),
                    'pub_time': news.get('pub_time', news.get('å‘å¸ƒæ—¶é—´'))
                })

            # ä¿å­˜åˆ°æ•°æ®åº“
            db = SessionLocal()
            try:
                save_result = self.news_service.save_news(
                    db=db,
                    ts_code=ts_code,
                    news_list=formatted_news,
                    apply_filter=True,
                    min_relevance_score=30
                )

                result["saved"] = save_result.get("saved", 0)
                result["filtered"] = save_result.get("filtered", 0)
                result["duplicate"] = save_result.get("duplicate", 0)
                result["skipped"] = save_result.get("skipped", 0)

            finally:
                db.close()

            self.logger.info(f"âœ… {ts_code} æ–°é—»åŒæ­¥å®Œæˆ: ä¿å­˜={result['saved']}, è¿‡æ»¤={result['filtered']}")

        except Exception as e:
            result["error"] = str(e)
            self.logger.error(f"âŒ {ts_code} æ–°é—»åŒæ­¥å¤±è´¥: {e}")

        return result

    def start_sync(
        self,
        stock_codes: Optional[List[str]] = None,
        sync_all_monitored: bool = False
    ) -> str:
        """
        å¯åŠ¨åŒæ­¥ä»»åŠ¡

        Args:
            stock_codes: è¦åŒæ­¥çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
            sync_all_monitored: æ˜¯å¦åŒæ­¥æ‰€æœ‰ç›‘æ§è‚¡ç¥¨

        Returns:
            åŒæ­¥ä»»åŠ¡ID
        """
        if self._is_running:
            self.logger.warning("âš ï¸ åŒæ­¥ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­")
            return self._current_sync_id

        # ç”ŸæˆåŒæ­¥ID
        sync_id = f"sync_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self._current_sync_id = sync_id
        self._is_running = True

        # é‡ç½®ç»Ÿè®¡
        self._stats = SyncStats()
        self._stats.start_time = datetime.now()
        self._tasks.clear()

        # è·å–è¦åŒæ­¥çš„è‚¡ç¥¨åˆ—è¡¨
        stocks_to_sync = []

        if sync_all_monitored:
            # ä»æ•°æ®åº“è·å–æ‰€æœ‰ç›‘æ§è‚¡ç¥¨
            db = SessionLocal()
            try:
                monitored = db.query(MonitoredStock).filter(
                    MonitoredStock.is_active == 1
                ).all()
                stocks_to_sync = [(s.ts_code, s.name) for s in monitored]
            finally:
                db.close()
        elif stock_codes:
            # ä½¿ç”¨æŒ‡å®šçš„è‚¡ç¥¨ä»£ç 
            stocks_to_sync = [(code, code) for code in stock_codes]

        if not stocks_to_sync:
            self.logger.warning("âš ï¸ æ²¡æœ‰è¦åŒæ­¥çš„è‚¡ç¥¨")
            self._is_running = False
            return sync_id

        self._stats.total_tasks = len(stocks_to_sync)

        # åˆ›å»ºä»»åŠ¡
        for ts_code, stock_name in stocks_to_sync:
            self._tasks[ts_code] = SyncTask(ts_code=ts_code, stock_name=stock_name)

        # å¯åŠ¨åå°åŒæ­¥
        threading.Thread(target=self._run_sync, args=(stocks_to_sync,), daemon=True).start()

        self.logger.info(f"ğŸš€ å¯åŠ¨æ–°é—»åŒæ­¥ä»»åŠ¡: {sync_id}, å…± {len(stocks_to_sync)} åªè‚¡ç¥¨")
        return sync_id

    def _run_sync(self, stocks_to_sync: List[tuple]):
        """è¿è¡ŒåŒæ­¥ä»»åŠ¡"""
        try:
            futures = []

            for ts_code, stock_name in stocks_to_sync:
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                with self._lock:
                    if ts_code in self._tasks:
                        self._tasks[ts_code].status = "running"
                        self._tasks[ts_code].start_time = datetime.now()

                # æäº¤ä»»åŠ¡
                future = self.executor.submit(self._sync_stock_news, ts_code, stock_name)
                futures.append((ts_code, future))

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for ts_code, future in futures:
                try:
                    result = future.result(timeout=120)  # 2åˆ†é’Ÿè¶…æ—¶

                    with self._lock:
                        if ts_code in self._tasks:
                            self._tasks[ts_code].status = "completed"
                            self._tasks[ts_code].end_time = datetime.now()
                            self._tasks[ts_code].result = result

                            if result.get("error"):
                                self._tasks[ts_code].status = "failed"
                                self._tasks[ts_code].error = result["error"]
                                self._stats.failed_tasks += 1
                            else:
                                self._stats.completed_tasks += 1
                                self._stats.total_news_saved += result.get("saved", 0)
                                self._stats.total_news_filtered += result.get("filtered", 0)
                                self._stats.total_news_duplicate += result.get("duplicate", 0)

                except Exception as e:
                    with self._lock:
                        if ts_code in self._tasks:
                            self._tasks[ts_code].status = "failed"
                            self._tasks[ts_code].end_time = datetime.now()
                            self._tasks[ts_code].error = str(e)
                            self._stats.failed_tasks += 1

                    self.logger.error(f"âŒ {ts_code} åŒæ­¥ä»»åŠ¡å¼‚å¸¸: {e}")

        finally:
            # å®ŒæˆåŒæ­¥
            self._stats.end_time = datetime.now()
            if self._stats.start_time:
                self._stats.duration_seconds = (self._stats.end_time - self._stats.start_time).total_seconds()

            self._is_running = False
            self.logger.info(f"âœ… æ–°é—»åŒæ­¥å®Œæˆ: æˆåŠŸ={self._stats.completed_tasks}, å¤±è´¥={self._stats.failed_tasks}, "
                           f"ä¿å­˜={self._stats.total_news_saved}æ¡, è€—æ—¶={self._stats.duration_seconds:.1f}ç§’")

    def get_sync_status(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥çŠ¶æ€"""
        with self._lock:
            tasks_status = {}
            for ts_code, task in self._tasks.items():
                tasks_status[ts_code] = {
                    "stock_name": task.stock_name,
                    "status": task.status,
                    "start_time": task.start_time.isoformat() if task.start_time else None,
                    "end_time": task.end_time.isoformat() if task.end_time else None,
                    "result": task.result,
                    "error": task.error
                }

            return {
                "sync_id": self._current_sync_id,
                "is_running": self._is_running,
                "stats": {
                    "total_tasks": self._stats.total_tasks,
                    "completed_tasks": self._stats.completed_tasks,
                    "failed_tasks": self._stats.failed_tasks,
                    "total_news_saved": self._stats.total_news_saved,
                    "total_news_filtered": self._stats.total_news_filtered,
                    "total_news_duplicate": self._stats.total_news_duplicate,
                    "start_time": self._stats.start_time.isoformat() if self._stats.start_time else None,
                    "end_time": self._stats.end_time.isoformat() if self._stats.end_time else None,
                    "duration_seconds": self._stats.duration_seconds
                },
                "tasks": tasks_status
            }

    def stop_sync(self):
        """åœæ­¢åŒæ­¥"""
        if not self._is_running:
            return

        self.logger.info("â¹ï¸ æ­£åœ¨åœæ­¢åŒæ­¥ä»»åŠ¡...")
        self._is_running = False
        self.executor.shutdown(wait=False)
        self.executor = ThreadPoolExecutor(max_workers=self.max_workers)


# å…¨å±€æœåŠ¡å®ä¾‹
_news_sync_service = None


def get_news_sync_service() -> NewsSyncService:
    """è·å–æ–°é—»åŒæ­¥æœåŠ¡å®ä¾‹"""
    global _news_sync_service
    if _news_sync_service is None:
        _news_sync_service = NewsSyncService()
        logger.info("âœ… æ–°é—»åŒæ­¥æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
    return _news_sync_service


# ==================== å®šæ—¶åŒæ­¥è°ƒåº¦å™¨ ====================

class NewsSyncScheduler:
    """æ–°é—»åŒæ­¥è°ƒåº¦å™¨"""

    def __init__(self, sync_interval_minutes: int = 30):
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨

        Args:
            sync_interval_minutes: åŒæ­¥é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
        """
        self.sync_interval = sync_interval_minutes
        self.sync_service = get_news_sync_service()
        self._is_running = False
        self._scheduler_thread = None
        self.logger = logging.getLogger(__name__)

    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self._is_running:
            return

        self._is_running = True
        self._scheduler_thread = threading.Thread(target=self._run_scheduler, daemon=True)
        self._scheduler_thread.start()
        self.logger.info(f"â° æ–°é—»åŒæ­¥è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œé—´éš”: {self.sync_interval}åˆ†é’Ÿ")

    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self._is_running = False
        self.logger.info("â¹ï¸ æ–°é—»åŒæ­¥è°ƒåº¦å™¨å·²åœæ­¢")

    def _run_scheduler(self):
        """è¿è¡Œè°ƒåº¦å™¨"""
        while self._is_running:
            try:
                # æ£€æŸ¥æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´ï¼ˆ9:00-15:30ï¼‰
                now = datetime.now()
                hour = now.hour
                minute = now.minute

                # äº¤æ˜“æ—¶é—´å†…æ›´é¢‘ç¹åŒæ­¥
                if 9 <= hour < 16:
                    self.logger.info("ğŸ“… å¼€å§‹å®šæ—¶æ–°é—»åŒæ­¥...")
                    self.sync_service.start_sync(sync_all_monitored=True)

                    # ç­‰å¾…åŒæ­¥å®Œæˆ
                    while self.sync_service._is_running:
                        import time
                        time.sleep(5)

            except Exception as e:
                self.logger.error(f"âŒ å®šæ—¶åŒæ­¥å¼‚å¸¸: {e}")

            # ç­‰å¾…ä¸‹ä¸€æ¬¡åŒæ­¥
            import time
            time.sleep(self.sync_interval * 60)


# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
_news_sync_scheduler = None


def get_news_sync_scheduler() -> NewsSyncScheduler:
    """è·å–æ–°é—»åŒæ­¥è°ƒåº¦å™¨å®ä¾‹"""
    global _news_sync_scheduler
    if _news_sync_scheduler is None:
        _news_sync_scheduler = NewsSyncScheduler()
    return _news_sync_scheduler
