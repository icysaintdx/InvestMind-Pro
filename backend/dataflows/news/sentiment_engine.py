"""
æ–°é—»æƒ…ç»ªåˆ†æå¼•æ“
åŸºäºå…³é”®è¯ã€æƒ…æ„Ÿè¯å…¸å’ŒNLPæŠ€æœ¯è¿›è¡Œæƒ…ç»ªæ‰“åˆ†
"""

from typing import List, Dict, Optional
import re
from datetime import datetime

from backend.utils.logging_config import get_logger

logger = get_logger("news.sentiment")


class SentimentEngine:
    """æƒ…ç»ªåˆ†æå¼•æ“ - å¢å¼ºç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æƒ…æ„Ÿè¯å…¸"""
        
        # ==================== æ­£é¢è¯æ±‡è¯å…¸ ====================
        
        # ä¸šç»©åˆ©å¥½ç±»
        self.positive_performance = {
            'å¢é•¿', 'ä¸Šæ¶¨', 'ç›ˆåˆ©', 'çªç ´', 'åˆ›æ–°é«˜', 'è¶…é¢„æœŸ', 'å¤§æ¶¨', 'æš´æ¶¨',
            'ç¿»å€', 'ç¿»ç•ª', 'é«˜å¢é•¿', 'çˆ†å‘å¼å¢é•¿', 'å¤§å¹…å¢é•¿', 'é«˜ä½è¿è¡Œ',
            'ä¸šç»©äº®çœ¼', 'ä¸šç»©ä¼˜ç§€', 'ä¸šç»©ç¿»ç•ª', 'ä¸šç»©åŒå‡»', 'ä¸šç»©å˜è„¸',
            'å‡€åˆ©æ¶¦å¢é•¿', 'è¥æ”¶å¢é•¿', 'æ¯›åˆ©ç‡æå‡', 'åˆ©æ¶¦ç‡ä¸Šå‡',
            'æ‰­äºä¸ºç›ˆ', 'é¦–æ¬¡ç›ˆåˆ©', 'ç»©ä¼˜', 'è¶…é¢å®Œæˆ', 'ç¨³æ­¥å¢é•¿'
        }
        
        # å¸‚åœºæƒ…ç»ªç§¯æç±»
        self.positive_market = {
            'åˆ©å¥½', 'å—ç›Š', 'çœ‹å¥½', 'ä¹è§‚', 'å¼ºåŠ²', 'å›å‡', 'å¤è‹', 'æå‡',
            'æ”¹å–„', 'ä¼˜åŒ–', 'çªå‡º', 'é¢†å…ˆ', 'ä¼˜åŠ¿', 'æ‰©å¼ ', 'å¢æŒ', 'ä¹°å…¥',
            'çƒ­ç‚¹', 'æ´»è·ƒ', 'çˆ†å‘', 'æœºä¼š', 'æ½œåŠ›', 'ä»·å€¼', 'ä½ä¼°', 'æ”¯æ’‘',
            'ç¨³å®š', 'å¼ºåŠ¿', 'æ”¾é‡', 'æ‹‰å‡', 'åå¼¹', 'åè½¬', 'çªç ´', 'åŠ é€Ÿ',
            'ç‰›å¸‚', 'ä¸Šæ”»', 'é‡ä»·é½å‡', 'é‡èƒ½æ”¾å¤§', 'ä¸»åŠ›å…¥åœº', 'èµ„é‡‘æµå…¥',
            'å¤šå¤´æ’åˆ—', 'å¤šå¤´å¼ºåŠ¿', 'æ¶ˆæ¯é¢åˆ©å¥½', 'æ”¿ç­–æ”¯æŒ', 'è¡Œä¸šå¤è‹'
        }
        
        # å…¬å¸è¿è¥æ­£é¢ç±»
        self.positive_operation = {
            'ä¸­æ ‡', 'åˆä½œ', 'åè®®', 'è®¢å•', 'å¹¶è´­', 'é‡ç»„', 'åˆ†çº¢', 'å›è´­',
            'ç­¾çº¦', 'ç­¾è®¢', 'å¾—æ ‡', 'å¤§å•', 'è¶…å¤§è®¢å•', 'æ ¸å¿ƒäº§å“',
            'æ–°å“å‘å¸ƒ', 'äº§å“å‡çº§', 'æŠ€æœ¯çªç ´', 'åˆ›æ–°äº§å“',
            'æˆ˜ç•¥åˆä½œ', 'æ·±åº¦åˆä½œ', 'é•¿æœŸåˆä½œ', 'æ¡†æ¶åè®®',
            'è‚¡æƒæ¿€åŠ±', 'å‘˜å·¥æŒè‚¡', 'ç®¡ç†å±‚å¢æŒ', 'å¤§è‚¡ä¸œå¢æŒ',
            'å¸‚åœºä»½é¢æå‡', 'å“ç‰Œä»·å€¼ä¸Šå‡', 'ç«äº‰åŠ›å¢å¼º'
        }
        
        # è¡Œä¸šæ”¿ç­–åˆ©å¥½ç±»
        self.positive_policy = {
            'æ”¿ç­–æ”¯æŒ', 'è¡¥è´´', 'æ¿€åŠ±', 'é¼“åŠ±', 'æ¨è¿›', 'æ¨åŠ¨', 'æ”¯æŒ',
            'å‡ç¨', 'å…ç¨', 'é€€ç¨', 'ä¼˜æƒ ', 'æ‰«éšœ', 'æ”¾å¼€', 'æ”¾å®½',
            'é¡¶å±‚è®¾è®¡', 'å›½å®¶æˆ˜ç•¥', 'è¡Œä¸šè§„åˆ’', 'å‘å±•è§„åˆ’',
            'é‡ç‚¹æ”¯æŒ', 'é‡ç‚¹åŸ¹è‚²', 'ç¤ºèŒƒå·¥ç¨‹', 'è¯•ç‚¹é¡¹ç›®'
        }
        
        # æŠ€æœ¯åˆ›æ–°ç±»
        self.positive_innovation = {
            'åˆ›æ–°', 'ç ”å‘', 'çªç ´', 'é¢†å…ˆ', 'é¦–å‘', 'è‡ªä¸»çŸ¥è¯†äº§æƒ',
            'ä¸“åˆ©', 'æ ¸å¿ƒæŠ€æœ¯', 'å…³é”®æŠ€æœ¯', 'å‰æ²¿æŠ€æœ¯', 'é«˜ç§‘æŠ€',
            'æ™ºèƒ½åŒ–', 'æ•°å­—åŒ–', 'è‡ªåŠ¨åŒ–', 'å‡çº§æ”¹é€ ', 'è½¬å‹å‡çº§',
            'AI', 'äººå·¥æ™ºèƒ½', 'å¤§æ•°æ®', 'äº‘è®¡ç®—', 'ç‰©è”ç½‘', '5G', 'åŒºå—é“¾'
        }
        
        # åˆå¹¶æ‰€æœ‰æ­£é¢è¯æ±‡
        self.positive_words = (
            self.positive_performance | self.positive_market | 
            self.positive_operation | self.positive_policy | self.positive_innovation
        )
        
        # ==================== è´Ÿé¢è¯æ±‡è¯å…¸ ====================
        
        # ä¸šç»©åˆ©ç©ºç±»
        self.negative_performance = {
            'ä¸‹è·Œ', 'äºæŸ', 'å‡å°‘', 'ä¸‹æ»‘', 'æš´è·Œ', 'å¤§è·Œ', 'è·³æ°´', 'é—ªå´©',
            'å·¨äº', 'äºæŸé¢', 'å‡€åˆ©æ¶¦ä¸‹æ»‘', 'è¥æ”¶ä¸‹é™', 'ä¸šç»©å˜è„¸',
            'ä¸šç»©äºæŸ', 'ä¸šç»©å¤§å¹…ä¸‹æ»‘', 'ä¸šç»©ä¸åŠé¢„æœŸ', 'é¦–äº',
            'æ¯›åˆ©ç‡ä¸‹é™', 'åˆ©æ¶¦ç‡ä¸‹æ»‘', 'ç›ˆåˆ©èƒ½åŠ›ä¸‹é™'
        }
        
        # å¸‚åœºæƒ…ç»ªæ¶ˆæç±»
        self.negative_market = {
            'åˆ©ç©º', 'ä¸åŠé¢„æœŸ', 'èç¼©', 'ä¸‹è¡Œ', 'ç–²è½¯', 'æ¶åŒ–', 'è¡°é€€', 'è­¦å‘Š',
            'å‡æŒ', 'æŠ›å”®', 'å–å‡º', 'çœ‹ç©º', 'æ‚²è§‚', 'æ‹…å¿§', 'é£é™©', 'å±æœº',
            'ç¼©é‡', 'è·Œç ´', 'å¤±å®ˆ', 'å¥—ç‰¢', 'å‰²è‚‰', 'è¸©é›·', 'çˆ†é›·', 'é»‘å¤©é¹…',
            'ç ´ä½', 'ä½è¿·', 'ç–²å¼±', 'æ‰¿å‹', 'æ‹–ç´¯', 'æ€è·Œ', 'ææ…Œ', 'è°ƒæ•´',
            'ç†Šå¸‚', 'ä¸‹æ”»', 'é‡ä»·é½è·Œ', 'é‡èƒ½èç¼©', 'ä¸»åŠ›å‡ºé€ƒ', 'èµ„é‡‘æµå‡º',
            'ç©ºå¤´æ’åˆ—', 'ç©ºå¤´å¼ºåŠ¿', 'æ¶ˆæ¯é¢åˆ©ç©º', 'æ”¿ç­–æ”¶ç´§', 'è¡Œä¸šä½è¿·'
        }
        
        # å…¬å¸é—®é¢˜ç±»
        self.negative_operation = {
            'è¿è§„', 'å¤„ç½š', 'è°ƒæŸ¥', 'åœç‰Œ', 'ST', 'é€€å¸‚', 'è¯‰è®¼', 'çº çº·',
            'è´¨ç–‘', 'è´¨æŠ¼', 'å†»ç»“', 'å°é—¨', 'æŸ¥å°', 'ç¨½æŸ¥', 'ç«‹æ¡ˆ',
            'è´¢åŠ¡é€ å‡', 'è´¢åŠ¡è™šå‡', 'ä¼šè®¡å¤±è¯¯', 'å†…æ§ç¼ºé™·',
            'é«˜ç®¡ç¦»èŒ', 'é«˜ç®¡è¾©èŒ', 'æ ¸å¿ƒäººå‘˜ç¦»èŒ', 'å›¢é˜ŸåŠ¨è¡',
            'å€ºåŠ¡è¿çº¦', 'èµ„é‡‘é“¾ç´§å¼ ', 'ç°é‡‘æµé—®é¢˜', 'ç»è¥å›°éš¾',
            'äº§å“å¬å›', 'è´¨é‡é—®é¢˜', 'å®‰å…¨éšæ‚£', 'äº‹æ•…'
        }
        
        # ç›‘ç®¡é£é™©ç±»
        self.negative_regulation = {
            'é—®è¯¢å‡½', 'ç›‘ç®¡å‡½', 'è­¦ç¤ºå‡½', 'å…³æ³¨å‡½', 'æ‰¹å¤',
            'ä¸äºˆæ‰¹å‡†', 'ç»ˆæ­¢å®¡æŸ¥', 'åœæ­¢äº¤æ˜“', 'å¼ºåˆ¶é€€å¸‚',
            'å…¬å¼€è°´è´£', 'é€šæŠ¥æ‰¹è¯„', 'è¡Œæ”¿å¤„ç½š', 'ç½šæ¬¾',
            'é™åˆ¶æ¶ˆè´¹', 'å¤±ä¿¡è¢«æ‰§è¡Œäºº', 'é™åˆ¶é«˜æ¶ˆè´¹'
        }
        
        # åˆå¹¶æ‰€æœ‰è´Ÿé¢è¯æ±‡
        self.negative_words = (
            self.negative_performance | self.negative_market | 
            self.negative_operation | self.negative_regulation
        )
        
        # ==================== å¼ºåŒ–è¯ï¼ˆåŠ æƒï¼‰ ====================
        self.intensifiers = {
            # ç¨‹åº¦å¼ºåŒ–
            'å¤§å¹…': 1.5, 'æ˜¾è‘—': 1.4, 'æ˜æ˜¾': 1.3, 'å¤§': 1.2,
            'è¶…': 1.4, 'æ': 1.5, 'éå¸¸': 1.3, 'ååˆ†': 1.3,
            'æåº¦': 1.5, 'æå…¶': 1.4, 'ç›¸å½“': 1.2, 'æ¯”è¾ƒ': 1.1,
            # æ—¶é—´å¼ºåŒ–
            'çªç„¶': 1.3, 'æ€¥å‰§': 1.4, 'è¿…é€Ÿ': 1.3, 'å¿«é€Ÿ': 1.2,
            'æŒç»­': 1.2, 'è¿ç»­': 1.3, 'ä¸€ç›´': 1.2,
            # èŒƒå›´å¼ºåŒ–
            'å…¨é¢': 1.3, 'å…¨éƒ¨': 1.3, 'æ‰€æœ‰': 1.2, 'å¤šä¸ª': 1.2,
            'æ™®é': 1.2, 'å¤§é‡': 1.3, 'å¤§è§„æ¨¡': 1.4,
            # ç¡®å®šæ€§å¼ºåŒ–
            'ç¡®å®š': 1.2, 'æ˜ç¡®': 1.2, 'è‚¯å®š': 1.2, 'å¿…ç„¶': 1.3,
            'ä¸€å®š': 1.2, 'å¿…é¡»': 1.2, 'å®Œå…¨': 1.3
        }
        
        # ==================== å¦å®šè¯ ====================
        self.negation_words = {
            # åŸºç¡€å¦å®šè¯
            'ä¸', 'æ²¡', 'æ— ', 'æœª', 'é', 'å¦', 'åˆ«', 'è«',
            # å¤åˆå¦å®šè¯
            'ä¸æ˜¯', 'æ²¡æœ‰', 'æ— æ³•', 'æœªèƒ½', 'ä¸èƒ½', 'ä¸ä¼š',
            'ä¸å¯', 'ä¸è¦', 'ä¸åº”', 'ä¸åº”è¯¥', 'ä¸å¿…',
            # ç¨‹åº¦å¦å®š
            'å‡ ä¹ä¸', 'å‡ ä¹æ²¡', 'å‡ ä¹æ— ', 'æå°‘',
            'å¾ˆå°‘', 'å°‘æœ‰', 'éš¾ä»¥', 'éš¾äº'
        }
        
        # ==================== ç´§æ€¥ç¨‹åº¦å…³é”®è¯ ====================
        self.urgency_levels = {
            'critical': {  # ç‰¹åˆ«ç´§æ€¥
                'ç‰¹åˆ«é‡å¤§', 'ç‰¹å¤§', 'ç‰¹å¤§å‹', 'ç‰¹å¤§äº‹æ•…', 'ç‰¹å¤§ç¾å®³',
                'ç‰¹åˆ«æç¤º', 'ç´§æ€¥é€šçŸ¥', 'ç´§æ€¥å…¬å‘Š', 'ç´§æ€¥åœç‰Œ',
                'å¼ºåˆ¶é€€å¸‚', 'åœæ­¢äº¤æ˜“', 'é‡å¤§è¿æ³•', 'é‡å¤§è¿è§„'
            },
            'high': {  # é«˜åº¦é‡è¦
                'é‡å¤§', 'é‡è¦', 'ä¸¥é‡', 'ä¸¥å³»', 'é‡ç‚¹', 'å…³é”®',
                'æ ¸å¿ƒ', 'é‡å¤§äº‹é¡¹', 'é‡å¤§èµ„äº§é‡ç»„', 'é‡å¤§åˆåŒ',
                'é‡å¤§è¯‰è®¼', 'é‡å¤§äºæŸ', 'é‡å¤§é£é™©'
            },
            'medium': {  # ä¸€èˆ¬é‡è¦
                'è¾ƒå¤§', 'è¾ƒå¤š', 'ä¸å°', 'ä¸€å®šç¨‹åº¦',
                'å€¼å¾—å…³æ³¨', 'éœ€è¦å…³æ³¨', 'åº”å½“æ³¨æ„'
            },
            'low': {  # ä¸€èˆ¬
                'æ™®é€š', 'å¸¸è§„', 'æ—¥å¸¸', 'ä¸€èˆ¬', 'æ­£å¸¸'
            }
        }
        
        # ==================== æŠ¥å‘Šç±»å‹å…³é”®è¯ ====================
        self.report_types = {
            'financial': {  # è´¢åŠ¡æŠ¥å‘Š
                'è´¢æŠ¥', 'è´¢åŠ¡æŠ¥å‘Š', 'å¹´æŠ¥', 'åŠå¹´æŠ¥', 'å­£æŠ¥',
                'ä¸šç»©é¢„å‘Š', 'ä¸šç»©å¿«æŠ¥', 'ä¸šç»©ä¿®æ­£', 'ä¸šç»©è¯´æ˜',
                'åˆ©æ¶¦è¡¨', 'èµ„äº§è´Ÿå€ºè¡¨', 'ç°é‡‘æµé‡è¡¨'
            },
            'research': {  # ç ”ç©¶æŠ¥å‘Š
                'ç ”æŠ¥', 'ç ”ç©¶æŠ¥å‘Š', 'åˆ†æå¸ˆ', 'æœºæ„ç ”ç©¶',
                'æ·±åº¦ç ”ç©¶', 'è¡Œä¸šç ”ç©¶', 'å…¬å¸ç ”ç©¶', 'è°ƒç ”',
                'ä¹°å…¥', 'å¢æŒ', 'ä¸­æ€§', 'å‡æŒ', 'å–å‡º', 'ç›®æ ‡ä»·'
            },
            'announcement': {  # å…¬å‘Šæ–‡ä»¶
                'å…¬å‘Š', 'æç¤ºæ€§å…¬å‘Š', 'é£é™©æç¤º', 'æ¾„æ¸…å…¬å‘Š',
                'é—®è¯¢å‡½å›å¤', 'è¡¥å……å…¬å‘Š', 'æ›´æ­£å…¬å‘Š', 'è¿›å±•å…¬å‘Š'
            },
            'news': {  # æ–°é—»èµ„è®¯
                'æ–°é—»', 'èµ„è®¯', 'å¿«è®¯', 'å¿«è®¯', 'é€Ÿé€’',
                'ä¸“è®¿', 'é‡‡è®¿', 'é‡‡è®¿', 'æŠ¥é“', 'åª’ä½“',
                'å®˜æ–¹', 'å®˜ç½‘', 'å®˜å¾®', 'å£°æ˜'
            },
            'policy': {  # æ”¿ç­–æ–‡ä»¶
                'æ”¿ç­–', 'é€šçŸ¥', 'æ„è§', 'æŒ‡å¯¼', 'è§„åˆ’',
                'åŠæ³•', 'æ¡ä¾‹', 'è§„å®š', 'è§„ç« ', 'æ³•è§„',
                'å›½åŠ¡é™¢', 'è¯ç›‘ä¼š', 'å‘æ”¹å§”', 'å·¥ä¿¡éƒ¨'
            }
        }
        
        logger.info("âœ… æƒ…ç»ªåˆ†æå¼•æ“åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ­£é¢è¯æ±‡: {len(self.positive_words)}ä¸ª")
        logger.info(f"   è´Ÿé¢è¯æ±‡: {len(self.negative_words)}ä¸ª")
        logger.info(f"   å¼ºåŒ–è¯: {len(self.intensifiers)}ä¸ª")
        logger.info(f"   å¦å®šè¯: {len(self.negation_words)}ä¸ª")
    
    def analyze_text(self, text: str, weight_title: bool = False) -> Dict:
        """
        åˆ†æå•æ¡æ–‡æœ¬çš„æƒ…ç»ª
        
        Args:
            text: å¾…åˆ†ææ–‡æœ¬
            weight_title: æ˜¯å¦ä¸ºæ ‡é¢˜ï¼ˆæ ‡é¢˜æƒé‡æ›´é«˜ï¼‰
            
        Returns:
            {
                'score': float,  # æƒ…ç»ªå¾—åˆ† 0-100
                'sentiment': str,  # 'positive'/'negative'/'neutral'
                'positive_count': int,
                'negative_count': int,
                'keywords': list,
                'urgency': str,  # ç´§æ€¥ç¨‹åº¦
                'report_type': str  # æŠ¥å‘Šç±»å‹
            }
        """
        if not text:
            return {
                'score': 50,
                'sentiment': 'neutral',
                'positive_count': 0,
                'negative_count': 0,
                'keywords': [],
                'urgency': 'low',
                'report_type': 'unknown'
            }
        
        # åˆ†è¯ï¼ˆç®€å•å®ç°ï¼Œå®é™…å¯ç”¨jiebaï¼‰
        words = list(text)
        
        positive_score = 0
        negative_score = 0
        keywords = []
        
        # åˆ†ææ­£é¢è¯æ±‡
        for word in self.positive_words:
            count = text.count(word)
            if count > 0:
                # æ£€æŸ¥å¼ºåŒ–è¯
                weight = 1.0
                for intensifier, mult in self.intensifiers.items():
                    try:
                        if intensifier in text:
                            int_idx = text.find(intensifier)
                            word_idx = text.find(word)
                            # å¼ºåŒ–è¯åœ¨ç›®æ ‡è¯å‰é¢3ä¸ªå­—ç¬¦å†…
                            if 0 <= word_idx - int_idx <= 3:
                                weight = mult
                                break
                    except:
                        pass
                
                # æ£€æŸ¥å¦å®š
                is_negated = self._check_negation(text, word)
                if is_negated:
                    negative_score += count * weight
                else:
                    positive_score += count * weight
                    keywords.append(word)
        
        # åˆ†æè´Ÿé¢è¯æ±‡
        for word in self.negative_words:
            count = text.count(word)
            if count > 0:
                weight = 1.0
                for intensifier, mult in self.intensifiers.items():
                    try:
                        if intensifier in text:
                            int_idx = text.find(intensifier)
                            word_idx = text.find(word)
                            if 0 <= word_idx - int_idx <= 3:
                                weight = mult
                                break
                    except:
                        pass
                
                is_negated = self._check_negation(text, word)
                if is_negated:
                    positive_score += count * weight
                else:
                    negative_score += count * weight
                    keywords.append(word)
        
        # æ ‡é¢˜æƒé‡åŠ æˆ
        if weight_title:
            positive_score *= 1.5
            negative_score *= 1.5
        
        # è®¡ç®—æƒ…ç»ªå¾—åˆ† (0-100)
        total = positive_score + negative_score
        if total == 0:
            score = 50  # ä¸­æ€§
        else:
            score = (positive_score / total) * 100
        
        # ç¡®å®šæƒ…ç»ªå€¾å‘
        if score >= 60:
            sentiment = 'positive'
        elif score <= 40:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'
        
        # è¯„ä¼°ç´§æ€¥ç¨‹åº¦
        urgency = self._assess_urgency(text)
        
        # è¯†åˆ«æŠ¥å‘Šç±»å‹
        report_type = self._identify_report_type(text)
        
        return {
            'score': round(score, 2),
            'sentiment': sentiment,
            'positive_count': int(positive_score),
            'negative_count': int(negative_score),
            'keywords': keywords[:10],  # æœ€å¤šè¿”å›10ä¸ªå…³é”®è¯
            'urgency': urgency,
            'report_type': report_type
        }
    
    def _assess_urgency(self, text: str) -> str:
        """
        è¯„ä¼°æ–‡æœ¬ç´§æ€¥ç¨‹åº¦
        
        Returns:
            'critical' / 'high' / 'medium' / 'low'
        """
        # æ£€æŸ¥å„çº§åˆ«å…³é”®è¯
        for level, keywords in self.urgency_levels.items():
            for keyword in keywords:
                if keyword in text:
                    return level
        return 'low'
    
    def _identify_report_type(self, text: str) -> str:
        """
        è¯†åˆ«æŠ¥å‘Šç±»å‹
        
        Returns:
            'financial' / 'research' / 'announcement' / 'news' / 'policy' / 'unknown'
        """
        # ç»Ÿè®¡å„ç±»å‹å…³é”®è¯å‡ºç°æ¬¡æ•°
        type_scores = {}
        for report_type, keywords in self.report_types.items():
            count = sum(1 for kw in keywords if kw in text)
            if count > 0:
                type_scores[report_type] = count
        
        if not type_scores:
            return 'unknown'
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„ç±»å‹
        return max(type_scores.items(), key=lambda x: x[1])[0]
    
    def analyze_news_list(self, news_list: List[Dict]) -> Dict:
        """
        åˆ†ææ–°é—»åˆ—è¡¨çš„æ•´ä½“æƒ…ç»ª
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨ï¼Œæ¯æ¡æ–°é—»åŒ…å«titleå’Œcontent
            
        Returns:
            {
                'overall_score': float,  # æ€»ä½“æƒ…ç»ªå¾—åˆ†
                'overall_sentiment': str,
                'positive_count': int,  # æ­£é¢æ–°é—»æ•°
                'negative_count': int,  # è´Ÿé¢æ–°é—»æ•°
                'neutral_count': int,   # ä¸­æ€§æ–°é—»æ•°
                'news_sentiments': list,  # æ¯æ¡æ–°é—»çš„æƒ…ç»ªåˆ†æ
                'urgency_stats': dict,  # ç´§æ€¥ç¨‹åº¦ç»Ÿè®¡
                'report_type_stats': dict,  # æŠ¥å‘Šç±»å‹ç»Ÿè®¡
                'time_series': list  # æ—¶é—´åºåˆ—æƒ…ç»ª
            }
        """
        if not news_list:
            return {
                'overall_score': 50,
                'overall_sentiment': 'neutral',
                'positive_count': 0,
                'negative_count': 0,
                'neutral_count': 0,
                'news_sentiments': [],
                'urgency_stats': {},
                'report_type_stats': {},
                'time_series': []
            }
        
        logger.info(f"ğŸ“Š å¼€å§‹åˆ†æ{len(news_list)}æ¡æ–°é—»çš„æƒ…ç»ª...")
        
        news_sentiments = []
        scores = []
        
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        
        # ç»Ÿè®¡ç´§æ€¥ç¨‹åº¦å’ŒæŠ¥å‘Šç±»å‹
        urgency_stats = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0}
        report_type_stats = {
            'financial': 0, 'research': 0, 'announcement': 0,
            'news': 0, 'policy': 0, 'unknown': 0
        }
        
        for news in news_list:
            # åˆå¹¶æ ‡é¢˜å’Œå†…å®¹è¿›è¡Œåˆ†æ
            title = news.get('title', '')
            content = news.get('content', '')
            
            # å…ˆåˆ†ææ ‡é¢˜ï¼ˆé«˜æƒé‡ï¼‰
            title_sentiment = self.analyze_text(title, weight_title=True) if title else None
            
            # å†åˆ†æå…¨æ–‡
            text = f"{title} {content}"
            full_sentiment = self.analyze_text(text)
            
            # ç»¼åˆè¯„åˆ†ï¼šæ ‡é¢˜60% + å…¨æ–‡40%
            if title_sentiment:
                final_score = title_sentiment['score'] * 0.6 + full_sentiment['score'] * 0.4
                final_sentiment = title_sentiment['sentiment'] if title_sentiment['score'] != 50 else full_sentiment['sentiment']
                # åˆå¹¶å…³é”®è¯
                keywords = list(set(title_sentiment['keywords'] + full_sentiment['keywords']))[:10]
            else:
                final_score = full_sentiment['score']
                final_sentiment = full_sentiment['sentiment']
                keywords = full_sentiment['keywords']
            
            # ç»Ÿè®¡æƒ…ç»ªåˆ†å¸ƒ
            if final_sentiment == 'positive':
                positive_count += 1
            elif final_sentiment == 'negative':
                negative_count += 1
            else:
                neutral_count += 1
            
            # ç»Ÿè®¡ç´§æ€¥ç¨‹åº¦
            urgency = full_sentiment.get('urgency', 'low')
            urgency_stats[urgency] = urgency_stats.get(urgency, 0) + 1
            
            # ç»Ÿè®¡æŠ¥å‘Šç±»å‹
            report_type = full_sentiment.get('report_type', 'unknown')
            report_type_stats[report_type] = report_type_stats.get(report_type, 0) + 1
            
            scores.append(final_score)
            
            news_sentiments.append({
                'title': title,
                'pub_time': news.get('pub_time', ''),
                'source': news.get('source', ''),
                'score': round(final_score, 2),
                'sentiment': final_sentiment,
                'keywords': keywords,
                'urgency': urgency,
                'report_type': report_type
            })
        
        # è®¡ç®—æ€»ä½“å¾—åˆ†
        overall_score = sum(scores) / len(scores) if scores else 50
        
        if overall_score >= 60:
            overall_sentiment = 'positive'
        elif overall_score <= 40:
            overall_sentiment = 'negative'
        else:
            overall_sentiment = 'neutral'
        
        # æŒ‰æ—¶é—´æ’åºçš„æƒ…ç»ªè¶‹åŠ¿
        time_series = sorted(
            news_sentiments,
            key=lambda x: x.get('pub_time', ''),
            reverse=True
        )[:20]  # æœ€å¤š20æ¡
        
        logger.info(f"âœ… æƒ…ç»ªåˆ†æå®Œæˆ: æ€»ä½“å¾—åˆ†={overall_score:.2f}, æ­£é¢={positive_count}, è´Ÿé¢={negative_count}")
        
        return {
            'overall_score': round(overall_score, 2),
            'overall_sentiment': overall_sentiment,
            'positive_count': positive_count,
            'negative_count': negative_count,
            'neutral_count': neutral_count,
            'news_sentiments': news_sentiments,
            'urgency_stats': urgency_stats,
            'report_type_stats': report_type_stats,
            'time_series': time_series
        }
        
    def _check_negation(self, text: str, word: str) -> bool:
        """æ£€æŸ¥è¯æ±‡å‰æ˜¯å¦æœ‰å¦å®šè¯"""
        try:
            word_index = text.index(word)
            # æ£€æŸ¥å‰5ä¸ªå­—ç¬¦å†…æ˜¯å¦æœ‰å¦å®šè¯
            preceding_text = text[max(0, word_index-5):word_index]
            
            for neg_word in self.negation_words:
                if neg_word in preceding_text:
                    return True
            
            return False
        except:
            return False
    
    def format_sentiment_report(self, sentiment_data: Dict) -> str:
        """
        æ ¼å¼åŒ–æƒ…ç»ªåˆ†ææŠ¥å‘Š
        
        Args:
            sentiment_data: analyze_news_listè¿”å›çš„æ•°æ®
            
        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬æŠ¥å‘Š
        """
        overall_score = sentiment_data.get('overall_score', 50)
        overall_sentiment = sentiment_data.get('overall_sentiment', 'neutral')
        
        # æƒ…ç»ªemoji
        emoji_map = {
            'positive': 'ğŸ˜Š',
            'neutral': 'ğŸ˜',
            'negative': 'ğŸ˜Ÿ'
        }
        emoji = emoji_map.get(overall_sentiment, 'ğŸ˜')
        
        report = f"ğŸ“Š èˆ†æƒ…æƒ…ç»ªåˆ†ææŠ¥å‘Š\n"
        report += f"=" * 60 + "\n"
        report += f"{emoji} æ€»ä½“æƒ…ç»ª: {overall_sentiment.upper()} (å¾—åˆ†: {overall_score:.2f}/100)\n\n"
        
        report += f"ğŸ“ˆ æƒ…ç»ªåˆ†å¸ƒ:\n"
        report += f"  - æ­£é¢æ–°é—»: {sentiment_data.get('positive_count', 0)}æ¡\n"
        report += f"  - ä¸­æ€§æ–°é—»: {sentiment_data.get('neutral_count', 0)}æ¡\n"
        report += f"  - è´Ÿé¢æ–°é—»: {sentiment_data.get('negative_count', 0)}æ¡\n\n"
        
        # æ˜¾ç¤ºéƒ¨åˆ†æ–°é—»æƒ…ç»ª
        news_sentiments = sentiment_data.get('news_sentiments', [])
        if news_sentiments:
            report += f"ğŸ“° æ–°é—»æƒ…ç»ªè¯¦æƒ…ï¼ˆå‰5æ¡ï¼‰:\n"
            report += "-" * 60 + "\n"
            
            for i, item in enumerate(news_sentiments[:5], 1):
                sentiment = item['sentiment']
                emoji = emoji_map.get(sentiment['sentiment'], 'ğŸ˜')
                
                report += f"\n[{i}] {emoji} {sentiment['sentiment']} (å¾—åˆ†: {sentiment['score']})\n"
                report += f"    æ ‡é¢˜: {item['title'][:50]}...\n"
                if sentiment['keywords']:
                    report += f"    å…³é”®è¯: {', '.join(sentiment['keywords'][:5])}\n"
        
        return report


# å…¨å±€å®ä¾‹
_sentiment_engine = None


def get_sentiment_engine() -> SentimentEngine:
    """è·å–å…¨å±€æƒ…ç»ªåˆ†æå¼•æ“å®ä¾‹"""
    global _sentiment_engine
    if _sentiment_engine is None:
        _sentiment_engine = SentimentEngine()
    return _sentiment_engine


# ä¾¿æ·å‡½æ•°
def analyze_news_sentiment(news_list: List[Dict]) -> Dict:
    """åˆ†ææ–°é—»åˆ—è¡¨æƒ…ç»ª"""
    engine = get_sentiment_engine()
    return engine.analyze_news_list(news_list)


def get_sentiment_score(news_list: List[Dict]) -> float:
    """è·å–æƒ…ç»ªå¾—åˆ†"""
    engine = get_sentiment_engine()
    result = engine.analyze_news_list(news_list)
    return result.get('overall_score', 50)
