"""
LLM å¤šçº§é™çº§å¤„ç†å™¨
å®ç°æ™ºèƒ½é™çº§ç­–ç•¥ï¼Œç¡®ä¿åˆ†ææµç¨‹ä¸ä¼šå› ä¸ªåˆ«è¶…æ—¶è€Œä¸­æ–­
"""
import asyncio
import httpx
import json
import time
import hashlib
from typing import Dict, Optional, Any, Tuple
from dataclasses import dataclass
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

@dataclass
class RequestMetrics:
    """è¯·æ±‚æŒ‡æ ‡"""
    prompt_length: int
    prompt_tokens_est: int
    request_size_kb: float
    attempt_times: list
    error_types: list
    final_status: str
    total_time: float
    
class FallbackHandler:
    """
    å¤šçº§é™çº§å¤„ç†å™¨
    
    é™çº§ç­–ç•¥ï¼š
    1. åŸå§‹è¯·æ±‚ (60s timeout)
    2. æ‘˜è¦å‹ç¼© (45s timeout) - å‹ç¼©åˆ° 50%
    3. æ·±åº¦å‹ç¼© (30s timeout) - å‹ç¼©åˆ° 25%
    4. æœ€å°åŒ–è¯·æ±‚ (20s timeout) - åªä¿ç•™æ ¸å¿ƒä¿¡æ¯
    5. é»˜è®¤å“åº” - è¿”å›é¢„è®¾çš„ä¿å®ˆå»ºè®®
    """
    
    def __init__(self, summarizer=None):
        """
        Args:
            summarizer: æ–‡æœ¬æ‘˜è¦å™¨å®ä¾‹
        """
        self.summarizer = summarizer
        self.request_cache = {}  # ç¼“å­˜æˆåŠŸçš„è¯·æ±‚
        self.error_stats = {}    # é”™è¯¯ç»Ÿè®¡
        
    async def execute_with_fallback(
        self,
        client: httpx.AsyncClient,
        url: str,
        headers: Dict,
        data: Dict,
        agent_role: str,
        max_retries: int = 4
    ) -> Tuple[Dict, RequestMetrics]:
        """
        æ‰§è¡Œè¯·æ±‚ï¼Œå¸¦å¤šçº§é™çº§
        
        Returns:
            (response_dict, metrics)
        """
        original_prompt = data["messages"][-1]["content"]
        original_system = data["messages"][0]["content"] if len(data["messages"]) > 1 else ""
        
        metrics = RequestMetrics(
            prompt_length=len(original_prompt),
            prompt_tokens_est=len(original_prompt) // 2,
            request_size_kb=len(json.dumps(data)) / 1024,
            attempt_times=[],
            error_types=[],
            final_status="",
            total_time=0
        )
        
        start_time = time.time()
        
        # é™çº§çº§åˆ«é…ç½®
        fallback_levels = [
            {
                "name": "åŸå§‹è¯·æ±‚",
                "timeout": 60.0,
                "compression": 1.0,
                "max_tokens": data.get("max_tokens", 1024)
            },
            {
                "name": "è½»åº¦å‹ç¼©",
                "timeout": 45.0,
                "compression": 0.5,
                "max_tokens": 512
            },
            {
                "name": "æ·±åº¦å‹ç¼©",
                "timeout": 30.0,
                "compression": 0.25,
                "max_tokens": 256
            },
            {
                "name": "æœ€å°åŒ–",
                "timeout": 20.0,
                "compression": 0.1,
                "max_tokens": 128
            }
        ]
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(agent_role, original_prompt)
        if cache_key in self.request_cache:
            logger.info(f"[é™çº§å¤„ç†] ä½¿ç”¨ç¼“å­˜å“åº”: {agent_role}")
            cached = self.request_cache[cache_key]
            metrics.final_status = "cached"
            metrics.total_time = 0.001
            return cached, metrics
        
        # é€çº§å°è¯•
        for level_idx, level in enumerate(fallback_levels):
            attempt_start = time.time()
            
            try:
                # å‡†å¤‡è¯·æ±‚æ•°æ®
                current_data = data.copy()
                
                # å‹ç¼©æç¤ºè¯
                if level["compression"] < 1.0 and self.summarizer:
                    compressed_prompt = await self._compress_prompt(
                        original_prompt,
                        level["compression"],
                        agent_role
                    )
                    current_data["messages"][-1]["content"] = compressed_prompt
                    logger.info(f"[é™çº§å¤„ç†] {level['name']}: å‹ç¼©åˆ° {len(compressed_prompt)}/{len(original_prompt)} å­—ç¬¦")
                
                # è°ƒæ•´è¾“å‡ºé•¿åº¦
                current_data["max_tokens"] = level["max_tokens"]
                
                # å‘é€è¯·æ±‚
                logger.info(f"[é™çº§å¤„ç†] å°è¯• {level['name']} (è¶…æ—¶: {level['timeout']}s)")
                
                response = await asyncio.wait_for(
                    client.post(url, headers=headers, json=current_data),
                    timeout=level["timeout"]
                )
                
                attempt_time = time.time() - attempt_start
                metrics.attempt_times.append(attempt_time)
                
                if response.status_code == 200:
                    result = response.json()
                    
                    # ç¼“å­˜æˆåŠŸçš„å“åº”
                    self.request_cache[cache_key] = result
                    
                    # è®°å½•æˆåŠŸ
                    metrics.final_status = f"success_level_{level_idx}"
                    metrics.total_time = time.time() - start_time
                    
                    logger.info(f"[é™çº§å¤„ç†] âœ… {level['name']}æˆåŠŸ (è€—æ—¶: {attempt_time:.1f}s)")
                    
                    # å¦‚æœä¸æ˜¯åŸå§‹è¯·æ±‚ï¼Œæ·»åŠ é™çº§æ ‡è®°
                    if level_idx > 0:
                        text = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                        text = f"[é™çº§çº§åˆ«{level_idx}: {level['name']}]\n{text}"
                        result["choices"][0]["message"]["content"] = text
                        result["fallback_level"] = level_idx
                    
                    return result, metrics
                else:
                    raise httpx.HTTPStatusError(
                        f"HTTP {response.status_code}",
                        request=response.request,
                        response=response
                    )
                    
            except asyncio.TimeoutError:
                metrics.error_types.append(f"timeout_level_{level_idx}")
                logger.warning(f"[é™çº§å¤„ç†] â±ï¸ {level['name']}è¶…æ—¶ ({level['timeout']}s)")
                # å¦‚æœè¿˜æœ‰ä¸‹ä¸€çº§ï¼Œæ˜ç¡®æ—¥å¿—æç¤ºå°†åˆ‡æ¢åˆ°ä¸‹ä¸€çº§é™çº§ç­–ç•¥
                if level_idx + 1 < len(fallback_levels):
                    next_level = fallback_levels[level_idx + 1]
                    logger.info(
                        f"[é™çº§å¤„ç†] å°†ä»{level['name']}åˆ‡æ¢åˆ°ä¸‹ä¸€çº§é™çº§ç­–ç•¥: {next_level['name']} "
                        f"(å‹ç¼©æ¯”ä¾‹: {next_level['compression']:.0%}, è¶…æ—¶: {next_level['timeout']}s)"
                    )
                
            except httpx.ReadTimeout:
                metrics.error_types.append(f"read_timeout_level_{level_idx}")
                logger.warning(f"[é™çº§å¤„ç†] â±ï¸ {level['name']}è¯»å–è¶…æ—¶")
                if level_idx + 1 < len(fallback_levels):
                    next_level = fallback_levels[level_idx + 1]
                    logger.info(
                        f"[é™çº§å¤„ç†] å°†ä»{level['name']}åˆ‡æ¢åˆ°ä¸‹ä¸€çº§é™çº§ç­–ç•¥: {next_level['name']} "
                        f"(å‹ç¼©æ¯”ä¾‹: {next_level['compression']:.0%}, è¶…æ—¶: {next_level['timeout']}s)"
                    )
                
            except Exception as e:
                metrics.error_types.append(f"{type(e).__name__}_level_{level_idx}")
                logger.error(f"[é™çº§å¤„ç†] âŒ {level['name']}å¤±è´¥: {type(e).__name__}: {str(e)[:100]}")
                if level_idx + 1 < len(fallback_levels):
                    next_level = fallback_levels[level_idx + 1]
                    logger.info(
                        f"[é™çº§å¤„ç†] å°†ä»{level['name']}åˆ‡æ¢åˆ°ä¸‹ä¸€çº§é™çº§ç­–ç•¥: {next_level['name']} "
                        f"(å‹ç¼©æ¯”ä¾‹: {next_level['compression']:.0%}, è¶…æ—¶: {next_level['timeout']}s)"
                    )
        
        # æ‰€æœ‰çº§åˆ«éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å“åº”
        metrics.final_status = "all_failed_use_default"
        metrics.total_time = time.time() - start_time
        
        # è®°å½•é”™è¯¯ç»Ÿè®¡
        self._record_error(agent_role, metrics)
        
        # ç”Ÿæˆè¯¦ç»†çš„é”™è¯¯æŠ¥å‘Š
        error_report = self._generate_error_report(agent_role, metrics, original_prompt)
        
        logger.error(f"[é™çº§å¤„ç†] âŒ æ‰€æœ‰é™çº§çº§åˆ«å¤±è´¥ï¼Œè¿”å›é»˜è®¤å“åº”")
        logger.error(error_report)
        
        # è¿”å›é»˜è®¤å“åº”
        return self._get_default_response(agent_role, error_report), metrics
    
    async def _compress_prompt(self, prompt: str, ratio: float, agent_role: str) -> str:
        """
        å‹ç¼©æç¤ºè¯ - ä¼˜å…ˆä½¿ç”¨LLMæ™ºèƒ½æ‘˜è¦
        
        Args:
            prompt: åŸå§‹æç¤ºè¯
            ratio: å‹ç¼©æ¯”ä¾‹ (0.1-1.0)
            agent_role: æ™ºèƒ½ä½“è§’è‰²
            
        Returns:
            å‹ç¼©åçš„æç¤ºè¯
        """
        # ä¼˜å…ˆä½¿ç”¨LLMæ™ºèƒ½æ‘˜è¦
        try:
            # åŠ¨æ€å¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            import httpx
            import json
            import os
            
            # è¯»å–é…ç½®
            config_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), "agent_configs.json")
            model_name = "Qwen/Qwen2.5-7B-Instruct"
            temperature = 0.2
            api_key = os.getenv("SILICONFLOW_API_KEY", "")
            
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                    model_name = config_data.get("summarizerModel", model_name)
                    temperature = config_data.get("summarizerTemperature", temperature)
            
            # æ„å»ºæ™ºèƒ½æ‘˜è¦è¯·æ±‚
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ–‡æœ¬æ‘˜è¦ä¸“å®¶ï¼Œæ“…é•¿æå–å’Œä¿ç•™å…³é”®æŠ•èµ„ä¿¡æ¯ã€‚"
            
            if ratio <= 0.25:  # æ·±åº¦å‹ç¼©
                user_prompt = f"""è¯·å°†ä¸‹é¢çš„æŠ•èµ„åˆ†ææ–‡æœ¬å‹ç¼©åˆ°{int(ratio*100)}%ï¼Œåªä¿ç•™æœ€æ ¸å¿ƒçš„ä¿¡æ¯ï¼š

{prompt}

ä¸¥æ ¼è¦æ±‚ï¼š
1. å¿…é¡»ä¿ç•™ï¼šæ‰€æœ‰è‚¡ç¥¨ä»£ç ã€å…·ä½“ä»·æ ¼ã€æ¶¨è·Œç™¾åˆ†æ¯”ã€å…³é”®è´¢åŠ¡æ•°æ®
2. å¿…é¡»ä¿ç•™ï¼šæ ¸å¿ƒæŠ•èµ„å»ºè®®ï¼ˆä¹°å…¥/å–å‡º/æŒæœ‰ï¼‰å’Œç›®æ ‡ä»·ä½
3. å¿…é¡»ä¿ç•™ï¼šä¸»è¦é£é™©æç¤ºå’Œæ­¢æŸä½
4. åˆ é™¤ï¼šå†—ä½™æè¿°ã€é‡å¤å†…å®¹ã€è¿‡æ¸¡è¯­å¥
5. è¾“å‡ºå¿…é¡»ç®€æ´ï¼Œä¸è¦ä»»ä½•å¼€åœºç™½"""
            elif ratio <= 0.5:  # ä¸­åº¦å‹ç¼©
                user_prompt = f"""è¯·æ™ºèƒ½æå–ä¸‹é¢æŠ•èµ„åˆ†æçš„å…³é”®ä¿¡æ¯ï¼Œå‹ç¼©åˆ°{int(ratio*100)}%ï¼š

{prompt}

ä¿ç•™è¦ç‚¹ï¼š
1. æ‰€æœ‰æ•°å­—ã€ç™¾åˆ†æ¯”ã€ä»·æ ¼ä¿¡æ¯
2. æ ¸å¿ƒåˆ†æç»“è®ºå’ŒæŠ•èµ„å»ºè®®
3. é‡è¦é£é™©å’Œæœºä¼š
4. å…³é”®æ”¯æ’‘ä½å’Œé˜»åŠ›ä½
è¾“å‡ºæ¸…æ™°ç®€æ´çš„æ‘˜è¦"""
            else:  # è½»åº¦å‹ç¼©
                user_prompt = f"""è¯·ç²¾ç®€ä¸‹é¢çš„æŠ•èµ„åˆ†ææ–‡æœ¬åˆ°{int(ratio*100)}%ï¼Œä¿ç•™æ‰€æœ‰å…³é”®ä¿¡æ¯ï¼š

{prompt}

å»é™¤å†—ä½™ä½†ä¿ç•™è¦ç‚¹"""
            
            # æ„å»ºè¯·æ±‚
            data = {
                "model": model_name,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": temperature,
                "max_tokens": int(len(prompt) * ratio / 2),  # æ§åˆ¶è¾“å‡ºé•¿åº¦
                "stream": False
            }
            
            # å¿«é€Ÿè°ƒç”¨LLMï¼ˆ5ç§’è¶…æ—¶ï¼‰
            async with httpx.AsyncClient(timeout=httpx.Timeout(5.0)) as client:
                response = await client.post(
                    "https://api.siliconflow.cn/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json"
                    },
                    json=data
                )
                
                if response.status_code == 200:
                    result = response.json()
                    compressed_text = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                    
                    if compressed_text and len(compressed_text) < len(prompt):
                        logger.info(f"[é™çº§å¤„ç†] âœ… LLMæ™ºèƒ½æ‘˜è¦æˆåŠŸ: {len(compressed_text)}/{len(prompt)} å­—ç¬¦")
                        return compressed_text + f"\n[æ™ºèƒ½å‹ç¼©è‡³{int(ratio*100)}%]"
                    
        except Exception as e:
            logger.warning(f"[é™çº§å¤„ç†] LLMæ‘˜è¦å¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°å‹ç¼©: {e}")
        
        # é™çº§åˆ°æœ¬åœ°æ™ºèƒ½å‹ç¼©
        if not self.summarizer:
            # æœ€ç®€å•çš„æˆªæ–­
            target_length = int(len(prompt) * ratio)
            return prompt[:target_length] + "\n...[å·²æˆªæ–­]"
        
        try:
            # ä½¿ç”¨æœ¬åœ°æ‘˜è¦å™¨
            compressed = await self.summarizer.compress(
                prompt,
                target_ratio=ratio,
                preserve_key_info=True,
                context=agent_role
            )
            return compressed
        except Exception as e:
            logger.error(f"æœ¬åœ°æ‘˜è¦å™¨å¤±è´¥: {e}")
            target_length = int(len(prompt) * ratio)
            return prompt[:target_length] + "\n...[å·²æˆªæ–­]"
    
    def _get_cache_key(self, agent_role: str, prompt: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{agent_role}:{prompt[:100]}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _record_error(self, agent_role: str, metrics: RequestMetrics):
        """è®°å½•é”™è¯¯ç»Ÿè®¡"""
        if agent_role not in self.error_stats:
            self.error_stats[agent_role] = {
                "total_errors": 0,
                "timeout_errors": 0,
                "last_error_time": None,
                "error_types": {}
            }
        
        stats = self.error_stats[agent_role]
        stats["total_errors"] += 1
        stats["last_error_time"] = datetime.now()
        
        for error_type in metrics.error_types:
            if "timeout" in error_type:
                stats["timeout_errors"] += 1
            stats["error_types"][error_type] = stats["error_types"].get(error_type, 0) + 1
    
    def _generate_error_report(self, agent_role: str, metrics: RequestMetrics, prompt: str) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„é”™è¯¯æŠ¥å‘Š"""
        report = f"""
======== LLM è¯·æ±‚å¤±è´¥æŠ¥å‘Š ========
æ™ºèƒ½ä½“: {agent_role}
æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æ€»è€—æ—¶: {metrics.total_time:.1f}ç§’

è¯·æ±‚ä¿¡æ¯:
- åŸå§‹æç¤ºè¯é•¿åº¦: {metrics.prompt_length} å­—ç¬¦
- ä¼°ç®—Tokenæ•°: {metrics.prompt_tokens_est}
- è¯·æ±‚ä½“å¤§å°: {metrics.request_size_kb:.1f} KB

å°è¯•è®°å½•:
"""
        for i, (attempt_time, error) in enumerate(zip(
            metrics.attempt_times + [None] * (4 - len(metrics.attempt_times)),
            metrics.error_types + [""] * (4 - len(metrics.error_types))
        )):
            if attempt_time is not None:
                report += f"  çº§åˆ«{i}: {attempt_time:.1f}s - {error or 'æˆåŠŸ'}\n"
            else:
                report += f"  çº§åˆ«{i}: æœªå°è¯•\n"
        
        # å†å²é”™è¯¯ç»Ÿè®¡
        if agent_role in self.error_stats:
            stats = self.error_stats[agent_role]
            report += f"\nå†å²ç»Ÿè®¡:\n"
            report += f"- æ€»é”™è¯¯æ¬¡æ•°: {stats['total_errors']}\n"
            report += f"- è¶…æ—¶æ¬¡æ•°: {stats['timeout_errors']}\n"
            report += f"- é”™è¯¯ç±»å‹åˆ†å¸ƒ: {stats['error_types']}\n"
        
        # æç¤ºè¯ç‰‡æ®µï¼ˆç”¨äºè°ƒè¯•ï¼‰
        report += f"\næç¤ºè¯å‰100å­—ç¬¦:\n{prompt[:100]}...\n"
        report += "=" * 40
        
        return report
    
    def _get_default_response(self, agent_role: str, error_report: str) -> Dict:
        """
        è·å–é»˜è®¤å“åº”
        
        æ ¹æ®ä¸åŒæ™ºèƒ½ä½“è¿”å›åˆé€‚çš„é»˜è®¤å»ºè®®
        """
        default_texts = {
            "NEWS": "ğŸ“° æ–°é—»åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚åŸºäºå†å²ç»éªŒï¼Œå»ºè®®ä¿æŒè§‚æœ›ã€‚",
            "FUNDAMENTAL": "ğŸ“Š åŸºæœ¬é¢åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚å»ºè®®å‚è€ƒå…¬å¼€è´¢æŠ¥æ•°æ®ã€‚",
            "TECHNICAL": "ğŸ“ˆ æŠ€æœ¯åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚å»ºè®®å…³æ³¨å…³é”®æ”¯æ’‘ä½ã€‚",
            "BULL": "ğŸ‚ å¤šæ–¹è§‚ç‚¹ï¼šåœ¨æ•°æ®ä¸è¶³çš„æƒ…å†µä¸‹ï¼Œå»ºè®®è°¨æ…ä¹è§‚ã€‚",
            "BEAR": "ğŸ» ç©ºæ–¹è§‚ç‚¹ï¼šåœ¨æ•°æ®ä¸è¶³çš„æƒ…å†µä¸‹ï¼Œå»ºè®®ä¿æŒè°¨æ…ã€‚",
            "RISK": "âš ï¸ é£é™©è¯„ä¼°ï¼šç³»ç»Ÿæš‚æ—¶æ— æ³•åˆ†æï¼Œå»ºè®®é‡‡ç”¨ä¿å®ˆç­–ç•¥ï¼ŒæŒæœ‰è§‚æœ›ã€‚",
            "MANAGER": "ğŸ‘” ç»ç†å»ºè®®ï¼šåŸºäºå½“å‰å¯ç”¨ä¿¡æ¯ï¼Œå»ºè®®ç»´æŒç°æœ‰ä»“ä½ã€‚",
            "TRADER": "ğŸ’¹ äº¤æ˜“å»ºè®®ï¼šæš‚æ—¶æ— æ³•ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼Œå»ºè®®ç­‰å¾…ã€‚"
        }
        
        # è·å–å¯¹åº”çš„é»˜è®¤æ–‡æœ¬
        role_key = agent_role.upper() if agent_role else "DEFAULT"
        default_text = default_texts.get(role_key, "âš ï¸ åˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼Œå»ºè®®ç¨åé‡è¯•ã€‚")
        
        # æ·»åŠ é”™è¯¯ä¿¡æ¯ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ï¼‰
        if logger.level <= logging.DEBUG:
            default_text += f"\n\n[è°ƒè¯•ä¿¡æ¯]\n{error_report}"
        
        return {
            "success": True,
            "choices": [{
                "message": {
                    "content": default_text
                }
            }],
            "usage": {
                "prompt_tokens": 0,
                "completion_tokens": 0,
                "total_tokens": 0
            },
            "fallback": True,
            "fallback_level": 99  # ç‰¹æ®Šæ ‡è®°ï¼šä½¿ç”¨äº†é»˜è®¤å“åº”
        }

class TextSummarizer:
    """
    æ–‡æœ¬æ‘˜è¦å™¨
    ç”¨äºå‹ç¼©è¿‡é•¿çš„æç¤ºè¯
    """
    
    async def compress(
        self,
        text: str,
        target_ratio: float = 0.5,
        preserve_key_info: bool = True,
        context: str = None
    ) -> str:
        """
        å‹ç¼©æ–‡æœ¬
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            target_ratio: ç›®æ ‡å‹ç¼©æ¯”ä¾‹
            preserve_key_info: æ˜¯å¦ä¿ç•™å…³é”®ä¿¡æ¯
            context: ä¸Šä¸‹æ–‡ï¼ˆå¦‚æ™ºèƒ½ä½“è§’è‰²ï¼‰
        
        Returns:
            å‹ç¼©åçš„æ–‡æœ¬
        """
        target_length = int(len(text) * target_ratio)
        
        if not preserve_key_info:
            # ç®€å•æˆªæ–­
            return text[:target_length] + "\n...[å·²å‹ç¼©]"
        
        # æ™ºèƒ½å‹ç¼©ç­–ç•¥
        lines = text.split('\n')
        
        # 1. è¯†åˆ«å…³é”®éƒ¨åˆ†
        key_patterns = [
            "è‚¡ç¥¨", "ä»£ç ", "ä»·æ ¼", "æ¶¨è·Œ", "æˆäº¤",
            "å»ºè®®", "é£é™©", "æœºä¼š", "ç›®æ ‡", "æ­¢æŸ",
            "è´¢åŠ¡", "è¥æ”¶", "åˆ©æ¶¦", "å¢é•¿", "ä¸‹è·Œ"
        ]
        
        key_lines = []
        other_lines = []
        
        for line in lines:
            if any(pattern in line for pattern in key_patterns):
                key_lines.append(line)
            else:
                other_lines.append(line)
        
        # 2. ä¼˜å…ˆä¿ç•™å…³é”®è¡Œ
        result = []
        current_length = 0
        
        # å…ˆæ·»åŠ å…³é”®è¡Œ
        for line in key_lines:
            if current_length + len(line) < target_length * 0.7:  # 70% ç»™å…³é”®ä¿¡æ¯
                result.append(line)
                current_length += len(line)
        
        # å†æ·»åŠ å…¶ä»–è¡Œ
        for line in other_lines:
            if current_length + len(line) < target_length:
                result.append(line)
                current_length += len(line)
            else:
                break
        
        compressed = '\n'.join(result)
        
        # 3. æ·»åŠ å‹ç¼©æ ‡è®°
        compression_info = f"\n[å·²å‹ç¼©: {len(compressed)}/{len(text)} å­—ç¬¦, ä¿ç•™ç‡: {target_ratio*100:.0f}%]"
        
        return compressed + compression_info

# å…¨å±€å®ä¾‹
_fallback_handler = None

def get_fallback_handler() -> FallbackHandler:
    """è·å–å…¨å±€é™çº§å¤„ç†å™¨å®ä¾‹"""
    global _fallback_handler
    if _fallback_handler is None:
        summarizer = TextSummarizer()
        _fallback_handler = FallbackHandler(summarizer)
    return _fallback_handler
