"""
IcySaint AI - Python åç«¯æœåŠ¡å™¨
ä½¿ç”¨ FastAPI æ¡†æ¶æ›¿ä»£ Vercel Serverless Functions
"""

import os
import json
import asyncio
from typing import Optional, Dict, Any, List
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
import httpx
from dotenv import load_dotenv
import uvicorn

# åŠ è½½ç¯å¢ƒå˜é‡ - æ˜ç¡®æŒ‡å®š.envæ–‡ä»¶è·¯å¾„
import sys
from pathlib import Path
env_file = Path(__file__).parent.parent / '.env'
if env_file.exists():
    load_dotenv(env_file)
    print(f"âœ… åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_file}")
else:
    load_dotenv()  # å°è¯•é»˜è®¤åŠ è½½
    print("âš ï¸ ä½¿ç”¨é»˜è®¤ç¯å¢ƒå˜é‡åŠ è½½")

# å¯¼å…¥APIè·¯ç”±
from backend.api.news_api import router as news_router
from backend.api.debate_api import router as debate_router
from backend.api.trading_api import router as trading_router
from backend.api.verification_api import router as verification_router

# ==================== é…ç½® ====================

# API Keys ä»ç¯å¢ƒå˜é‡è¯»å–
API_KEYS = {
    "gemini": os.getenv("GEMINI_API_KEY", ""),
    "deepseek": os.getenv("DEEPSEEK_API_KEY", ""),
    "qwen": os.getenv("DASHSCOPE_API_KEY", "") or os.getenv("QWEN_API_KEY", ""),  # æ”¯æŒä¸¤ç§ç¯å¢ƒå˜é‡å
    "siliconflow": os.getenv("SILICONFLOW_API_KEY", ""),
    "juhe": os.getenv("JUHE_API_KEY", "")
}

# API ç«¯ç‚¹
API_ENDPOINTS = {
    "gemini": "https://generativelanguage.googleapis.com/v1beta/models",
    "deepseek": "https://api.deepseek.com/chat/completions",
    "qwen": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
    "siliconflow": "https://api.siliconflow.cn/v1/chat/completions",
    "siliconflow_models": "https://api.siliconflow.cn/v1/models",
    "juhe": "http://web.juhe.cn/finance/stock/hs"
}

# ==================== HTTPè¿æ¥æ±  ====================
# å…¨å±€HTTPå®¢æˆ·ç«¯è¿æ¥æ± ï¼Œé¿å…é‡å¤åˆ›å»ºè¿æ¥
http_clients = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–è¿æ¥æ± 
    global http_clients
    
    # é€šç”¨è¿æ¥é™åˆ¶é…ç½®
    limits = httpx.Limits(
        max_keepalive_connections=20,  # ä¿æŒæ´»åŠ¨è¿æ¥æ•°
        max_connections=50,            # æœ€å¤§è¿æ¥æ•°
        keepalive_expiry=30            # è¿æ¥ä¿æŒæ—¶é—´ï¼ˆç§’ï¼‰
    )
    
    # AI APIçš„è¶…æ—¶é…ç½®ï¼ˆéœ€è¦é•¿æ—¶é—´ï¼‰
    # æ³¨æ„ï¼šhttpxä¸æ”¯æŒtotalå‚æ•°ï¼Œä½¿ç”¨timeoutå‚æ•°ä»£æ›¿
    ai_timeout = httpx.Timeout(
        connect=5.0,      # è¿æ¥è¶…æ—¶ï¼šå»ºç«‹TCPè¿æ¥çš„æ—¶é—´
        read=180.0,       # è¯»å–è¶…æ—¶ï¼š3åˆ†é’Ÿï¼Œé€‚åº”AIé•¿å“åº”
        write=10.0,       # å†™å…¥è¶…æ—¶ï¼šå‘é€è¯·æ±‚çš„æ—¶é—´
        pool=5.0          # è¿æ¥æ± è¶…æ—¶ï¼šè·å–è¿æ¥çš„ç­‰å¾…æ—¶é—´
    )
    
    # æ™®é€šAPIçš„è¶…æ—¶é…ç½®ï¼ˆè‚¡ç¥¨æ•°æ®ç­‰ï¼‰
    normal_timeout = httpx.Timeout(
        connect=5.0,      
        read=30.0,        # æ™®é€šAPI 30ç§’è¶³å¤Ÿ
        write=10.0,       
        pool=5.0         
    )
    
    # ä¸ºæ¯ä¸ªAPIæœåŠ¡åˆ›å»ºä¸“ç”¨å®¢æˆ·ç«¯
    http_clients['gemini'] = httpx.AsyncClient(
        limits=limits,
        timeout=ai_timeout,  # AI APIä½¿ç”¨é•¿è¶…æ—¶
        verify=True
    )
    
    http_clients['deepseek'] = httpx.AsyncClient(
        limits=limits,
        timeout=ai_timeout,  # AI APIä½¿ç”¨é•¿è¶…æ—¶
        verify=True
    )
    
    http_clients['qwen'] = httpx.AsyncClient(
        limits=limits,
        timeout=ai_timeout,  # AI APIä½¿ç”¨é•¿è¶…æ—¶
        verify=True
    )
    
    http_clients['siliconflow'] = httpx.AsyncClient(
        limits=limits,
        timeout=ai_timeout,  # AI APIä½¿ç”¨é•¿è¶…æ—¶
        verify=True
    )
    
    # è‚¡ç¥¨APIä¸“ç”¨å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨æ™®é€šè¶…æ—¶ï¼‰
    http_clients['juhe'] = httpx.AsyncClient(
        limits=limits,
        timeout=normal_timeout,  # è‚¡ç¥¨APIä½¿ç”¨çŸ­è¶…æ—¶
        verify=True
    )
    
    # é€šç”¨å®¢æˆ·ç«¯ï¼ˆç”¨äºå…¶ä»–è¯·æ±‚ï¼‰
    http_clients['default'] = httpx.AsyncClient(
        limits=limits,
        timeout=ai_timeout,  # é»˜è®¤ä½¿ç”¨AIè¶…æ—¶é…ç½®
        verify=True
    )
    
    print("âœ… HTTPè¿æ¥æ± åˆå§‹åŒ–æˆåŠŸ")
    
    # yield æ§åˆ¶æƒç»™åº”ç”¨
    yield
    
    # å…³é—­æ—¶æ¸…ç†è¿æ¥æ± 
    for name, client in http_clients.items():
        await client.aclose()
        print(f"âœ… å…³é—­ {name} è¿æ¥æ± ")
    
    http_clients.clear()
    print("âœ… æ‰€æœ‰HTTPè¿æ¥æ± å·²å…³é—­")

# åˆ›å»º FastAPI åº”ç”¨ï¼ˆä½¿ç”¨æ–°çš„lifespanï¼‰
app = FastAPI(
    title="IcySaint AI Backend",
    version="1.0.0",
    lifespan=lifespan
)

# æ³¨å†ŒAPIè·¯ç”±
app.include_router(news_router)
app.include_router(debate_router)
app.include_router(trading_router)
app.include_router(verification_router)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æºï¼ŒåŒ…æ‹¬Vueå¼€å‘æœåŠ¡å™¨
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== æ•°æ®æ¨¡å‹ ====================

class GeminiRequest(BaseModel):
    model: str = "gemini-2.5-flash"
    prompt: str
    temperature: float = 0.7
    tools: Optional[List[Dict]] = None
    apiKey: Optional[str] = None

class DeepSeekRequest(BaseModel):
    model: str = "deepseek-chat"
    systemPrompt: str
    prompt: str
    temperature: float = 0.7
    apiKey: Optional[str] = None

class QwenRequest(BaseModel):
    model: str = "qwen-plus"
    systemPrompt: str
    prompt: str
    temperature: float = 0.7
    apiKey: Optional[str] = None

class SiliconFlowRequest(BaseModel):
    model: str = "Qwen/Qwen2.5-7B-Instruct"
    systemPrompt: str
    prompt: str
    temperature: float = 0.7
    apiKey: Optional[str] = None

class StockRequest(BaseModel):
    symbol: str
    apiKey: Optional[str] = None

class AnalyzeRequest(BaseModel):
    agent_id: str
    stock_code: str
    stock_data: Optional[Dict[str, Any]] = {}
    previous_outputs: Optional[Dict[str, Any]] = {}

# ==================== AI API ç«¯ç‚¹ ====================

@app.post("/api/ai/gemini")
async def gemini_api(request: GeminiRequest):
    """Google Gemini API ä»£ç†"""
    try:
        api_key = request.apiKey or API_KEYS["gemini"]
        if not api_key:
            raise HTTPException(status_code=500, detail="æœªé…ç½® Gemini API Key")
        
        # ä½¿ç”¨å…¨å±€è¿æ¥æ± å®¢æˆ·ç«¯
        client = http_clients.get('gemini', http_clients['default'])
        
        # ç®€åŒ–çš„å®ç°ï¼Œå®é™…éœ€è¦æŒ‰ç…§ Google API æ ¼å¼
        headers = {"x-api-key": api_key}
        data = {
            "contents": [{"parts": [{"text": request.prompt}]}],
            "generationConfig": {"temperature": request.temperature}
        }
        
        response = await client.post(
            f"{API_ENDPOINTS['gemini']}/{request.model}:generateContent",
            headers=headers,
            json=data
        )
        
        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail="Gemini API é”™è¯¯")
        
        result = response.json()
        text = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
        
        return {"success": True, "text": text}
    
    except HTTPException as e:
        import traceback
        error_detail = f"HTTP {e.status_code}: {e.detail}"
        print(f"[Gemini] HTTPé”™è¯¯: {error_detail}")
        print(traceback.format_exc())
        return {"success": False, "error": error_detail}
    except Exception as e:
        import traceback
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"[Gemini] é”™è¯¯: {error_msg}")
        print(f"[Gemini] è¯¦ç»†ä¿¡æ¯:")
        print(traceback.format_exc())
        return {"success": False, "error": error_msg}

@app.post("/api/ai/deepseek")
async def deepseek_api(request: DeepSeekRequest):
    """DeepSeek API ä»£ç†"""
    try:
        api_key = request.apiKey or API_KEYS["deepseek"]
        if not api_key:
            raise HTTPException(status_code=500, detail="æœªé…ç½® DeepSeek API Key")
        
        # ä½¿ç”¨å…¨å±€è¿æ¥æ± å®¢æˆ·ç«¯
        client = http_clients.get('deepseek', http_clients['default'])
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        data = {
            "model": request.model,
            "messages": [
                {"role": "system", "content": request.systemPrompt},
                {"role": "user", "content": request.prompt}
            ],
            "temperature": request.temperature,
            "stream": False
        }
        
        # é‡è¯•æœºåˆ¶
        max_retries = 2
        for attempt in range(max_retries):
            try:
                response = await client.post(
                    API_ENDPOINTS["deepseek"],
                    headers=headers,
                    json=data,
                    timeout=httpx.Timeout(180.0, connect=60.0)
                )
                break
            except httpx.ReadTimeout:
                if attempt < max_retries - 1:
                    print(f"[DeepSeek] è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•... (å°è¯• {attempt + 2}/{max_retries})")
                    await asyncio.sleep(2)
                else:
                    print(f"[DeepSeek] æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥")
                    raise
        
        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail="DeepSeek API é”™è¯¯")
        
        result = response.json()
        text = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        
        return {"success": True, "text": text}
    
    except HTTPException as e:
        import traceback
        error_detail = f"HTTP {e.status_code}: {e.detail}"
        print(f"[DeepSeek] HTTPé”™è¯¯: {error_detail}")
        print(traceback.format_exc())
        return {"success": False, "error": error_detail}
    except Exception as e:
        import traceback
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"[DeepSeek] é”™è¯¯: {error_msg}")
        print(f"[DeepSeek] è¯¦ç»†ä¿¡æ¯:")
        print(traceback.format_exc())
        return {"success": False, "error": error_msg}

@app.post("/api/ai/qwen")
async def qwen_api(request: QwenRequest):
    """é€šä¹‰åƒé—® API ä»£ç†"""
    try:
        api_key = request.apiKey or API_KEYS["qwen"]
        if not api_key:
            raise HTTPException(status_code=500, detail="æœªé…ç½® Qwen API Key")
        
        # ä½¿ç”¨å…¨å±€è¿æ¥æ± å®¢æˆ·ç«¯
        client = http_clients.get('qwen', http_clients['default'])
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        data = {
            "model": request.model,
            "messages": [
                {"role": "system", "content": request.systemPrompt},
                {"role": "user", "content": request.prompt}
            ],
            "temperature": request.temperature,
            "stream": False
        }
        
        # é‡è¯•æœºåˆ¶
        max_retries = 2
        for attempt in range(max_retries):
            try:
                response = await client.post(
                    API_ENDPOINTS["qwen"],
                    headers=headers,
                    json=data,
                    timeout=httpx.Timeout(180.0, connect=60.0)
                )
                break
            except httpx.ReadTimeout:
                if attempt < max_retries - 1:
                    print(f"[Qwen] è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•... (å°è¯• {attempt + 2}/{max_retries})")
                    await asyncio.sleep(2)
                else:
                    print(f"[Qwen] æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥")
                    raise
        
        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail="Qwen API é”™è¯¯")
        
        result = response.json()
        text = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        
        return {"success": True, "text": text}
    
    except HTTPException as e:
        import traceback
        error_detail = f"HTTP {e.status_code}: {e.detail}"
        print(f"[Qwen] HTTPé”™è¯¯: {error_detail}")
        print(traceback.format_exc())
        return {"success": False, "error": error_detail}
    except Exception as e:
        import traceback
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"[Qwen] é”™è¯¯: {error_msg}")
        print(f"[Qwen] è¯¦ç»†ä¿¡æ¯:")
        print(traceback.format_exc())
        return {"success": False, "error": error_msg}

@app.post("/api/ai/siliconflow")
async def siliconflow_api(request: SiliconFlowRequest):
    """ç¡…åŸºæµåŠ¨ API ä»£ç†"""
    try:
        api_key = request.apiKey or API_KEYS["siliconflow"]
        if not api_key:
            raise HTTPException(status_code=500, detail="æœªé…ç½® SiliconFlow API Key")
        
        # ä½¿ç”¨å…¨å±€è¿æ¥æ± å®¢æˆ·ç«¯
        client = http_clients.get('siliconflow', http_clients['default'])
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        data = {
            "model": request.model,
            "messages": [
                {"role": "system", "content": request.systemPrompt},
                {"role": "user", "content": request.prompt}
            ],
            "temperature": request.temperature,
            "max_tokens": 99999999,
            "stream": False
        }
        
        # å¢åŠ è¶…æ—¶æ—¶é—´å¹¶æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 2
        for attempt in range(max_retries):
            try:
                response = await client.post(
                    API_ENDPOINTS["siliconflow"],
                    headers=headers,
                    json=data,
                    timeout=httpx.Timeout(180.0, connect=60.0)  # 3åˆ†é’Ÿè¶…æ—¶ï¼Œ60ç§’è¿æ¥è¶…æ—¶
                )
                break  # æˆåŠŸåˆ™è·³å‡ºå¾ªç¯
            except httpx.ReadTimeout:
                if attempt < max_retries - 1:
                    print(f"[SiliconFlow] è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•... (å°è¯• {attempt + 2}/{max_retries})")
                    await asyncio.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                else:
                    print(f"[SiliconFlow] æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥")
                    raise
        
        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail="SiliconFlow API é”™è¯¯")
        
        result = response.json()
        text = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        
        # è·å–tokenä½¿ç”¨ä¿¡æ¯
        usage = result.get("usage", {})
        prompt_tokens = usage.get("prompt_tokens", 0)
        completion_tokens = usage.get("completion_tokens", 0)
        total_tokens = usage.get("total_tokens", 0)
        
        print(f"[SiliconFlow] Tokenä½¿ç”¨: {total_tokens} (è¾“å…¥: {prompt_tokens}, è¾“å‡º: {completion_tokens})")
        
        return {
            "success": True, 
            "text": text,
            "usage": {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            }
        }
    
    except HTTPException as e:
        import traceback
        error_detail = f"HTTP {e.status_code}: {e.detail}"
        print(f"[SiliconFlow] HTTPé”™è¯¯: {error_detail}")
        print(traceback.format_exc())
        return {"success": False, "error": error_detail}
    except Exception as e:
        import traceback
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"[SiliconFlow] é”™è¯¯: {error_msg}")
        print(f"[SiliconFlow] è¯¦ç»†ä¿¡æ¯:")
        print(traceback.format_exc())
        return {"success": False, "error": error_msg}

@app.get("/api/models")
async def get_all_models():
    """è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹çš„ç»¼åˆåˆ—è¡¨"""
    all_models = []
    
    # 1. è·å–ç¡…åŸºæµåŠ¨æ¨¡å‹
    if API_KEYS.get("siliconflow"):
        try:
            # ä½¿ç”¨å…¨å±€è¿æ¥æ± å®¢æˆ·ç«¯
            client = http_clients.get('siliconflow', http_clients['default'])
            headers = {"Authorization": f"Bearer {API_KEYS['siliconflow']}"}
            response = await client.get(
                API_ENDPOINTS["siliconflow_models"],
                headers=headers
            )
            
            if response.status_code == 200:
                result = response.json()
                for model in result.get("data", []):
                    model_id = model.get("id", "")
                    # è§£æprovider
                    provider = "UNKNOWN"
                    if "qwen" in model_id.lower():
                        provider = "QWEN"
                    elif "llama" in model_id.lower():
                        provider = "LLAMA"
                    elif "deepseek" in model_id.lower():
                        provider = "DEEPSEEK"
                    elif "mistral" in model_id.lower():
                        provider = "MISTRAL"
                    elif "yi-" in model_id.lower() or "/yi" in model_id.lower():
                        provider = "YI"
                    elif "glm" in model_id.lower() or "chatglm" in model_id.lower():
                        provider = "GLM"
                    elif "gemma" in model_id.lower():
                        provider = "GEMMA"
                    elif "baichuan" in model_id.lower():
                        provider = "BAICHUAN"
                    elif "internlm" in model_id.lower():
                        provider = "INTERNLM"
                    elif "phi" in model_id.lower():
                        provider = "PHI"
                    elif model.get("owned_by") == "siliconflow":
                        provider = model_id.split("/")[0].upper() if "/" in model_id else "OTHER"
                    
                    # åˆ¤æ–­æ¨¡å‹ç±»å‹
                    model_type = "llm"  # é»˜è®¤ä¸ºLLM
                    if any(keyword in model_id.lower() for keyword in ["stable-diffusion", "sdxl", "flux", "playground", "dall-e", "midjourney"]):
                        model_type = "vision"
                    elif any(keyword in model_id.lower() for keyword in ["embedding", "bge", "jina-embed", "text-embedding"]):
                        model_type = "embedding"
                    elif any(keyword in model_id.lower() for keyword in ["whisper", "speech", "audio", "voice", "bark"]):
                        model_type = "audio"
                    
                    all_models.append({
                        "provider": provider,
                        "name": model_id,
                        "label": model_id.split("/")[-1] if "/" in model_id else model_id,
                        "type": model_type,
                        "channel": "ç¡…åŸºæµåŠ¨"
                    })
        except Exception as e:
            print(f"[Models] è·å–ç¡…åŸºæµåŠ¨æ¨¡å‹å¤±è´¥: {str(e)}")
    
    # 2. æ·»åŠ é€šä¹‰åƒé—®æ¨¡å‹
    if API_KEYS.get("qwen"):
        qwen_models = [
            {"provider": "QWEN", "name": "qwen-max", "label": "é€šä¹‰åƒé—® Max", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen-max-longcontext", "label": "é€šä¹‰åƒé—® Max é•¿æ–‡æœ¬", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen-plus", "label": "é€šä¹‰åƒé—® Plus", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen-turbo", "label": "é€šä¹‰åƒé—® Turbo", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen-turbo-latest", "label": "é€šä¹‰åƒé—® Turbo æœ€æ–°", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen2.5-72b-instruct", "label": "Qwen2.5 72B", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen2.5-32b-instruct", "label": "Qwen2.5 32B", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen2.5-14b-instruct", "label": "Qwen2.5 14B", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen2.5-7b-instruct", "label": "Qwen2.5 7B", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen2.5-3b-instruct", "label": "Qwen2.5 3B", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen2.5-coder-32b-instruct", "label": "Qwen2.5 Coder 32B", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
            {"provider": "QWEN", "name": "qwen2.5-coder-7b-instruct", "label": "Qwen2.5 Coder 7B", "type": "llm", "channel": "é˜¿é‡Œäº‘"},
        ]
        all_models.extend(qwen_models)
    
    # 3. æ·»åŠ DeepSeekæ¨¡å‹
    if API_KEYS.get("deepseek"):
        deepseek_models = [
            {"provider": "DEEPSEEK", "name": "deepseek-chat", "label": "DeepSeek Chat", "type": "llm", "channel": "DeepSeek"},
            {"provider": "DEEPSEEK", "name": "deepseek-coder", "label": "DeepSeek Coder", "type": "llm", "channel": "DeepSeek"},
            {"provider": "DEEPSEEK", "name": "deepseek-reasoner", "label": "DeepSeek Reasoner", "type": "llm", "channel": "DeepSeek"},
        ]
        all_models.extend(deepseek_models)
    
    # 4. æ·»åŠ Geminiæ¨¡å‹
    if API_KEYS.get("gemini"):
        gemini_models = [
            {"provider": "GEMINI", "name": "gemini-2.0-flash-exp", "label": "Gemini 2.0 Flash (å®éªŒç‰ˆ)", "type": "llm", "channel": "Google"},
            {"provider": "GEMINI", "name": "gemini-exp-1206", "label": "Gemini å®éªŒç‰ˆ 1206", "type": "llm", "channel": "Google"},
            {"provider": "GEMINI", "name": "gemini-exp-1121", "label": "Gemini å®éªŒç‰ˆ 1121", "type": "llm", "channel": "Google"},
            {"provider": "GEMINI", "name": "gemini-1.5-pro-002", "label": "Gemini 1.5 Pro 002", "type": "llm", "channel": "Google"},
            {"provider": "GEMINI", "name": "gemini-1.5-pro", "label": "Gemini 1.5 Pro", "type": "llm", "channel": "Google"},
            {"provider": "GEMINI", "name": "gemini-1.5-flash", "label": "Gemini 1.5 Flash", "type": "llm", "channel": "Google"},
            {"provider": "GEMINI", "name": "gemini-1.5-flash-8b", "label": "Gemini 1.5 Flash 8B", "type": "llm", "channel": "Google"},
        ]
        all_models.extend(gemini_models)
    
    print(f"[Models] è¿”å› {len(all_models)} ä¸ªæ¨¡å‹")
    return {"success": True, "models": all_models, "total": len(all_models)}

@app.get("/api/ai/siliconflow-models")
async def siliconflow_models(apiKey: Optional[str] = None):
    """è·å–ç¡…åŸºæµåŠ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    try:
        api_key = apiKey or API_KEYS["siliconflow"]
        if not api_key:
            return {"success": False, "error": "æœªé…ç½® SiliconFlow API Key", "models": []}
        
        # ä½¿ç”¨å…¨å±€è¿æ¥æ± å®¢æˆ·ç«¯
        client = http_clients.get('siliconflow', http_clients['default'])
        headers = {"Authorization": f"Bearer {api_key}"}
        response = await client.get(
            API_ENDPOINTS["siliconflow_models"],
            headers=headers
        )
        
        if response.status_code != 200:
            return {"success": False, "error": "è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥", "models": []}
        
        result = response.json()
        models = []
        for model in result.get("data", []):
            model_id = model.get("id", "")
            # ä¸è¿‡æ»¤ï¼Œè¿”å›æ‰€æœ‰æ¨¡å‹
            models.append({
                "id": model_id,
                "name": model_id,
                "label": model_id.split("/")[-1] if "/" in model_id else model_id,
                "owned_by": model.get("owned_by", "unknown")
            })
        
        print(f"[SiliconFlow] åŠ è½½äº† {len(models)} ä¸ªæ¨¡å‹")
        return {"success": True, "models": models}
    
    except Exception as e:
        print(f"[SiliconFlow Models] é”™è¯¯: {str(e)}")
        return {"success": False, "error": str(e), "models": []}

# ==================== åˆ†æ API ====================

# å…¨å±€ç¼“å­˜é…ç½®
_agent_configs_cache = None
_cache_timestamp = 0

def get_agent_config(agent_id: str):
    """è·å–æ™ºèƒ½ä½“é…ç½®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    global _agent_configs_cache, _cache_timestamp
    
    config_file = os.path.join(os.path.dirname(__file__), "agent_configs.json")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ›´æ–°ï¼ˆæ¯5ç§’æœ€å¤šè¯»ä¸€æ¬¡ï¼‰
    current_time = asyncio.get_event_loop().time()
    if _agent_configs_cache is None or (current_time - _cache_timestamp) > 5:
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                _agent_configs_cache = json.load(f)
                _cache_timestamp = current_time
    
    if _agent_configs_cache:
        for agent in _agent_configs_cache.get('agents', []):
            if agent.get('id') == agent_id:
                return agent
    return None

@app.post("/api/analyze")
async def analyze_stock(request: AnalyzeRequest):
    """ç»Ÿä¸€çš„æ™ºèƒ½ä½“åˆ†ææ¥å£"""
    try:
        agent_id = request.agent_id
        stock_code = request.stock_code
        stock_data = request.stock_data
        previous_outputs = request.previous_outputs
        
        # ä»ç¼“å­˜è·å–é…ç½®
        agent_config = get_agent_config(agent_id)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not agent_config:
            agent_config = {
                "modelName": "deepseek-chat",
                "modelProvider": "DEEPSEEK",
                "temperature": 0.3
            }
        
        model_name = agent_config.get("modelName", "deepseek-chat")
        temperature = agent_config.get("temperature", 0.3)
        
        # æ ¹æ®æ¨¡å‹åç§°åˆ¤æ–­ä½¿ç”¨å“ªä¸ªAPI
        # ä¼˜å…ˆåˆ¤æ–­ï¼šå¦‚æœåŒ…å«æ–œæ ï¼Œè¯´æ˜æ˜¯å¹³å°æ¨¡å‹ï¼ˆå¦‚ Qwen/Qwen3-8Bï¼‰ï¼Œä½¿ç”¨ç¡…åŸºæµåŠ¨
        api_endpoint = None
        if "/" in model_name:
            # åŒ…å«æ–œæ çš„éƒ½æ˜¯å¹³å°æ¨¡å‹ï¼Œé€šè¿‡ç¡…åŸºæµåŠ¨è®¿é—®
            api_endpoint = "/api/ai/siliconflow"
            provider = "SILICONFLOW"
        elif model_name.startswith("gemini"):
            # Geminiå®˜æ–¹æ¨¡å‹
            api_endpoint = "/api/ai/gemini"
            provider = "GEMINI"
        elif model_name in ["deepseek-chat", "deepseek-coder", "deepseek-reasoner"]:
            # DeepSeekå®˜æ–¹æ¨¡å‹ï¼ˆæ˜ç¡®åˆ—ä¸¾ï¼‰
            api_endpoint = "/api/ai/deepseek"
            provider = "DEEPSEEK"
        elif model_name in ["qwen-max", "qwen-plus", "qwen-turbo", "qwen-max-longcontext", "qwen-turbo-latest"] or "é€šä¹‰åƒé—®" in model_name:
            # Qwenå®˜æ–¹æ¨¡å‹ï¼ˆæ˜ç¡®åˆ—ä¸¾ï¼‰
            api_endpoint = "/api/ai/qwen"
            provider = "QWEN"
        else:
            # é»˜è®¤ä½¿ç”¨ç¡…åŸºæµåŠ¨ï¼ˆæ”¯æŒæœ€å¤šæ¨¡å‹ï¼‰
            api_endpoint = "/api/ai/siliconflow"
            provider = "SILICONFLOW"
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{get_agent_role(agent_id)}ã€‚è¯·åŸºäºæä¾›çš„è‚¡ç¥¨æ•°æ®è¿›è¡Œæ·±å…¥åˆ†æã€‚"
        
        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = f"è¯·åˆ†æè‚¡ç¥¨ä»£ç  {stock_code} çš„ä»¥ä¸‹æ•°æ®ï¼š\n"
        user_prompt += f"å½“å‰ä»·æ ¼: {stock_data.get('nowPri', 'N/A')}\n"
        user_prompt += f"ä»Šæ—¥æ¶¨è·Œå¹…: {stock_data.get('increase', 'N/A')}%\n"
        user_prompt += f"æˆäº¤é‡: {stock_data.get('traAmount', 'N/A')}\n"
        user_prompt += f"æˆäº¤é¢: {stock_data.get('traNumber', 'N/A')}\n"
        
        # å¦‚æœæœ‰ä¹‹å‰çš„åˆ†æç»“æœï¼Œæ·»åŠ åˆ°ä¸Šä¸‹æ–‡
        if previous_outputs:
            user_prompt += "\nå…¶ä»–å›¢é˜Ÿçš„åˆ†æç»“æœï¼š\n"
            for agent_name, output in previous_outputs.items():
                if output:
                    user_prompt += f"{agent_name}: {output[:200]}...\n"
        
        # è°ƒç”¨ç›¸åº”çš„AI API
        if provider == "GEMINI":
            req = GeminiRequest(
                prompt=user_prompt,
                systemPrompt=system_prompt,
                model=model_name,
                temperature=temperature
            )
            result = await gemini_api(req)
        elif provider == "DEEPSEEK":
            req = DeepSeekRequest(
                prompt=user_prompt,
                systemPrompt=system_prompt,
                model=model_name,
                temperature=temperature
            )
            result = await deepseek_api(req)
        elif provider == "QWEN":
            req = QwenRequest(
                prompt=user_prompt,
                systemPrompt=system_prompt,
                model=model_name,
                temperature=temperature
            )
            result = await qwen_api(req)
        else:
            req = SiliconFlowRequest(
                prompt=user_prompt,
                systemPrompt=system_prompt,
                model=model_name,
                temperature=temperature
            )
            result = await siliconflow_api(req)
        
        if result.get("success"):
            return {"success": True, "result": result.get("text", "")}
        else:
            return {"success": False, "error": result.get("error", "åˆ†æå¤±è´¥")}
            
    except Exception as e:
        import traceback
        print(f"[Analyze] é”™è¯¯: {str(e)}")
        print(traceback.format_exc())
        return {"success": False, "error": str(e)}

def get_agent_role(agent_id):
    """æ ¹æ®æ™ºèƒ½ä½“IDè·å–è§’è‰²æè¿°"""
    roles = {
        "macro": "å®è§‚ç»æµåˆ†æå¸ˆ",
        "industry": "è¡Œä¸šç ”ç©¶åˆ†æå¸ˆ",
        "technical": "æŠ€æœ¯åˆ†æå¸ˆ",
        "funds": "èµ„é‡‘æµå‘åˆ†æå¸ˆ",
        "fundamental": "åŸºæœ¬é¢åˆ†æå¸ˆ",
        "manager_fundamental": "åŸºæœ¬é¢æŠ•èµ„ç»ç†",
        "manager_momentum": "åŠ¨é‡æŠ•èµ„ç»ç†",
        "risk_system": "ç³»ç»Ÿæ€§é£é™©æ€»ç›‘",
        "risk_portfolio": "ç»„åˆé£é™©æ€»ç›‘",
        "gm": "æŠ•èµ„å†³ç­–æ€»ç»ç†"
    }
    return roles.get(agent_id, "æŠ•èµ„åˆ†æå¸ˆ")

# ==================== è‚¡ç¥¨æ•°æ® API ====================

@app.post("/api/stock/{symbol}")
async def stock_data(symbol: str, request: StockRequest):
    """èšåˆæ•°æ®è‚¡ç¥¨ API ä»£ç†"""
    try:
        api_key = request.apiKey or API_KEYS["juhe"]
        if not api_key:
            raise HTTPException(status_code=500, detail="æœªé…ç½®èšåˆæ•°æ® API Key")
        
        # æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç ï¼ˆæ·»åŠ  sh/sz å‰ç¼€ï¼‰
        formatted_symbol = symbol.lower()
        if not formatted_symbol.startswith(("sh", "sz")):
            first_digit = formatted_symbol[0]
            if first_digit in ['6', '9']:
                formatted_symbol = 'sh' + formatted_symbol
            elif first_digit in ['0', '2', '3']:
                formatted_symbol = 'sz' + formatted_symbol
        
        # ä½¿ç”¨å…¨å±€è¿æ¥æ± å®¢æˆ·ç«¯
        client = http_clients.get('juhe', http_clients['default'])
        params = {
            "gid": formatted_symbol,
            "key": api_key
        }
        response = await client.get(
            API_ENDPOINTS["juhe"],
            params=params
        )
        
        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail="èšåˆæ•°æ® API é”™è¯¯")
        
        result = response.json()
        
        # æ£€æŸ¥é”™è¯¯
        if result.get("error_code") and result["error_code"] != 0:
            return {"success": False, "error": result.get("reason", "æœªçŸ¥é”™è¯¯")}
        
        # æå–æ•°æ®
        if result.get("result") and len(result["result"]) > 0:
            stock_data = result["result"][0]
            return {"success": True, "data": stock_data}
        else:
            return {"success": False, "error": "æœªæ‰¾åˆ°è‚¡ç¥¨æ•°æ®"}
    
    except Exception as e:
        print(f"[Stock] é”™è¯¯: {str(e)}")
        return {"success": False, "error": str(e)}

# ==================== é…ç½®ç®¡ç† API ====================

@app.get("/api/config")
async def get_config():
    """è·å–é…ç½®ä¿¡æ¯ï¼ˆä¸åŒ…å«æ•æ„Ÿçš„ API Keysï¼‰"""
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥
    config = {
        "api_keys": {},
        "model_configs": [],
        "backend_status": "running",
        "endpoints": list(API_ENDPOINTS.keys())
    }
    
    # æ£€æŸ¥å„ä¸ªAPIå¯†é’¥ - ä½¿ç”¨å·²åŠ è½½çš„API_KEYS
    if API_KEYS.get("gemini"):
        config["api_keys"]["gemini"] = "configured"
        config["GEMINI_API_KEY"] = "configured"
    
    if API_KEYS.get("deepseek"):
        config["api_keys"]["deepseek"] = "configured"
        config["DEEPSEEK_API_KEY"] = "configured"
    
    if API_KEYS.get("qwen"):
        config["api_keys"]["qwen"] = "configured"
        config["DASHSCOPE_API_KEY"] = "configured"
        
    if API_KEYS.get("siliconflow"):
        config["api_keys"]["siliconflow"] = "configured"
        config["SILICONFLOW_API_KEY"] = "configured"
        
    if API_KEYS.get("juhe"):
        config["api_keys"]["juhe"] = "configured"
        config["JUHE_API_KEY"] = "configured"
    
    # å°è¯•ä»æ–‡ä»¶åŠ è½½æ¨¡å‹é…ç½®
    try:
        config_file = os.path.join(os.path.dirname(__file__), 'agent_configs.json')
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                saved_config = json.load(f)
                if 'model_configs' in saved_config:
                    config["model_configs"] = saved_config['model_configs']
        else:
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹é…ç½®
            config["model_configs"] = [
                {"id": "macro", "model_name": "gemini-2.0-flash-exp", "temperature": 0.3},
                {"id": "industry", "model_name": "deepseek-chat", "temperature": 0.3},
                {"id": "technical", "model_name": "qwen-plus", "temperature": 0.2},
                {"id": "funds", "model_name": "Qwen/Qwen2.5-7B-Instruct", "temperature": 0.2},
                {"id": "fundamental", "model_name": "deepseek-chat", "temperature": 0.3}
            ]
    except Exception as e:
        print(f"åŠ è½½æ¨¡å‹é…ç½®å¤±è´¥: {e}")
        
    return config

@app.post("/api/config/update")
async def update_config(keys: Dict[str, str]):
    """åŠ¨æ€æ›´æ–° API Keysï¼ˆä»…é™å¼€å‘ç¯å¢ƒï¼‰"""
    global API_KEYS
    for key, value in keys.items():
        if key in API_KEYS and value:
            API_KEYS[key] = value
    return {"success": True, "message": "é…ç½®å·²æ›´æ–°"}

@app.post("/api/config/agents")
async def save_agent_configs(config_data: Dict[str, Any]):
    """ä¿å­˜æ™ºèƒ½ä½“é…ç½®åˆ°æ–‡ä»¶ï¼ˆåŒ…æ‹¬æ¨¡å‹é€‰æ‹©ï¼‰"""
    try:
        config_file = os.path.join(os.path.dirname(__file__), "agent_configs.json")
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, ensure_ascii=False, indent=2)
        
        agent_count = len(config_data.get('agents', []))
        model_count = len(config_data.get('selectedModels', []))
        print(f"[é…ç½®] å·²ä¿å­˜ {agent_count} ä¸ªæ™ºèƒ½ä½“é…ç½®å’Œ {model_count} ä¸ªæ¨¡å‹é€‰æ‹©")
        return {"success": True, "message": "é…ç½®å·²ä¿å­˜"}
    except Exception as e:
        print(f"[é…ç½®] ä¿å­˜å¤±è´¥: {str(e)}")
        return {"success": False, "error": str(e)}

@app.get("/api/config/agents")
async def load_agent_configs():
    """ä»æ–‡ä»¶åŠ è½½æ™ºèƒ½ä½“é…ç½®ï¼ˆåŒ…æ‹¬æ¨¡å‹é€‰æ‹©ï¼‰"""
    try:
        config_file = os.path.join(os.path.dirname(__file__), "agent_configs.json")
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            # å…¼å®¹æ—§æ ¼å¼ï¼ˆç›´æ¥æ˜¯æ•°ç»„ï¼‰
            if isinstance(config_data, list):
                config_data = {"agents": config_data, "selectedModels": []}
            
            agent_count = len(config_data.get('agents', []))
            model_count = len(config_data.get('selectedModels', []))
            print(f"[é…ç½®] å·²åŠ è½½ {agent_count} ä¸ªæ™ºèƒ½ä½“é…ç½®å’Œ {model_count} ä¸ªæ¨¡å‹é€‰æ‹©")
            return {"success": True, "data": config_data}
        else:
            return {"success": True, "data": {"agents": [], "selectedModels": []}}
    except Exception as e:
        print(f"[é…ç½®] åŠ è½½å¤±è´¥: {str(e)}")
        return {"success": False, "error": str(e), "data": {"agents": [], "selectedModels": []}}

# ==================== é™æ€æ–‡ä»¶æœåŠ¡ ====================

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
import os.path
static_dir = os.path.join(os.path.dirname(__file__), "static")
if os.path.exists(static_dir):
    app.mount("/static", StaticFiles(directory=static_dir), name="static")

# ==================== å¥åº·æ£€æŸ¥ ====================

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - è¿”å› HTML é¡µé¢ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
    html_file = os.path.join(static_dir, "index.html")
    if os.path.exists(html_file):
        return FileResponse(html_file)
    else:
        return {
            "status": "running",
            "service": "IcySaint AI Backend",
            "version": "1.0.0",
            "endpoints": [
                "/api/ai/gemini",
                "/api/ai/deepseek",
                "/api/ai/qwen",
                "/api/ai/siliconflow",
                "/api/ai/siliconflow-models",
                "/api/analyze",
                "/api/stock/{symbol}",
                "/api/config"
            ]
        }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy"}

# ==================== å¯åŠ¨æœåŠ¡å™¨ ====================

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         IcySaint AI - Python Backend Server          â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # æ£€æŸ¥ API Keys é…ç½®ï¼ˆä½¿ç”¨å…¨å±€çš„API_KEYSï¼Œä¸è¦é‡æ–°èµ‹å€¼ï¼‰
    print("ğŸ“‹ API Keys é…ç½®çŠ¶æ€:")
    for name, key in API_KEYS.items():
        status = "âœ… å·²é…ç½®" if key else "âŒ æœªé…ç½®"
        print(f"  {name.upper()}: {status}")
    
    print("\nğŸš€ å¯åŠ¨æœåŠ¡å™¨...")
    print("ğŸ“ åç«¯API: http://localhost:8000")
    print("ğŸ“ Vueå‰ç«¯: http://localhost:8080")
    print("ğŸ“ APIæ–‡æ¡£: http://localhost:8000/docs")
    print("\nâœ¨ æ¶æ„: FastAPIåç«¯ + Vue3å‰ç«¯")
    print("ğŸ’¡ æç¤º: è¯·ç¡®ä¿Vueå‰ç«¯ä¹Ÿåœ¨è¿è¡Œ (npm run serve)")
    print("ğŸ¯ ä½¿ç”¨ scripts/dev.py å¯ä¸€é”®å¯åŠ¨å‰åç«¯ï¼")
    print("-" * 60)
    
    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        app,  # ç›´æ¥ä½¿ç”¨appå¯¹è±¡è€Œä¸æ˜¯å­—ç¬¦ä¸²å¯¼å…¥
        host="0.0.0.0",
        port=8000,
        reload=False,  # å…³é—­è‡ªåŠ¨é‡è½½ä»¥é¿å…CORSé—®é¢˜
        log_level="info"
    )
