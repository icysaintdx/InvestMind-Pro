# LLM 超时多级降级方案

**设计日期**: 2025-12-11  
**问题**: 个别智能体超时导致分析中断  
**目标**: 零中断分析流程

---

## 🎯 核心洞察

### 超时类型分析

| 超时类型 | 含义 | 发生频率 | 严重程度 | 根本原因 |
|---------|------|---------|---------|---------|
| **连接超时 (15s)** | 无法建立TCP连接 | 极少 | 🔴 致命 | 网络故障 |
| **读取超时 (60s)** | 服务器无响应 | 较多 | 🔴 关键 | LLM负载/提示词过长 |
| **传输超时 (90s)** | 响应传输过慢 | 很少 | 🟡 一般 | 响应内容过长 |

### 关键发现

✅ **`read_timeout`** = 服务器开始响应的时间（首字节 TTFB）
- 一旦收到任何数据，超时会重置
- 60秒内没有任何响应 = 服务器根本没处理

✅ **个别超时现象** = LLM 负载问题，不是网络问题
- 同一流程中，某个智能体超时，其他正常
- 说明是请求内容或 LLM 压力导致

---

## 🚀 多级降级策略

### 降级级别

```
级别0: 原始请求 (60s) ──失败──> 级别1: 轻度压缩 (45s)
                                    │
                                    ↓失败
                              级别2: 深度压缩 (30s)
                                    │
                                    ↓失败
                              级别3: 最小化 (20s)
                                    │
                                    ↓失败
                              级别4: 默认响应 (0s)
```

### 详细配置

| 级别 | 名称 | 超时 | 压缩比 | 输出长度 | 适用场景 |
|------|------|------|--------|----------|----------|
| **0** | 原始请求 | 60s | 100% | 1024 tokens | 正常情况 |
| **1** | 轻度压缩 | 45s | 50% | 512 tokens | 轻微负载 |
| **2** | 深度压缩 | 30s | 25% | 256 tokens | 中度负载 |
| **3** | 最小化 | 20s | 10% | 128 tokens | 严重负载 |
| **4** | 默认响应 | 0s | - | - | 完全失败 |

---

## 💡 实现特性

### 1. 智能压缩

```python
# 保留关键信息的压缩
关键词识别: ["股票", "价格", "建议", "风险", "财务"]
压缩策略:
  - 70% 空间给关键信息
  - 30% 空间给其他内容
  - 保留数字和百分比
```

### 2. 请求缓存

```python
# 相同请求直接返回缓存
缓存键 = MD5(agent_role + prompt[:100])
缓存时间 = 5分钟
命中率预期 = 20-30%（重复分析同一股票）
```

### 3. 错误统计

```python
错误记录:
  - 总错误次数
  - 超时次数
  - 错误类型分布
  - 最后错误时间
  
用途:
  - 识别问题模式
  - 优化降级策略
  - 预警系统问题
```

### 4. 详细错误报告

```
======== LLM 请求失败报告 ========
智能体: NEWS_ANALYST
时间: 2025-12-11 03:00:00
总耗时: 155.3秒

请求信息:
- 原始提示词长度: 8543 字符
- 估算Token数: 4271
- 请求体大小: 9.2 KB

尝试记录:
  级别0: 60.1s - timeout_level_0
  级别1: 45.0s - timeout_level_1
  级别2: 30.1s - timeout_level_2
  级别3: 20.1s - timeout_level_3

历史统计:
- 总错误次数: 3
- 超时次数: 3
- 错误类型分布: {'timeout_level_0': 3}

建议:
1. 减少新闻数据量
2. 使用更快的模型
3. 调整分析深度
```

---

## 🎯 默认响应策略

### 智能体特定响应

| 智能体 | 默认响应 | 风险等级 |
|--------|----------|----------|
| **NEWS** | 基于历史经验，建议保持观望 | 🟡 中性 |
| **FUNDAMENTAL** | 参考公开财报数据 | 🟡 中性 |
| **TECHNICAL** | 关注关键支撑位 | 🟡 中性 |
| **BULL** | 数据不足，谨慎乐观 | 🟢 偏多 |
| **BEAR** | 数据不足，保持谨慎 | 🔴 偏空 |
| **RISK** | 采用保守策略，持有观望 | 🔴 保守 |
| **MANAGER** | 维持现有仓位 | 🟡 中性 |
| **TRADER** | 等待交易信号 | 🟡 中性 |

### 降级标记

```python
# 响应中添加降级标记
if fallback_level > 0:
    text = f"[降级级别{level}: {level_name}]\n{text}"
    
# 前端可以识别并显示
if (response.fallback_level > 0) {
    showWarning(`使用了降级响应（级别${response.fallback_level}）`)
}
```

---

## 📊 效果对比

### 修复前

| 场景 | 结果 | 用户体验 |
|------|------|----------|
| 60秒超时 | 分析中断 ❌ | 需要重新分析 |
| 部分智能体失败 | 流程卡住 ❌ | 无法获得完整报告 |
| 提示词过长 | 直接失败 ❌ | 无解决方案 |

### 修复后

| 场景 | 结果 | 用户体验 |
|------|------|----------|
| 60秒超时 | 自动降级 ✅ | 获得压缩版结果 |
| 部分智能体失败 | 使用默认响应 ✅ | 获得完整报告 |
| 提示词过长 | 自动压缩 ✅ | 正常完成分析 |

---

## 🔧 集成步骤

### 1. 安装降级处理器

```bash
# 文件已创建
backend/utils/llm_fallback_handler.py
```

### 2. 修改 server.py

```python
# 导入
from backend.utils.llm_fallback_handler import get_fallback_handler

# 在 siliconflow_api 中使用
fallback_handler = get_fallback_handler()
result, metrics = await fallback_handler.execute_with_fallback(
    client=client,
    url=url,
    headers=headers,
    data=data,
    agent_role=agent_role
)
```

### 3. 前端传递角色

```javascript
// 在请求中添加 agentRole
const response = await axios.post('/api/ai/siliconflow', {
    model: 'Qwen/Qwen2.5-7B-Instruct',
    prompt: promptText,
    systemPrompt: systemPrompt,
    agentRole: 'NEWS',  // ← 添加这个
    temperature: 0.7
})
```

### 4. 前端处理降级

```javascript
// 检查是否使用了降级
if (response.data.fallback_level > 0) {
    if (response.data.fallback_level === 99) {
        // 使用了默认响应
        console.warn('使用了默认响应')
    } else {
        // 使用了压缩响应
        console.warn(`使用了级别${response.data.fallback_level}降级`)
    }
}
```

---

## 📈 监控指标

### 关键指标

1. **降级率**
   - 目标: < 5%
   - 警戒: > 10%
   - 严重: > 20%

2. **平均响应时间**
   - 优秀: < 10s
   - 正常: 10-30s
   - 缓慢: > 30s

3. **默认响应率**
   - 目标: < 1%
   - 警戒: > 3%
   - 严重: > 5%

### 监控仪表板

```python
# 获取统计信息
stats = fallback_handler.error_stats

# 生成报告
for agent, data in stats.items():
    print(f"{agent}:")
    print(f"  错误率: {data['total_errors']}")
    print(f"  超时率: {data['timeout_errors']}")
```

---

## 🚨 注意事项

### 1. 压缩质量

- 轻度压缩（50%）：基本保留所有关键信息
- 深度压缩（25%）：可能丢失部分细节
- 最小化（10%）：只保留核心结论

### 2. 缓存策略

- 缓存时间不宜过长（5分钟）
- 定期清理缓存防止内存溢出
- 敏感信息不应缓存

### 3. 降级透明度

- 始终告知用户使用了降级
- 记录降级原因供调试
- 提供手动重试选项

---

## ✅ 总结

### 实现目标

1. ✅ **零中断**: 即使 LLM 完全失败，也返回默认响应
2. ✅ **智能降级**: 4级降级，逐步压缩
3. ✅ **详细报告**: 完整的错误信息和统计
4. ✅ **缓存优化**: 避免重复请求
5. ✅ **透明度**: 用户知道降级情况

### 预期效果

- **成功率提升**: 95% → 99.9%
- **平均响应时间**: 降低 30%
- **用户体验**: 大幅改善
- **运维压力**: 显著降低

### 后续优化

1. 根据历史数据优化压缩算法
2. 实现智能缓存预热
3. 添加 A/B 测试对比降级效果
4. 集成监控告警系统

---

**降级方案设计完成！** 🎉

这个方案可以确保：
- 除非网络完全断开，否则总能返回结果
- 用户永远不会因为个别超时而中断分析
- 提供详细的错误信息用于问题排查
