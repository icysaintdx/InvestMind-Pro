股票数据

数据名称	API	描述	最低分值
日线行情	daily	全部历史，交易日每日15点～17点之间更新	120起
周线行情	weekly	全部历史，每周五15点～17点之间更新	2000
月线行情	monthly	全部历史，每月更新	2000
复权行情	pro_bar	全部历史，每月更新	2000 （分钟、指数、基金、期货除外）
每日指标数据	daily_basic	交易日每日15点～17点之间更新	2000起
IPO新股列表	new_share	每日19点更新	120
龙虎榜每日明细	top_list	数据开始于2005年，每日晚8点更新	2000
龙虎榜机构交易明细	top_inst	数据开始于2005年，每日晚8点更新	2000
股权质押明细	pledge_detail	数据开始于2004年，每日晚9点更新	2000
股权质押统计	pledge_stat	数据开始于2014年，每日晚9点更新	2000
融资融券交易汇总	margin	数据开始于2010年，每日9点更新	2000
融资融交易明细	margin_detail	数据开始于2010年，每日9点更新	2000
股票回购	repurchase	数据开始于2011年，每日定时更新	2000
限售股解禁	share_float	定期更新	3000
大宗交易	block_trade	每日晚9点	2000
股东人数	stk_holdernumber	不定期更新	2000
个股资金流向	moneyflow	交易日19点	2000
股东增减持	stk_holdertrade	交易日19点	2000
每日涨跌停价格	stk_limit	交易日9点	2000起
沪深股通持股明细	hk_hold	下个交易日8点	2000起


财务数据

数据名称	API	描述	最低分值
利润表	income	全部历史，实时更新	2000起
资产负债表	balancesheet	全部历史，实时更新	2000起
现金流量表	cashflow	全部历史，实时更新	2000起
业绩预告	forecast	全部历史，实时更新	2000起
业绩快报	express	全部历史，实时更新	2000起
分红送股	dividend	全部历史，实时更新	2000起
财务指标数据	fina_indicator	全部历史，随财报实时更新	2000起
财务审计意见	fina_audit	全部历史，随财报实时更新	2000起
主营业务构成	fina_mainbz	全部历史，随财报实时更新	2000起
财报披露计划	disclosure_date	全部历史，定期更新	2000起


基金数据

数据名称	API	描述	最低分值
公募基金列表	fund_basic	全部历史，定时更新	2000
公募基金公司	fund_company	全部历史，定时更新	2000
公募基金净值	fund_nav	全部历史，每日定期更新	2000
场内基金日线行情	fund_daily	全部历史，每日盘后更新	2000
公募基金分红	fund_div	全部历史，定期更新	2000
公募基金持仓数据	fund_portfolio	股票持仓数据，定期采集更新	2000
基金复权因子	fund_adj	基金复权因子，每日17点更新	5000起


期货数据

数据名称	API	描述	最低分值
期货合约列表	fut_basic	全部历史	2000
期货交易日历	trade_cal	数据开始月1996年1月，定期更新	2000
期货日线行情	fut_daily	数据开始月1996年1月，每日盘后更新	2000
每日成交持仓排名	fut_holding	数据开始月2002年1月，每日盘后更新	2000
仓单日报	fut_wsr	数据开始月2006年1月，每日盘后更新	2000
结算参数	fut_settle	数据开始月2012年1月，每日盘后更新	2000
南华期货指数行情	index_daily	超过10年历史，每日盘后更新	2000


期权数据

数据名称	API	描述	最低分值
期权合约列表	opt_basic	全部历史，每日晚8点更新	2000起
期权日线行情	opt_daily	全部历史，每日17点更新	5000起


债券数据

数据名称	API	描述	最低分值
可转债基础信息	cb_basic	全部历史，每日更新	2000
可转债发行数据	cb_issue	全部历史，每日更新	2000
可转债日线数据	cb_daily	全部历史，每日17点更新	2000


外汇数据

数据名称	API	描述	最低分值
外汇基础信息（海外）	fx_obasic	全部历史，每日更新	2000
外汇日线行情	fx_daily	全部历史，每日更新	2000


指数数据

数据名称	API	描述	最低分值
指数基本信息	index_basic	每日更新	2000
指数日线行情	index_daily	全部历史，交易日15点～17点更新	2000起
指数周线行情	index_weekly	每周盘后更新	2000起
指数月线行情	index_monthly	每月盘后更新	2000起
指数成分和权重	index_weight	月度成分和权重数据	2000
大盘指数每日指标	index_dailybasic	数据开始月2004年1月，每日盘后更新	4000起
申万行业分类	index_classify	全部分类	2000
申万行业成分	index_member_all	全部数据	2000


港股数据

数据名称	API	描述	最低分值
港股列表	hk_basic	全部历史，每日更新	2000
港股日线行情	hk_daily	全部历史，每日更新	1000元
港股分钟行情	hk_mins	全部历史，每日更新	2000元


行业特色

数据名称	API	描述	最低分值
台湾电子产业月营收	tmt_twincome	数据开始于2011年，月度更新	0
台湾电子产业月营收明细	tmt_twincomedetail	数据开始于2011年，月度更新	0
电影月度票房	bo_monthly	数据开始于2008年，月度更新	500
电影周度票房	bo_weekly	数据开始于2008年，每周更新	500
电影日度票房	bo_daily	数据开始于2018年，每日更新	500
影院每日票房	bo_cinema	数据开始于2018年，每日更新	500
全国电影剧本备案数据	film_record	数据开始于2011年，定期更新	120起
全国电视剧本备案数据	teleplay_record	数据开始于2009年，定期更新	600起


宏观经济

数据名称	API	描述	最低分值
SHIBOR利率数据	shibor	数据开始于2006年，每日12点	2000
SHIBOR报价数据	shibor_quote	数据开始于2006年，每日12点	2000
LPR贷款基础利率	shibor_lpr	数据开始于2013年，每日12点	120
LIBOR拆借利率	libor	数据开始于1986年，每日12点	120
HIBOR拆借利率	hibor	数据开始于2002年，每日12点	120
温州民间借贷利率	wz_index	数据不定期更新	2000
广州民间借贷利率	gz_index	数据不定期更新	2000




平台分为两种权限模式：

1、需要积分的接口，此类接口需要达到一定的积分门槛，只要满足积分要求，都可以调取。类似各类资产的日线行情、基础数据等。（见下方表一）

2、需要单独开权限的接口，此类接口是单独开权限，跟积分没有关系，且是分别开权限各自独立。类似分钟数据、新闻舆情、公告等等。（见下方表二）



表（一）：积分接口

积分数	每分钟频次	每天总量上限	可以访问的接口（本表格积分不包括分钟权限）	捐助（元/年）
120	50	8000次	股票非复权日线行情，其他接口无法调取	0
2000以上	200	100000次/个API	tushare.pro 60%的API可以调取，可参考每个接口的积分要求	200
5000以上	500	常规数据无上限	tushare.pro 90%的API可以调取，可参考每个接口的积分要求	500
10000以上	1000	常规数据无上限，特色数据300次每分钟	特色数据权限，包括盈利预测数据、每日筹码和胜率、筹码分布、券商每月金股等数据	1000
15000以上	1000	特色数据无总量限制	特色数据专属权限	1500
10000积分以上可以有更高的API频次和权限，比如股票特色数据



此外，分钟和港美股数据权限不在积分范畴内，各类分钟单独分别开权限，且不加积分，以下是需要单独权限列表。



表（二）：独立权限接口

类型	包含数据	历史起始	捐助（元/年）	频次
股票历史分钟	1、5、15、30、60分钟	2009年	2000	每分钟500次，每次8000行数据，总量不限制
股票实时分钟	1、5、15、30、60分钟	实时	1000/月	每分钟500次，单次可同时请求300个股票
股票实时日线	开盘后当日实时日线成交情况	每天9点半开始	200/月，支付时备注“A实时”	每分钟50次，每次可以提取全市场
指数实时日线	开盘后指数实时成交情况	每天9点半开始	200/月，支付时备注“指数实时”	每分钟50次，每次可以提取全市场
ETF实时日线	开盘后当日ETF实时日线成交情况	每天9点半开始	200/月，支付时备注“ETF实时”	每分钟50次，每次可以提取全市场
期货历史分钟	1、5、15、30、60分钟	2010年	2000	每分钟500次，每次8000行数据，总量不限制
期货实时分钟	1、5、15、30、60分钟	全市场日盘夜盘实时更新	1000/月	支持SDK/HTTP/WebSocket
期权历史分钟	1、5、15、30、60分钟	2010年	2000，包含股指和商品期权	每分钟500次，每次8000行数据，总量不限制
申万分钟	同上	2015年	2000	每分钟500次，每次8000行数据，总量不限制
港股日线	日线，包括复权行情	全历史	1000	每分钟500次，每次6000行，总量不限制
港股分钟	分钟	2015年	2000	每分钟500次，每次8000行，总量不限制
港股财报	财报	2000年	单独500元或有15000积分	每分钟500次，每次10000行，总量不限制
港股实时日线	实时日线	每天9点半开始	1000/月，支付时备注“HK实时”	每分钟50次，每次可以提取全市场
美股日线	日线，包含估值指标、换手率等，提供复权行情	全股票全历史	2000	每分钟500次，每次8000行，总量不限制
美股财报	财报	2000年	单独500元或有15000积分	每分钟500次，每次10000行，总量不限制
新闻资讯	快讯、长篇新闻、新闻联播	3年以上	1000	每分钟400次，总量不限制
公告信息	包括股票、基金、固收相关的历史和增量公告，包括标题和pdf下载链接	10年以上	1000	每分钟500次
可转债价格变动	可转债转股价变动	全历史	500	每分钟500次，总量不限制
盘前股本	开盘前当日股本情况	近2年，每天更新次日数据	500	每分钟500次，总量不限制
上证e互动、深证互动易	上海和深圳交易所董秘问答文本数据	历史：深证25年历史 上证2年历史，每天更新数据	500或已经积累了1w积分	每分钟500次，总量不限制
集合竞价	开盘后当日集合竞价成交情况	每天9点半之前可以提取当日集合成交	单独500元或有10000积分或开通过股票分钟权限	每分钟500次，总量不限制


数据采集、预处理与建模
作者：Tushare社区用户

本系列主要介绍一套比较简单且完备的量化框架，该框架基于现代投资组合理论，并应用主流的机器学习算法进行分析，旨在帮助大家拓展量化投资的思路，辅助构建科学合理的投资策略。

作为系列第一篇，根据分析和计算流程，本篇主要介绍三部分：数据采集，数据预处理，利用SVM算法进行建模。

>> 数据采集 <<
本系列的量化框架，全部采用本地化计算。为什么要本地化计算呢，因为相比在线获取数据进行分析计算，本地化计算有如下优势：

1. 稳定——不会因网络不稳定而导致分析过程中断。
2. 快速——本地化运算对于数据的访问速度比在线获取数据快，当机器学习的算法涉及到海量数据做训练集或迭代训练的时候，这一点尤其重要。
3. 可复用——无论基础的行情数据还是加工处理后的数据，保存在本地后，对于后续进行结果分析或策略优化时更为方便。
我们进行本地化计算，首先要做的，就是将所需的基础数据采集到本地数据库里，本篇的示例源码采用的数据库是MySQL5.5，数据源是tushare pro接口。

我们现在要取一批特定股票的日线行情，部分代码如下：

# 设置tushare pro的token并获取连接
ts.set_token('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')
pro = ts.pro_api()
# 设定获取日线行情的初始日期和终止日期，其中终止日期设定为昨天。
start_dt = '20100101'
time_temp = datetime.datetime.now() - datetime.timedelta(days=1)
end_dt = time_temp.strftime('%Y%m%d')
# 建立数据库连接,剔除已入库的部分
db = pymysql.connect(host='127.0.0.1', user='root', passwd='admin', db='stock', charset='utf8')
cursor = db.cursor()
# 设定需要获取数据的股票池
stock_pool = ['603912.SH','300666.SZ','300618.SZ','002049.SZ','300672.SZ']
total = len(stock_pool)
# 循环获取单个股票的日线行情
for i in range(len(stock_pool)):
    try:
        df = pro.daily(ts_code=stock_pool[i], start_date=start_dt, end_date=end_dt)
        # 打印进度
        print('Seq: ' + str(i+1) + ' of ' + str(total) + '   Code: ' + str(stock_pool[i]))
上述代码的注释部分已将每行代码的功能解释清楚了，实际上数据采集的程序主要设置三个参数：获取行情的初始日期，终止日期，以及股票代码池。

当我们获取数据后，就要往本地数据库进行写入（存储）操作了，本篇代码用的是SQL语言，需提前在数据库内建好相应的表，表配置和表结构如下：

库名：stock       表名：stock_all


其中 state_dt 和 stock_code 是主键和索引。state_dt 的格式是 ‘yyyy-mm-dd’（例：'2018-06-11'）。这样的日期格式便于查询，且在MySQL内部能够进行大小比较。
（完整的数据采集代码详见 Init_StockAll_Sp.py 文件）

>> 数据预处理 <<
无论是量化策略还是单纯的机器学习项目，数据预处理都是非常重要的一环。以机器学习的视角来看，数据预处理主要包括数据清洗，排序，缺失值或异常值处理，统计量分析，相关性分析，主成分分析（PCA），归一化等。本篇所要介绍的数据预处理比较简单，只是将存在本地数据库的日线行情数据整合成一份训练集数据，以用于后续的机器学习建模和训练。

在介绍具体的示例代码之前，我们需要先思考一个问题，应用有监督学习的算法对个股进行建模，我们的输入数据有哪些，我们期望得到的输出数据又是什么？

这个问题的答案因人而异，因策略而异。这个问题本身是将市场问题转化为数学问题的一个过程。依赖的是量化宽客自己的知识体系和对市场的理解。

回到正题，本篇示例我们将以最简单的数据进行分析，我们输入端的数据是个股每日基础行情，输出端数据是股价相较前一交易日的涨跌状态。简单点说就是，我们向模型输入今天的基础行情，让模型预测明天股价是涨还是跌。

在代码实现方式上，我们采用面向对象的思想，将整个数据预处理过程和结果，封装成一个类，每次创建一个类实例，就得到了特定条件下的一份训练集。示例代码如下：

class data_collect(object):

    def __init__(self, in_code,start_dt,end_dt):
        ans = self.collectDATA(in_code,start_dt,end_dt)

    def collectDATA(self,in_code,start_dt,end_dt):
        # 建立数据库连接，获取日线基础行情(开盘价，收盘价，最高价，最低价，成交量，成交额)
        db = pymysql.connect(host='127.0.0.1', user='root', passwd='admin', db='stock', charset='utf8')
        cursor = db.cursor()
        sql_done_set = "SELECT * FROM stock_all a where stock_code = '%s' and state_dt >= '%s' and state_dt <= '%s' order by state_dt asc" % (in_code, start_dt, end_dt)
        cursor.execute(sql_done_set)
        done_set = cursor.fetchall()
        if len(done_set) == 0:
            raise Exception
        self.date_seq = []
        self.open_list = []
        self.close_list = []
        self.high_list = []
        self.low_list = []
        self.vol_list = []
        self.amount_list = []
        for i in range(len(done_set)):
            self.date_seq.append(done_set[i][0])
            self.open_list.append(float(done_set[i][2]))
            self.close_list.append(float(done_set[i][3]))
            self.high_list.append(float(done_set[i][4]))
            self.low_list.append(float(done_set[i][5]))
            self.vol_list.append(float(done_set[i][6]))
            self.amount_list.append(float(done_set[i][7]))
        cursor.close()
        db.close()
        # 将日线行情整合为训练集(其中self.train是输入集，self.target是输出集，self.test_case是end_dt那天的单条测试输入)
        self.data_train = []
        self.data_target = []
最终这个类实例化后是要整合出三个数据：

1. self.train ：训练集中的输入端数据，本例中是每日基础行情。
2. self.target ：训练集中的输出数据，本例中相较于前一天股价的涨跌，涨为1，不涨为0。并且在排序上，每条 t 交易日的self.train里的数据对应的是 t+1 天股价的涨跌状态。
3. self.test_case ：在 t 末交易日的基础行情数据，作为输入端，用于模型训练完成后，对第二天的涨跌进行预测。
（完整的数据预处理代码详见 DC.py 文件）

>> SVM建模 <<
机器学习中有诸多有监督学习算法，SVM是比较常见的一种，本例采用SVM算法进行建模。关于SVM的理论原理本篇不做详述，以下仅从实践角度进行建模介绍。

先贴一段建模、训练并进行预测的代码大家感受一下：）

model = svm.SVC()               # 建模
model.fit(train, target)        # 训练
ans2 = model.predict(test_case) # 预测
三行代码，让人想起了把大象装冰箱分几步的冷笑话……

不过这侧面也说明Python在数据挖掘方面的强大之处：简单，方便，好用。

本例用的机器学习框架是scikit-learn。是个非常强大的算法库，熟悉算法原理的朋友可以查阅官方API文档，可修改模型参数，进一步调优模型；亦可尝试其他算法比如决策树，逻辑回归，朴素贝叶斯等。

（完整的SVM建模代码详见 SVM.py 文件）

最后，我们虽然顺利建模并作出预测，但仍面对两个主要问题：1.模型预测能力如何？或者说该如何评估一个模型的质量？2.该如何结合模型进行仓位管理？风险如何？如何量化？

pip安装超时的解决方案
作者： Tushare社区用户 晓子

在中国大陆使用pip进行python包安装的时候经常会出现socket.timeout: The read operation timed out的问题，下面就讲讲解决方案。

>> 解决方案 <<
使用国内镜像（以安装tushare pro为例）

pip install tushare -i https://pypi.tuna.tsinghua.edu.cn/simple/
>> 深入探讨 <<
下面仔细说说上述问题并深入探讨下国内镜像的配置。

出现超时，主要是因为PyPI（pip命令的包）使用的源在国外，导致大陆链接速度过慢，进而引起超时。故而，我们可以使用国内的镜像来下载安装包。下面列举国内常用的一些安装镜像：

镜像	链接
阿里云	http://mirrors.aliyun.com/pypi/simple/
中国科技大学	https://pypi.mirrors.ustc.edu.cn/simple/
豆瓣(douban)	http://pypi.douban.com/simple/
清华大学	https://pypi.tuna.tsinghua.edu.cn/simple/
中国科学技术大学	http://pypi.mirrors.ustc.edu.cn/simple/
镜像的使用方法
在使用pip时传递-i及相应的镜像地址即可（见以下tushare pro的安装）

pip install tushare -i https://pypi.tuna.tsinghua.edu.cn/simple/
not a trusted or secure host 问题
如果在使用某个镜像时遇到如下的 not a trusted or secure host 提醒，并且确认该host是可信赖的，可以按照提示添加 --trusted-host 及该host链接来进行安装。

The repository located at pypi.douban.com is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherw
ise you may silence this warning and allow it anyway with '--trusted-host pypi.douban.com'.
配置默认镜像
如果觉得每次安装时添加镜像链接比较麻烦，可以将该镜像链接配置成默认源，方法如下：

需要创建或修改配置文件（一般都是创建，不同系统配置文件路径见下表），

系统	路径
linux	~/.pip/pip.conf
windows	%HOMEPATH%\pip\pip.ini
注：windows下可以在cmd中使用 echo %HOMEPATH% 来查看HOMEPATH。

修改内容为：

[global]
index-url = http://pypi.douban.com/simple
[install]
trusted-host=pypi.douban.com
这样在使用pip来安装时，会默认调用该镜像。

在python脚本中临时使用镜像
临时使用其他源安装软件包的python脚本如下：

#!/usr/bin/python

import os

package = input("Input the package:\n")
command = "pip install %s -i http://pypi.mirrors.ustc.edu.cn/simple --trusted-host pypi.mirrors.ustc.edu.cn" % package
os.system(command)

机器量化分析（二）——模型评估与仓位管理
作者：Tushare社区用户

在上一篇中，我们介绍了简单的数据收集，数据预处理与建模案例，本篇承接上篇内容，主要介绍两部分：模型评估，仓位管理。

>> 模型评估 <<
在机器学习领域，有诸多评估模型的方法和指标，本篇介绍一个最简单常用的指标——F1分值。

要计算模型的F1分值，就要了解混淆矩阵。但在介绍混淆矩阵之前，我们先从实际场景出发，去理解模型评估的思路。

当我们想设计一个模型评估的指标时，一个朴素的想法就是准确率，即模型正确预测的数量，Acc = T（正确预测的次数）/ N（总预测次数）。但在实际的场景中，我们关注的往往是单边的预测准确率，比如在上篇的数据建模里，想要盈利，我们最关心的是预测股价上涨的概率，而预测不上涨的概率则不那么重要；那么公式就需要稍微修改一下：Acc = Tp（预测为上涨且预测正确的次数）/ N（总预测次数）。这个公式虽然能描述正样本的预测准确率，但却有个致命缺陷——当模型把所有样本都预测为正样本时，该公式的准确率是100%！反映在实际场景中，就是无脑买多，这显然是不合理的。究其根本，问题出在公式的分母中，由于无论如何预测，分母都是不变的，那么显然把所有样本点都预测为正得到的准确率最大。为此，我们还需要修改公式，而且是从分母入手，可以有两种方案：

1. Acc（Precision） = Tp（预测为上涨且正确的次数）/ Tp + Fp(预测为上涨但实际不上涨的次数)。 该公式的分母，是所有预测为上涨（无论实际上涨与否）的次数。
2. Acc（Recall） = Tp（预测为上涨且正确的次数）/ Tp + Fn(预测不上涨但实际上涨的次数)。 该公式的分母，是所有实际上涨（无论预测上涨与否）的次数。
这两个公式没有好坏优劣之分，而是通过不同的角度来对模型进行评价。

现在，我们再来看混淆矩阵就非常简单了：


上面的两个公式，实际上是有区分的，第一个公式计算得到的值叫精度（也叫查准率），反映的是预测能力。第二个公式计算得到的值叫召回率（也叫查全率），反映的是对正样本的拟合能力。
下面我们结合一个实际的场景来解释这个混淆矩阵（图片来自sklearn官档，略作修改，侵删）：



样本背景：在过去n个交易日中（即图中圆点个数），个股股价相较于前一交易日，涨的话是红色点，不涨是蓝色点。横纵坐标分别是个股的两个自定义的状态（比如上篇中的收盘价和成交量）。

现在我们有一个最简单粗暴的分类预测器——画线，而且是直线。

用第一个公式计算的话，Precision = 图中直线右上的所有红点个数 / 图中直线右上所有（红点 + 蓝点）的个数。显然图中红灰黑三条直线中，黑线的Precision最高，高达100%，但在所有红点中占比很小，反映在实际场景中，即遇到机会非常少，实用性下降。

再看第二个公式，Recall= 图中直线右上的所有红点个数 / 图中所有红点个数。显然图中红灰黑三条直线中，红线的Recall最大，接近100%，但同时也会有许多误判（红线右上的蓝点都被预测成了红点），反映在实际场景中，即遇到的机会增大，但误判的概率也变大了。

回到这个场景和图片本身，一个真正好的分类预测模型，应该是类似图中灰色直线的效果，在Precision和Recall之间取一个平衡，在两者间取加权平均值的话就是F1分值：

F1 = ( 2 * Precision * Recall ) / ( Precision + Recall )

图中红灰黑三条直线的F1分值，灰色线的F1最高，而红线由于Precision较低，黑线由于Recall较低，F1分值不会太高。

接下来，我们通过代码来实现计算F1分值并评估模型，在实践中，我们不仅记录F1分值，同时还记录Precision和Recall以及负样本的Precision，综合这几个指标可以粗略判断出模型的状态，过拟合或欠拟合，从而为优化指出方向。

代码的实现需要用到数据库操作，主要用到两张表，一张是结果表，用于记录模型的F1分值等。另一张是中间表，用于存储F1计算过程的一些变量，功能上与内存相似。

结果表——库名：stock       表名：model_ev_resu

字段名	字段类型	字段说明
state_dt	varchar2(45)	评估日期
stock_code	varchar2(45)	股票代码
acc	decimal(20, 4)	查准率
recall	decimal(20, 4)	查全率
f1	decimal(20, 4)	f1分值
acc_neg	decimal(20, 4)	查准率（负样本）
bz	varchar2(45)	用于标注模型类别，比如svm、决策树等
predict	varchar2(45)	对评估日后一个交易日的预测值
中间表——库名：stock       表名：model_ev_mid

字段名	字段类型	字段说明
state_dt	varchar2(45)	回测日期
stock_code	varchar2(45)	股票代码
resu_predict	decimal(20, 2)	预测值
resu_real	decimal(20, 2)	真实值
在数据库内建好两张表，就可以对模型进行评估了，本篇代码用的是推进式建模（即每天获得最新的股票数据后添加到训练集中，重新建模并对第二天进行预测），部分代码如下：

# 计算查全率
sql_resu_recall_son = "select count(*) from model_ev_mid a where a.resu_real is not null and a.resu_predict = 1 and a.resu_real = 1"
cursor.execute(sql_resu_recall_son)
recall_son = cursor.fetchall()[0][0]
sql_resu_recall_mon = "select count(*) from model_ev_mid a where a.resu_real is not null and a.resu_real = 1"
cursor.execute(sql_resu_recall_mon)
recall_mon = cursor.fetchall()[0][0]
recall = recall_son / recall_mon
# 计算查准率
sql_resu_acc_son = "select count(*) from model_ev_mid a where a.resu_real is not null and a.resu_predict = 1 and a.resu_real = 1"
cursor.execute(sql_resu_acc_son)
acc_son = cursor.fetchall()[0][0]
sql_resu_acc_mon = "select count(*) from model_ev_mid a where a.resu_real is not null and a.resu_predict = 1"
cursor.execute(sql_resu_acc_mon)
acc_mon = cursor.fetchall()[0][0]
if acc_mon == 0:
    acc = recall = acc_neg = f1 = 0
else:
    acc = acc_son / acc_mon
基本的实现思路是：

1. 建回测时间序列。
2. 进行第一次时间序列的遍历，推进式建模，向中间表存入相关过程变量（包含每次的预测值）。
3. 进行第二次时间序列的遍历，向中间表中更新每次迭代的真实值。
4. 对中间表进行统计，计算Precision，Recall，F1分值等，并存入结果表。
（完整的模型评估代码详见 Model_Evaluate.py 文件）

>> 仓位管理 <<
在投资领域，交易择时和风险控制是同等重要的两大模块。前述机器学习的模型解决了交易择时的问题，而马科维茨投资组合理论，则是在投资组合确定的条件下，通过仓位配比来实现风险控制的强大工具。

我们取下面5只股票作为一套投资组合

股票代码	名称	行业
603912	佳力图	通用设备/5G/次新股
300666	江丰电子	半导体/芯片/次新股
300618	寒锐钴业	有色金属/锂电池
002049	紫光国芯	半导体/5G/两融股
300672	国科微	半导体/芯片/次新股
现在我们计算一下2018年1月1日的风险系数和其对应的头寸比例，采样长度90天。

计算的过程非常简单，步骤如下：

1. 计算投资组合在采样区间内的每日收益率，组成一个 m*n 的矩阵A（其中m为交易日天数，n为投资组合股票或基金数，m必须大于n）。
2. 计算该矩阵A的协方差矩阵。
3. 求解该协方差矩阵的特征值和特征向量。
4. （可选） 计算夏普率。
在求解特征值和特征向量后，我们能得到若干（不大于n）个特征值和其对应的特征向量。这些特征值就是马科维茨理论中的投资组合的风险，其对应的特征向量做归一化处理后就是投资组合中各个股票或基金的头寸比例。

注意，特征向量中会有负值，一起归一化后是作为卖空账户的保证金头寸比例的，鉴于A股融券市场的高门槛和扭曲，不建议做空操作。号主是将特征向量中的负值剔除，将剩余的做归一化处理。

由于特征值和特征向量有多组，显然我们倾向于选风险小的，也即特征值最小的，这代表着市场的方向。本篇的这套portfolio运算后的风险和头寸如下：



市场的方向往往也是大盘的方向，投资组合的收益围绕大盘小范围波动。对于激进型投资者来说，需要一个风险稍稍提高但收益带来明显提升的方案。对于这种需求，则是取次最小的特征值和特征向量，剔除负值并归一化，如下图：



（完整的模型评估代码详见 Portfolio.py 文件）

可见，两套头寸配比差异较大，那么这两套方案的实际表现如何呢，请关注下期内容：



模拟交易与回测
作者：Tushare社区用户

当我们的经验和策略通过代码的方式实现时，除了一些机器学习的评估方法，还需要通过模拟交易的方式来回测整个策略。策略整体在市场中的表现效果如何，该如何用量化的手段来评估，则是本篇要向大家介绍的内容——模拟交易与回测。

话不多说马上进入正题，我们现在要做的，就是构建一套自己的模拟交易系统，并用这套系统来回测各种策略。为了让本文更接地气，作者不打算画各种程序流程图或拓扑图等，这样的 “PPT Style” 太不接地气了，我们换成以一个交易员的视角来思考问题。

>> 模拟交易 <<
股市的交易规则是实时的撮合交易，我们没办法也没必要做到实时的撮合交易，所以在模拟交易系统里，交易规则要简化为：以下单当日的收盘价作为成交价。实际上，各大量化平台也是这么做的，做得更细致一点的，可以设定一个参数：“滑点”——来控制模拟交易和实盘交易的误差。

有了这样一种简化，模拟交易就变得十分简单了——复杂的撮合交易机制简化成了以股票行情的收盘价作为成交价，剩下的只是简单的“买”和“卖”的交易动作。作为交易的基本动作，号主专门用一个程序来封装，代码如下：Operator.py

import pymysql.cursors
import Deal

def buy(stock_code, opdate, buy_money):...

def sell(stock_code, opdate, predict):...
可见只是封装了 buy 和 sell 两个函数而已。

在buy函数里我定义了几个参数，分别是股票代码、交易日期、交易金额；在sell函数里定义的几个参数分别是 股票代码、交易日期、交易量、交易类型（主动卖或止损卖）。这几个参数见名知意，这里就不多解释了。

现在我们有了模拟交易的两个基本操作函数，但交易是双向的，我们买和卖的结果体现在哪里呢，这就需要一个资产账户来记录。细心的读者肯定发现了，上面的截图里引入了两个包，一个是数据库框架pymysql，另一个则是Deal包，这其实是号主自定义的一个python程序，也就是模拟交易中的资产账户。先来看一下这个Deal文件到底是什么：

import pymysql.cursors

class Deal(object):
    cur_capital = 0.00
    cur_money_lock = 0.00
    cur_money_rest = 0.00
    stock_pool = []
    stock_map1 = {}
    stock_map2 = {}
    stock_map3 = {}
    stock_all = []
    ban_list = []

    ...
    
可见，Deal类封装了一些参数，初始化函数就是为了更新这些参数。实际上，这些参数分别是账户总资产，股票资产，现金资产，股票池，股票资产详情等，整个Deal类就是一份资产账户详单。

关于资产账户的数据架构，底层的实现是mysql数据库，分成两张sql表来实现，一张是账本表（记录每一次的买和卖操作），表结构如下：

库名：stock               表名：my_capital

字段名	字段类型	字段说明
capital	DECIMAL(20, 4)	总资产
money_lock	DECIMAL(20, 4)	股票资产
money_rest	DECIMAL(20, 4)	现金资产
deal_action	VARCHAR2(45)	交易动作
stock_code	VARCHAR2(45)	股票代码
deal_price	DECIMAL(20, 4)	成交价
stock_vol	INT(11)	成交量
profit	DECIMAL(20, 4)	收益额
profit_rate	DECIMAL(20, 4)	收益率
bz	VARCHAR2(45)	备注
state_dt	VARCHAR2(45	交易日期
seq	INT(11)	序号（用作表主键）
另一张则是持仓表，表结构如下：

库名：stock               表名：my_stock_pool

字段名	字段类型	字段说明
stock_code	VARCHAR2(45)	股票代码
buy_price	DECIMAL(20, 2)	买入价
hold_vol	INT(11)	持仓量（单位：股）
hold_days	INT(11)	持仓天数（只计算交易日）
对于交易来说，只需要持仓股票代码和持仓量即可，买入价是为了测算收益，持仓天数则是为了某些策略用的（比如策略对持仓天数有限制时）。

至此，一个最简单的模拟交易过程就完成了，从交易的角度来看，就是通过buy和sell函数对Deal类（资产账户）里的数据做写操作，比如，买入股票就是扣除现金资产，增加股票资产，同时在持仓表中增加相应记录；卖出股票则是反向操作。

>> 策略回测 <<
有了上述一套模拟交易过程，接下来我们要考虑的就是策略层面的问题了。从交易的角度来看，策略是整个交易过程的入口，是逻辑和决策层。笔者直接用main函数来写策略了：

if __name__ == '__main__':
    # 先清空之前的测试记录

    # 建回测时间序列

    # 开始模拟交易
    for i in range(1, len(date_seq)):
        # 选股初始化模块

        # 交易预警模块

        # 模型训练模块

        # 买卖点判断模块（包括但不限于模型的预测结果）

        # 仓位管理

        # 交易执行模块

    # 结果数据可视化模块
代码中简明清晰地展示了号主策略的回测框架：首先清空之前的测试记录，然后取回测时间段内的交易日序列，通过for循环来遍历这个序列，每一次迭代，都是一个交易日，都包含了策略的多个功能模块，上一篇的策略并非全部用到这些模块，未用到的下面以“可选”标记：

选股初始化模块（可选）：这个模块的功能主要是选股，由于涉及的逻辑和计算量可能非常庞大，并非每日执行，可以每隔x个交易日执行一次。

交易预警模块（可选）：当模型的预测存在结构性误差时，往往需要该预警模块来作为买卖点判断的补充，比如大趋势转变，基本面变化，政策变化等。

模型训练模块：在策略中，建模方式分单次建模和推进建模，区别是推进建模每日收盘后会根据最新交易日的数据进行重训练，对于推进建模，该模块是必须的（在上篇的策略中，就是应用的推进建模）。

买卖点判断：包含但不限于模型的预测结果，往往结合其他的逻辑或信号进行判断（比如预警模块给出的信号），最终确定是否买卖。

仓位管理：确定交易股票的配仓（买入金额或卖出股数）。

交易执行模块：即上文详述的模拟交易过程，Operator.py里的buy和sell函数。

结果数据可视化模块：当跑完回测后，给出一个直观的结果（折线图，柱图等）。

接下来，让我们看一下上一篇中的那套portfolio的回测结果。为了跟测试集的时间序列保持连续，现在取2018.03.01~2018.04.01区间的交易日序列作为回测区间。首先来看一下投资组合的市场方向（特征值最小）的收益情况：



图中蓝线代表大盘的收益曲线（收益 = 当日收盘价 / 首日收盘价），在这一个月的回测周期中，大盘指数由 3273 点震荡到 3168 点，投资组合的收益曲线跟大盘趋势基本保持一致，在期末的收益率为 0.39% ，略微跑赢大盘。

接下来再看这套投资组合的账单表：



总计 7 次卖出操作，其中 3 次止盈，3 次超时平仓，1 次止损。从收益情况来看，7 次操作中 5 次盈利，2 次亏损。

作为对比，我们再来看一下投资组合的最大收益方向（次最小特征值）：



可见，投资组合的收益曲线背离大盘。在期末的收益率达到 9.45%，明显跑赢市场。接下来再看这套投资组合的账单详情：



总计 9 次卖出操作，其中 4 次止盈，2 次超时平仓，2 次止损，1 次预测卖。从收益情况来看，7 次盈利，2 次亏损。

与市场方向相比，操作数变多，止盈和止损次数均多于前次。从操作和收益来看也印证了“高风险高收益”的道理。

至此，构建投资组合==>回测验证策略 的流程已经结束。详细代码清单与功能如下（点击这里下载全部代码）：

文件名	功能
DC.py	【数据预处理】将本地存储的日基础行情整合成一份训练集。
Model_Evaluate.py	【模型评估】通过回测+推进式建模的方式对模型进行评估，主要计算查准率Precision，查全率Recall，F1分值，并存入结果表。
Portfolio.py	【仓位管理】基于马科维茨投资组合理论，计算一段时间序列内投资组合的风险、仓位配比和夏普率，有市场方向和最佳收益方向两种结果。
Deal.py.py	【模拟交易】封装类，用于模拟交易过程中获取最新的资产账户相关数据。
Operator.py	【模拟交易】封装函数，用于模拟交易过程中执行买和卖操作。
Cap_Update_daily.py	【模拟交易】封装函数，用于在回测过程中，每日更新资产表中相关数据。
Filter.py	【策略回测】封装函数，用于在回测过程中，处理一些简单的逻辑（更新持仓天数，买卖顺序等）。
main.py	【策略回测】策略的框架，回测的主函数。


python过滤HTML标签
作者：Tushare社区用户 晓子

>> 问题描述 <<
很多时候我们在爬取的网页内容或者提供的资讯数据中包含大量的HTML标签。有些时候，保留这些HTML标签是有用的，例如展现和查看，更多的是为了保留足够多的信息（标签中有但text中没有的信息，如img等）以便后续使用。但有时我们仅仅想要其中的text，这个时候我们需要除去文本中的标签。以下，笔者就介绍两种除去HTML标签的方法。一种使用BeautifulSoup，另外一种使用正则表达式（这种方法的代码，笔者抄录自网上，由于来源也没有备注作者，所以这里笔者也没有标明作者，如果作者看到这里，请联系晓子xiaoziwenji@126.com以正之）。

测试数据来源于tushare pro数字货币交易所Twitter：代码请见：

content = pro.exchange_twitter(start_date='2018-08-06 04:16:27', end_date='2018-08-06 04:16:27', fields="content")['content'][0]
得到的结果为带有标签的内容：

'<span style="color: grey">@joliwa</span> <span style="color: grey">@TurboStakeCoin</span> <span style="color: grey">@Shirt_Fun_Wear</span> Hi there,\nPlease create a support ticket at  <a href="https://t.co/EosnMa5kOP">https://t.co/EosnMa5kOP</a> and our Support Team will be in touch with you soon.'
>> BeautifulSoup <<
使用BeautifulSoup的代码如下：

from bs4 import BeautifulSoup

bsObj = BeautifulSoup(content, 'lxml')
bsObj.get_text()
结果为：

'@joliwa @TurboStakeCoin @Shirt_Fun_Wear Hi there,\nPlease create a support ticket at  https://t.co/EosnMa5kOP and our Support Team will be in touch with you soon.'
>> 正则表达式 <<
同样，笔者也提供了使用正则表达式来过滤标签的代码，方法定义如下：

import re


def filter_tags(htmlstr):
    # 先过滤CDATA
    re_cdata = re.compile('//<!\[CDATA\[[^>]*//\]\]>', re.I)  # 匹配CDATA
    re_script = re.compile('<\s*script[^>]*>[^<]*<\s*/\s*script\s*>', re.I)  # Script
    re_style = re.compile('<\s*style[^>]*>[^<]*<\s*/\s*style\s*>', re.I)  # style
    re_br = re.compile('<br\s*?/?>')  # 处理换行
    re_h = re.compile('</?\w+[^>]*>')  # HTML标签
    re_comment = re.compile('<!--[^>]*-->')  # HTML注释
    s = re_cdata.sub('', htmlstr)  # 去掉CDATA
    s = re_script.sub('', s)  # 去掉SCRIPT
    s = re_style.sub('', s)  # 去掉style
    s = re_br.sub('\n', s)  # 将br转换为换行
    s = re_h.sub('', s)  # 去掉HTML 标签
    s = re_comment.sub('', s)  # 去掉HTML注释
    # 去掉多余的空行
    blank_line = re.compile('\n+')
    s = blank_line.sub('\n', s)
    s = replaceCharEntity(s)  # 替换实体
    return s


def replaceCharEntity(htmlstr):
    CHAR_ENTITIES = {'nbsp': ' ', '160': ' ',
                     'lt': '<', '60': '<',
                     'gt': '>', '62': '>',
                     'amp': '&', '38': '&',
                     'quot': '"', '34': '"', }

    re_charEntity = re.compile(r'&#?(?P<name>\w+);')
    sz = re_charEntity.search(htmlstr)
    while sz:
        entity = sz.group()  # entity全称，如>
        key = sz.group('name')  # 去除&;后entity,如>为gt
        try:
            htmlstr = re_charEntity.sub(CHAR_ENTITIES[key], htmlstr, 1)
            sz = re_charEntity.search(htmlstr)
        except KeyError:
            # 以空串代替
            htmlstr = re_charEntity.sub('', htmlstr, 1)
            sz = re_charEntity.search(htmlstr)
    return htmlstr
使用的代码：

filter_tags(content)
结果为：

'@joliwa @TurboStakeCoin @Shirt_Fun_Wear Hi there,\nPlease create a support ticket at  https://t.co/EosnMa5kOP and our Support Team will be in touch with you soon.'
>> 结论 <<
可见两种方法得到的结果是一样的，但使用BeautifulSoup要简单和强大得多。


如何优雅高效的撸数据？
获取Tushare Pro 的数据API，首先需要注册一个pro账号，然后登录pro网站在个人主页里拿到token码。另外，别忘了修改一下个人信息，这样可以多20积分。对于股票行情数据，只要有120积分就可以相对高频的撸数据了，这120积分随手可得（注册成功有100积分、然后修改个人信息有20积分）。

Tushare的行情等时间序列数据，一般都有两个常用参数：trade_date和ts_code，分别是交易日期和证券代码。如果你是想提取部分个股的历史数据，用ts_code参数，加上开始和结束日期可以方便提取数据。

但！如果是要获取所有历史数据，我们不建议通过ts_code来循环，而是用trade_date来提取，道理很简单，股票有5000多个，需要循环5000多次，每年的交易日也就才220左右，所以效率更高。总的来说，积分越高可以调取的频次会越高。

也就是以下方式：

import tushare as ts

pro = ts.pro_api()

df = pro.daily(trade_date='20200325')
在循环提取数据时，首先我们可以通过交易日历拿到一段历史的交易日。

#获取20200101～20200401之间所有有交易的日期
df = pro.trade_cal(exchange='SSE', is_open='1', 
                            start_date='20200101', 
                            end_date='20200401', 
                            fields='cal_date')
    
 print(df.head())
 
交易日：

   cal_date
0  20200102
1  20200103
2  20200106
3  20200107
4  20200108
循环过程中，为了保持数据提取的稳定性，可以先建立一个专门的函数，实现一个重试机制：

def get_daily(self, ts_code='', trade_date='', start_date='', end_date=''):
    for _ in range(3):
      try:
            if trade_date:
                df = self.pro.daily(ts_code=ts_code, trade_date=trade_date)
            else:
                df = self.pro.daily(ts_code=ts_code, start_date=start_date, end_date=end_date)
         except:
                time.sleep(1)
        else:
                return df
然后通过在循环中调取数据：

for date in df['cal_date'].values:
     df = get_daily(date)


数据如何落地存入到MySQL数据库？
如果数据需要长期使用，尤其是历史数据，我们建议，可以将提取到的数据存入本地数据库，例如MySQL。

有如下几个步骤：

安装依赖包
sqlalchemy、mysqlclient
安装MySQL
对于MySQL版本，没有特别的要求，mysql 5+、mysql 8+ 都可以，如果是最新版mysql，需要将sqlalchemy升级到最新版。具体的安装过程，这里不做介绍，大家可自行baidu，有很多参考材料。
编写入库代码
由于用了sqlalchemy，这个过程非常简单。用户无需首先在数据库中建表就可以执行数据入库，但这种默认方式所创建的数据表并不是最优的数据结构，可以参考第4条进行优化。

res = df.to_sql('stock_basic', engine_ts, index=False, if_exists='append', chunksize=5000)

数据结构优化
对于默认创建的表，会有一些不太符合实际应用，比如数据结构类型比较单一，没有主键和索引等约束，没有comments等等。我们可以在数据库客户端对所建立的表进行修改，使其符合实际的最优设计。比如将一般的str类型转成varchar2数据类型，而不是text数据类型。

实现本地调度程序
完成数据调取接口和入库程序之后，我们可以开发一个调取程序，可以让系统的调度系统来定时从tushare拉取数据。比如windows我们可以用计划任务，Linux可以使用crontab。


数据如何落地存入到MongoDB数据库？
除了将数据存入关系型数据库（比如MySQL）外，也可以将数据存入MongoDB，以下是具体过程。

有如下几个步骤：

安装依赖包
pymongo
安装MongoDB（Linux）

 1、下载安装包

 curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.2.12.tgz

 2、解压

 tar -zxvf mongodb-linux-x86_64-3.2.12.tgz

 3、移动到指定位置

 mv  mongodb-linux-x86_64-3.2.12/ /usr/local/mongodb

 4、在/usr/local/mongodb下创建文件夹

 mkdir -p /data/db

 mkdir  /logs

 5、在/usr/local/mongodb/bin下新建配置

 vi mongodb.conf

 dbpath = /data/db
 logpath = /data/logs/mongodb.log
 port = 27017
 fork = true
 nohttpinterface = true
 auth=true

 bind_ip=0.0.0.0

 6、环境变量配置

 vi /etc/profile 

 export MONGODB_HOME=/usr/local/mongodb
 export PATH=$PATH:$MONGODB_HOME/bin

 保存后，重启系统配置

 source /etc/profile

 保存后，重启系统配置

 source /etc/profile
 7、启动

 在/usr/local/mongodb/bin下

 mongod -f mongodb.conf 或 ./mongod -f mongodb.conf

 8、关闭

 mongod -f ./mongodb.conf --shutdown  或./mongod -f ./mongodb.conf --shutdown
编写入库代码
首先需要定义mongo的连接，这里给一个样例，大家可以自行修改。

 import pandas as pd
 import tushare as ts
 from pymongo import MongoClient

 client = MongoClient(host='localhost',
                                          port=27017,
                                             username='root',
                                             password='mima123',
                                             authSource='admin',
                                             authMechanism='SCRAM-SHA-1')

 #存入数据
 def insert_mongo(df):
     db = client['demos']
     collection = db['stock_basic']
     #print(df)
     collection.insert_many(df.to_dict('records'))


如何获取分钟数据？
Tushare Pro提供了包括股票、指数、基金、期货、港股在内的各类资产交易行情的分钟数据。但由于数据量庞大，服务器和带宽成本压力很大，目前股票、期货、期权分钟是分别单独开权限的，跟平台积分没有关系，可以参考权限列表说明。

在使用方面，具体参数说明，可以参考通用行情接口获取更加详细的信息。

需要注意的几点：

分钟数据需要单独开权限才可以正常使用，否则只有试用权限，开权限请在QQ群里联系群主或加微信：waditu_a
由于服务器资源有限，目前只能一个个标的按时间段获取分钟，单次提取最多8000行数据
数据只供策略研究和学习使用，不允许作为商业目的
目前分钟频度包括1分、5、15、30、60分数据
数据每天收盘后处理更新，时间在17~21点之间完成
分钟数据时间参数请使用带时分秒的格式，比如：2019-06-04 19:00:00
如是end_date输入的是不带时分秒的日期，返回的数据不包括end_date当日，即数据返回的是 < end_date的数据
如果你已经拥有了分钟数据权限，可以通过以下推荐的方式来获取数据：

import tushare as ts

#获取股票1分钟数据
df = ts.pro_bar(ts_code='600000.SH',
                    freq='1min', 
                    start_date='2020-01-07 09:00:00', 
                    end_date='2020-01-08 17:00:00')

print(df)

       ts_code           trade_time   open  close   high    low     vol  \
0    600000.SH  2020-01-08 09:31:00  12.41  12.44  12.45  12.41  880140   
1    600000.SH  2020-01-08 10:14:00  12.37  12.37  12.38  12.37   61300   
2    600000.SH  2020-01-08 10:19:00  12.36  12.36  12.37  12.36  288400   
3    600000.SH  2020-01-08 10:29:00  12.34  12.33  12.35  12.33  119100   
4    600000.SH  2020-01-08 10:33:00  12.33  12.33  12.34  12.33  218700   
5    600000.SH  2020-01-08 10:59:00  12.38  12.37  12.38  12.36   76600   
6    600000.SH  2020-01-08 11:09:00  12.37  12.36  12.37  12.36   44777   
7    600000.SH  2020-01-08 11:15:00  12.37  12.37  12.38  12.37   67500   
8    600000.SH  2020-01-08 13:08:00  12.36  12.37  12.37  12.36   72300   
9    600000.SH  2020-01-08 13:10:00  12.36  12.37  12.37  12.36   43300   
10   600000.SH  2020-01-08 13:15:00  12.35  12.36  12.36  12.35   46900   
11   600000.SH  2020-01-08 13:27:00  12.33  12.34  12.34  12.33   29300   
12   600000.SH  2020-01-08 13:31:00  12.33  12.35  12.35  12.33  102301   
13   600000.SH  2020-01-08 14:05:00  12.30  12.29  12.30  12.29   88000   
14   600000.SH  2020-01-08 14:09:00  12.30  12.30  12.30  12.29   26400   
15   600000.SH  2020-01-08 14:15:00  12.28  12.28  12.29  12.28   80926   
16   600000.SH  2020-01-08 14:45:00  12.30  12.31  12.32  12.29  226800  

#获取指数分钟数据
df = ts.pro_bar(ts_code='000001.SH',
                    asset='I',
                    freq='1min', 
                    start_date='2020-01-07 09:00:00', 
                    end_date='2020-01-08 17:00:00')    

print(df)

       ts_code           trade_time      open     close      high       low  \
0    000001.SH  2020-01-08 09:30:00  3094.239  3094.239  3094.239  3094.239   
1    000001.SH  2020-01-08 09:34:00  3089.337  3091.416  3091.416  3089.311   
2    000001.SH  2020-01-08 09:36:00  3092.239  3089.240  3092.239  3089.240   
3    000001.SH  2020-01-08 09:37:00  3089.347  3089.743  3089.940  3089.347   
4    000001.SH  2020-01-08 09:38:00  3089.405  3085.691  3089.862  3085.374   
5    000001.SH  2020-01-08 09:40:00  3084.808  3088.857  3088.857  3084.808   
6    000001.SH  2020-01-08 09:48:00  3090.286  3088.414  3090.350  3088.414   
7    000001.SH  2020-01-08 09:52:00  3086.431  3085.874  3086.502  3085.469   
8    000001.SH  2020-01-08 09:56:00  3087.642  3087.394  3088.178  3087.394   
9    000001.SH  2020-01-08 09:59:00  3087.177  3086.959  3087.568  3086.754   
10   000001.SH  2020-01-08 10:06:00  3090.386  3090.284  3090.741  3089.893   
11   000001.SH  2020-01-08 10:14:00  3085.475  3084.236  3085.475  3084.236   
12   000001.SH  2020-01-08 10:18:00  3081.099  3081.567  3081.581  3080.709   
13   000001.SH  2020-01-08 10:39:00  3082.920  3083.558  3083.558  3082.769   
14   000001.SH  2020-01-08 10:46:00  3084.164  3084.402  3084.802  3083.929   
15   000001.SH  2020-01-08 10:50:00  3084.594  3084.198  3084.594  3083.419  


#获取基金1分钟数据
df = ts.pro_bar(ts_code='150018.SZ',
                    asset='FD',
                    freq='1min', 
                    start_date='2020-01-07 09:00:00', 
                    end_date='2020-01-08 17:00:00')    



#获取期货1分钟数据
df = ts.pro_bar(ts_code='CU2012.SHF',
                    asset='FT',
                    freq='1min', 
                    start_date='2020-01-07 09:00:00', 
                    end_date='2020-01-08 17:00:00')    
                    
print(df)

        ts_code           trade_time     open    close     high      low  vol  \
0    CU2012.SHF  2020-01-08 00:00:00  49300.0  49300.0  49300.0  49300.0    2   
1    CU2012.SHF  2020-01-08 00:08:00  49300.0  49300.0  49300.0  49300.0    0   
2    CU2012.SHF  2020-01-08 00:14:00  49300.0  49300.0  49300.0  49300.0    0   
3    CU2012.SHF  2020-01-08 00:18:00  49300.0  49300.0  49300.0  49300.0    0   
4    CU2012.SHF  2020-01-08 00:29:00  49300.0  49300.0  49300.0  49300.0    0   
5    CU2012.SHF  2020-01-08 00:36:00  49300.0  49300.0  49300.0  49300.0    0   
6    CU2012.SHF  2020-01-08 00:40:00  49300.0  49300.0  49300.0  49300.0    0   
7    CU2012.SHF  2020-01-08 00:45:00  49300.0  49300.0  49300.0  49300.0    0   
8    CU2012.SHF  2020-01-08 00:51:00  49300.0  49300.0  49300.0  49300.0    0   
9    CU2012.SHF  2020-01-08 01:00:00  49300.0  49300.0  49300.0  49300.0    0   
10   CU2012.SHF  2020-01-08 09:11:00  49300.0  49300.0  49300.0  49300.0    0   
11   CU2012.SHF  2020-01-08 09:20:00  49300.0  49300.0  49300.0  49300.0    0   
12   CU2012.SHF  2020-01-08 09:22:00  49300.0  49300.0  49300.0  49300.0    0   
13   CU2012.SHF  2020-01-08 09:23:00  49300.0  49310.0  49310.0  49300.0    8   
14   CU2012.SHF  2020-01-08 09:36:00  49310.0  49310.0  49310.0  49310.0    0   
15   CU2012.SHF  2020-01-08 09:38:00  49310.0  49310.0  49310.0  49310.0    0   


#获取数字货币分钟数据
df = pro.coin_mins(symbol='btcusdt',
                    exchange='huobi',
                    freq='1min', 
                    trade_date='20200107')

print(df)

       symbol                 date     open     high      low    close  \
0     btcusdt  2020-01-07 00:00:00  7519.82  7529.11  7514.65  7528.39   
1     btcusdt  2020-01-07 00:01:00  7527.31  7530.78  7526.02  7527.81   
2     btcusdt  2020-01-07 00:02:00  7527.40  7528.94  7525.00  7525.58   
3     btcusdt  2020-01-07 00:03:00  7525.11  7529.00  7524.12  7526.00   
4     btcusdt  2020-01-07 00:04:00  7526.01  7526.49  7520.63  7521.90   
5     btcusdt  2020-01-07 00:05:00  7522.47  7522.60  7517.34  7517.39   
6     btcusdt  2020-01-07 00:06:00  7517.39  7519.13  7515.17  7516.09   
7     btcusdt  2020-01-07 00:07:00  7516.90  7516.90  7511.00  7512.83   
8     btcusdt  2020-01-07 00:08:00  7511.46  7513.72  7510.00  7512.71   
9     btcusdt  2020-01-07 00:09:00  7512.73  7515.43  7510.61  7511.86   
10    btcusdt  2020-01-07 00:10:00  7512.09  7521.82  7511.41  7521.82   
11    btcusdt  2020-01-07 00:11:00  7521.81  7532.72  7521.65  7532.08   
12    btcusdt  2020-01-07 00:12:00  7532.08  7532.08  7527.00  7529.15   
13    btcusdt  2020-01-07 00:13:00  7529.79  7539.86  7529.79  7537.73   
14    btcusdt  2020-01-07 00:14:00  7537.72  7538.91  7535.38  7535.38   
15    btcusdt  2020-01-07 00:15:00  7535.00  7545.66  7534.40  7544.30   
16    btcusdt  2020-01-07 00:16:00  7544.23  7546.75  7540.00  7540.74 



常见问题

1、Tushare是一个什么样的平台或者组织?

Tushare是一个不以盈利为目的的开源开放以及免费的金融大数据社区，目前已经服务了超过30万用户，大概600家机构。Tushare自主研发了一套从数据采集/处理/加工到服务的完整系统和流程，可以为用户提供稳定的，高质量的数据服务。
     

2、Tushare是否收费?积分是永久的吗？

Tushare从发布到现在已经超过8年，一直坚持免费的服务模式，例如股票的日线行情数据，只需120积分（注册并填写个人信息），每分钟可以请求500次，每次可以提取一个股票23年历史数据。由于开发和运维数据投入巨大，社区需要大家的支持才能建设好，希望用户能通过官网捐助的方式支持社区发展，我们全力保证数据的质量和高效服务。未来，我们依然坚持非商业化服务的模式，从Pro版本开始，引入了社区积分制度，除行情等基础数据外，需要一定积分才可以调取。具体的积分获取办法，请参考前面章节的平台积分介绍。而积分也不是永久有效，为了保证社区的持续发展，目前积分是1年有效，在1年内积分不消耗不扣减，只要满足积分要求，数据可正常获取。

3、未来有什么发展计划?
专注数据，聚焦数据，一如既往的认真做好数据的事，让数据产生价值。

4、Tushare支持哪些获取方式?

目前支持通过Python SDK的方式方便获取数据，可以与Python开发的模型无缝对接，R语言和Matlab的SDK也已经发布。同时，Tushare也支持Http协议获取数据，具体请参考文档“操作手册”下的“调取数据”。

5、大学老师和学生是否可以获得更多数据权限和支持?

Tushare社区的目标除了提供数据之外，还有一项重要的使命就是为金融初入者提供更多方便，为从事金融教育的老师们提供更多数据内容和业务支持，因为我们也一直关注教育这一环节，我们愿意为大学老师和同学提供更多的数据权限，更多的数据服务，也可以为同学现场讲解金融数据业务和技术相关知识。请注册成功的老师和同学登录Tushare网站后在个人主页里完善个人资料，并通过QQ群(304084105)联系群主或管理员获取。（请**高校老师**在获得数据支持的同时，把tushare作为课程教学案例，开课的教师可以统一为学生申请权限；**高校学生**获得数据的同时，请积极成为tushare社区贡献者，为社区发展添砖加瓦）

6、机构投资用户如何获得更多数据支持和服务?
Tushare已经与不少私募等中小投资机构建立起了联系，我们很看重投资机构的专业能力，在服务互动过程中也能为Tushare带来更多的反馈和支持，所以我们愿意继续为更多中小机构提供一对一的专业数据服务，请在注册成功后登录后台，填写机构和个人信息，我们将为您提供更多数据内容和专业数据平台解决方案。

7、Tushare股票行情的前复权机制是什么？
在Tushare数据接口里，不管是旧版的一些接口还是Pro版的行情接口，都是以用户设定的end_date开始往前复权，跟所有行情软件或者财经网站上看到的前复权可能存在差异，因为行情软件都是以最近一个交易日开始往前复权的。比如今天是2018年10月26日，您想查2018年1月5日～2018年9月28日的前复权数据，Tushare是先查找9月28日的复权因子，从28日开始复权，而行情软件是从10月26日这天开始复权的。同时，Tushare的复权采用“分红再投”模式计算。

8、为什么我在调取API的时候，有时候会出现timeout异常？
由于Tushare Pro API加了频次限制，积分低的用户有时候会碰到超过最大限制调取或者timeout的情况，解决的办法有：1）尽可能多的积攒Pro积分，达到5000积分以上基本没有太多频次限制 2) 在程序的循环里增加重试机制。3)请确认关闭电脑的网络代理功能，类似翻墙软件等vpn。

9、Tushare的org(旧版)和Pro(新版)有什么区别?

Tushare早期是一个数据集成和转发工具，属于开放源代码的数据工具，但数据质量受制于第三方网站。而Tushare Pro完全是由Tushare自己的服务器提供数据，从数据规划，采集，加工处理，以及数据服务都是有统一平台来管理，而且从Pro开始建立起了Tushare自己的数据标准，同时有一个更加强大的数据社区在维持数据的正常运行。可以说，不管是从数据广度还是深度来说，Pro版都有了一个质的飞跃，相信在社区用户的共同努力下，未来一定更加完善。所以，Tushare Pro已经转变为一个数据开放平台，而不是一个开源软件，我们关注的是数据内容，而不是技术。我们强烈建议，所有用户尽快切换到Pro版API，旧版API将在未来停止维护直到关闭。

10、为什么有时候发现财务数据接口有重复数据？
如果发现有重复数据，绝大多数可能都是本季（年）度的财务数据有过修正，可以通过update_flag来确定，update_flag=1为修正后的数据，update_flag=0为初始数据。如果提取不到update_flag字段，请再fields参数指定，比如fields='ts_code,period,update_flag' ，字段用逗号分隔即可。

11、什么情况下Tushare积分会减少？
目前有两种情况下积分会减少，一是自己（手工或通过程序）注册的无效账号获得积分，会不定期清理；二是通过活动赠送的积分，一年后到期清理。除此以外不会减少积分，现阶段调取数据暂时不消耗积分。

12、我在公开发布的网站或者论文里用到了Tushare的数据，是否需要标注来源？
需要。凡是用到了Tushare数据，免费获得，也需要在网站上或者产品里标注，数据来源：Tushare数据

13、Tushare的日期参数格式是固定的吗？

在Tushare API接口里，只要是年月日的日期参数，输入格式统一为YYYYMMDD，比如：20220401，高频数据接口里带时分秒的参数格式是：2022-04-01 09:00:00




通过HTTP调取数据


长久以来，Tushare一直以固定的Python SDK方式为大家提供数据服务。

虽然在基于Python的数据分析和Python的量化策略开发很方便，但习惯用其他语言的同学们表示了“抗议”，于是在Tushare的Github开发组里，衍生出了各种语言版本的Tushare，比如Ruby Tushare，nodejs Tushare...

尽管多出了不少版本，但数据还是不能统一管理，Tushare的数据标准没有建立起来。

于是，我们在最近发布的Tushare Pro版里，增加对HTTP RESTful API的支持，用户可以通过标准协议，获得想要的数据，而且与编程语言无关。

HTTP API说明
在tushare.pro网站上，我们在平台介绍的“调取数据”部分，已经对http协议的数据获取做了说明，这里再次详细的向大家介绍一下，尽量让大家多一点的了解如何通过http的方式获取Tushare数据。

Tushare HTTP数据获取的方式，我们采用了post的机制，通过提交JSON body参数，就可以获得您想要的数据。具体参数说明如下：

输入参数
api_name：接口名称，比如stock_basic

token ：用户唯一标识，可通过登录pro网站获取

params：接口参数，如daily接口中start_date和end_date

fields：字段列表，用于接口获取指定的字段，以逗号分隔，如"open,high,low,close"
token的获取，请参与之前公众号文章《开启Pro体验的正确打开方式》，如需注册用户，可直接点击“阅读原文”完成。

输出参数
code： 接口返回码，2002表示权限问题。

msg：错误信息，比如“系统内部错误”，“没有权限”等

data：数据，data里包含fields和items字段，分别为字段和数据内容
以下，我们从几个方面来介绍具体的使用过程。

API工具快速检测
如果想简单快速获得数据API的效果，检测一下可用性，又不想写代码的话，postman这个工具或许可以派上用场。

运行postman，选择POST方式，在API地址栏里输入：http://api.tushare.pro ，然后在下面点击body，输入json格式的参数。


之后，点击“Send”按钮，我们可以在结果栏目里看到调取API的最终效果。


代码快速检测
有的程序员可能更喜欢用代码的方式来检查API的效果，更加直接，简单，高效。我们可以借助cURL工具来实现通过命令行方式来检测。

curl -X POST -d '{"api_name": "stock_basic", "token": "xxxxxxxx", "params": {"list_stauts":"L"}, "fields": "ts_code,name,area,industry,list_date"}' http://api.tushare.pro
（按住屏幕滑动可浏览全部代码）

在控制台执行后，我们就可以看到如下数据效果。


{
    "code": 0,
    "msg": null,
    "data": {
        "fields": [
            "ts_code",
            "name",
            "area",
            "industry",
            "list_date"
        ],
        "items": [
            [
                "000001.SZ",
                "平安银行",
                "深圳",
                "银行",
                "19910403"
            ],
            [
                "000002.SZ",
                "万科A",
                "深圳",
                "全国地产",
                "19910129"
            ],
            [
                "000004.SZ",
                "国农科技",
                "深圳",
                "生物制药",
                "19910114"
            ],
            [
                "000005.SZ",
                "世纪星源",
                "深圳",
                "房产服务",
                "19901210"
            ],
            [
                "000006.SZ",
                "深振业A",
                "深圳",
                "区域地产",
                "19920427"
            ],
            [
                "000007.SZ",
                "全新好",
                "深圳",
                "酒店餐饮",
                "19920413"
            ],
            [
                "000008.SZ",
                "神州高铁",
                "北京",
                "运输设备",
                "19920507"
            ]
            ...
      }
}
Python调取示例
前面已经提到,http restful API的好处就是跟编程语言无关，基本上所有编程语言都可以调取。

由于编程环境太多，这里只拿Python作为示例，其他语言的实现，请各位用户自行查找网络资源完成，相信绝大多数会编程的用户都能轻松搞定。

其实Tushare Pro新版的SDK，正是利用http方式来获取数据的，虽然我们也提供了tcp的方式，但是http目前运行良好，稳定性已经得到了验证。

以下就是相关的核心代码，有兴趣的朋友可以访问Tushare 的Github下载完整代码。


def req_http_api(self, req_params):
    req = Request(
        self.__http_url,
        json.dumps(req_params).encode('utf-8'),
        method='POST'
    )

    res = urlopen(req)
    result = json.loads(res.read().decode('utf-8'))

    if result['code'] != 0:
        raise Exception(result['msg'])

    return result['data']


def query(self, api_name, fields='', **kwargs):
    req_params = {
        'api_name': api_name,
        'token': self.__token,
        'params': kwargs,
        'fields': fields
    }

    if self.__protocol == 'tcp':
        data = self.req_zmq_api(req_params)
    elif self.__protocol == 'http':
        data = self.req_http_api(req_params)
    else:
        raise Warning('{} is unsupported protocol'.format(self.__protocol))

    columns = data['fields']
    items = data['items']

    return pd.DataFrame(items, columns=columns)



通过Python SDK 调取数据
导入tushare

import tushare as ts
这里注意， tushare版本需大于1.2.10

设置token

ts.set_token('your token here')
以上方法只需要在第一次或者token失效后调用，完成调取tushare数据凭证的设置，正常情况下不需要重复设置。也可以忽略此步骤，直接用pro_api('your token')完成初始化

初始化pro接口

pro = ts.pro_api()
如果上一步骤ts.set_token('your token')无效或不想保存token到本地，也可以在初始化接口里直接设置token:

pro = ts.pro_api('your token')
数据调取

以获取交易日历信息为例：

df = pro.trade_cal(exchange='', start_date='20180901', end_date='20181001', fields='exchange,cal_date,is_open,pretrade_date', is_open='0')
或者

df = pro.query('trade_cal', exchange='', start_date='20180901', end_date='20181001', fields='exchange,cal_date,is_open,pretrade_date', is_open='0')
调取结果：

    exchange  cal_date    is_open pretrade_date
0          SSE       20180901        0      20180831
1          SSE       20180902        0      20180831
2          SSE       20180908        0      20180907
3          SSE       20180909        0      20180907
4          SSE       20180915        0      20180914
5          SSE       20180916        0      20180914
6          SSE       20180922        0      20180921
7          SSE       20180923        0      20180921
8          SSE       20180924        0      20180921
9          SSE       20180929        0      20180928
10         SSE       20180930        0      20180928
11         SSE       20181001        0      20180928




调取pro版数据
下面介绍两种常用的数据调取方式：

通过tushare python包
使用http协议直接获取
注：pro版数据接口采用语言无关的http协议实现，但也提供了多种语言的SDK数据获取。

前提条件
1、已经注册了tushare社区用户 【注册用户】
2、已经获取到tushare token凭证 【获取token】

Python SDK
下载SDK
下载并安装最新版tushare SDK 【安装和升级方法】

导入tushare

import tushare as ts
这里注意， tushare版本需大于1.2.10

设置token

ts.set_token('your token here')
以上方法只需要在第一次或者token失效后调用，完成调取tushare数据凭证的设置，正常情况下不需要重复设置。也可以忽略此步骤，直接用pro_api('your token')完成初始化

初始化pro接口

pro = ts.pro_api()
如果上一步骤ts.set_token('your token')无效或不想保存token到本地，也可以在初始化接口里直接设置token:

pro = ts.pro_api('your token')
数据调取

以获取交易日历信息为例：

df = pro.trade_cal(exchange='', start_date='20180901', end_date='20181001', fields='exchange,cal_date,is_open,pretrade_date', is_open='0')
或者

df = pro.query('trade_cal', exchange='', start_date='20180901', end_date='20181001', fields='exchange,cal_date,is_open,pretrade_date', is_open='0')
调取结果：

    exchange  cal_date    is_open pretrade_date
0          SSE       20180901        0      20180831
1          SSE       20180902        0      20180831
2          SSE       20180908        0      20180907
3          SSE       20180909        0      20180907
4          SSE       20180915        0      20180914
5          SSE       20180916        0      20180914
6          SSE       20180922        0      20180921
7          SSE       20180923        0      20180921
8          SSE       20180924        0      20180921
9          SSE       20180929        0      20180928
10         SSE       20180930        0      20180928
11         SSE       20181001        0      20180928
HTTP协议方式
http restful 采用post方式，通过json body传入接口参数，请求地址为http://api.tushare.pro

输入参数
api_name，接口名称；
token，用于识别唯一用户的标识；
params，接口参数，如daily接口中start_date和end_date；
fields，字段列表，用于接口获取指定的字段，以逗号分隔，如"open,high,low,close"；
输出参数
code: 接口返回码，2002表示权限问题。
msg: 错误信息；
data: 具体数据，成功的请求包含fields和items字段，fields与items数据一一对齐；
示例
采用命令行工具curl的请求示例如下：

curl -X POST -d '{"api_name": "trade_cal", "token": "xxxxxxxx", "params": {"exchange":"", "start_date":"20180901", "end_date":"20181001", "is_open":"0"}, "fields": "exchange,cal_date,is_open,pretrade_date"}' http://api.tushare.pro
返回结果：

{
        "code":0,
        "msg":null,
        "data":{
                "fields":[
                        "exchange",
                        "cal_date",
                        "is_open",
                        "pretrade_date"
                ],
                "items":[
                        [
                                "SSE",
                                "20180901",
                                0,
                                "20180831"
                        ],
                        [
                                "SSE",
                                "20180902",
                                0,
                                "20180831"
                        ],
                        [
                                "SSE",
                                "20180908",
                                0,
                                "20180907"
                        ],

            ...

                        [
                                "SSE",
                                "20180929",
                                0,
                                "20180928"
                        ],
                        [
                                "SSE",
                                "20180930",
                                0,
                                "20180928"
                        ],
                        [
                                "SSE",
                                "20181001",
                                0,
                                "20180928"
                        ]
                ]
        }
}






