# çœŸå®APIå®ç°æŒ‡å—

> åˆ›å»ºæ—¶é—´: 2025-12-04 05:45  
> å‚è€ƒèµ„æ–™: GitHubé¡¹ç›®å’ŒJSåŠ å¯†ä»£ç 

---

## ğŸ¯ ç›®æ ‡

å®ç°ä»¥ä¸‹çœŸå®APIè°ƒç”¨ï¼š
1. **ä¸­å›½è£åˆ¤æ–‡ä¹¦ç½‘** - æ³•å¾‹æ¡ˆä»¶æ•°æ®
2. **å·¨æ½®èµ„è®¯ç½‘** - å…¬å¸å…¬å‘Šæ•°æ®  
3. **è´¢è”ç¤¾** - è´¢ç»å¿«è®¯æ•°æ®

---

## 1ï¸âƒ£ ä¸­å›½è£åˆ¤æ–‡ä¹¦ç½‘

### å‚è€ƒèµ„æ–™
- GitHub: https://github.com/nixinxin/WenShu
- GitHub: https://github.com/sixs/wenshu_spider
- åŠ å¯†ä»£ç : `docs/ä¸­å›½è£åˆ¤æ–‡ä¹¦ç½‘.cpws.js.md`

### æ ¸å¿ƒæŠ€æœ¯ç‚¹

#### 1. åŠ å¯†å‚æ•°ç”Ÿæˆ
```python
import hashlib
import time
import random
import string

def generate_cipher():
    """ç”Ÿæˆcipherå‚æ•°ï¼ˆå‚è€ƒJSä»£ç ï¼‰"""
    timestamp = str(int(time.time() * 1000))
    salt = ''.join(random.choices(string.ascii_letters + string.digits, k=24))
    
    # è·å–æ—¥æœŸ
    now = datetime.now()
    iv = now.strftime('%Y%m%d')
    
    # 3DESåŠ å¯†ï¼ˆéœ€è¦å®ç°ï¼‰
    enc = des3_encrypt(timestamp, salt, iv)
    
    # è½¬äºŒè¿›åˆ¶
    cipher_str = salt + iv + enc
    cipher_binary = str_to_binary(cipher_str)
    
    return cipher_binary

def str_to_binary(text):
    """å­—ç¬¦ä¸²è½¬äºŒè¿›åˆ¶"""
    result = []
    for char in text:
        binary = bin(ord(char))[2:]
        result.append(binary)
    return ' '.join(result)
```

#### 2. è¯·æ±‚å‚æ•°
```python
def search_cases(company_name):
    """æœç´¢æ¡ˆä»¶"""
    url = "https://wenshu.court.gov.cn/website/wenshu/181107ANFZ0BXSK4/index.html"
    
    headers = {
        'User-Agent': 'Mozilla/5.0...',
        'Referer': 'https://wenshu.court.gov.cn/'
    }
    
    # ç”ŸæˆåŠ å¯†å‚æ•°
    cipher = generate_cipher()
    guid = str(uuid.uuid4()).replace('-', '')
    
    params = {
        'Param': company_name,
        'Index': 1,
        'Page': 20,
        'Order': 'æ³•é™¢å±‚çº§',
        'Direction': 'asc',
        'vl5x': cipher,
        'guid': guid,
        'cfg': 'com.lawyee.judge.dc.parse.dto.SearchDataDsoDTO@queryDoc'
    }
    
    response = requests.post(url, data=params, headers=headers)
    return response.json()
```

#### 3. 3DESåŠ å¯†å®ç°
```python
from Crypto.Cipher import DES3
from Crypto.Util.Padding import pad
import base64

def des3_encrypt(plaintext, key, iv):
    """3DESåŠ å¯†"""
    # ç¡®ä¿keyé•¿åº¦ä¸º24å­—èŠ‚
    key = key.ljust(24, '0')[:24].encode('utf-8')
    iv = iv.encode('utf-8')
    
    cipher = DES3.new(key, DES3.MODE_CBC, iv)
    padded_text = pad(plaintext.encode('utf-8'), DES3.block_size)
    encrypted = cipher.encrypt(padded_text)
    
    return base64.b64encode(encrypted).decode('utf-8')
```

---

## 2ï¸âƒ£ å·¨æ½®èµ„è®¯ç½‘

### APIåœ°å€
```
http://www.cninfo.com.cn/new/hisAnnouncement/query
```

### è¯·æ±‚å‚æ•°
```python
def get_announcements(stock_code, days=30):
    """è·å–å…¬å‘Š"""
    url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
    
    # æ¸…ç†è‚¡ç¥¨ä»£ç 
    clean_code = stock_code.replace('.SH', '').replace('.SZ', '')
    
    # åˆ¤æ–­å¸‚åœº
    if stock_code.startswith('6'):
        plate = 'sh'  # ä¸Šäº¤æ‰€
    else:
        plate = 'sz'  # æ·±äº¤æ‰€
    
    # æ—¥æœŸèŒƒå›´
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    headers = {
        'User-Agent': 'Mozilla/5.0...',
        'Referer': 'http://www.cninfo.com.cn/',
        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
        'X-Requested-With': 'XMLHttpRequest'
    }
    
    data = {
        'stock': clean_code,
        'searchkey': '',
        'plate': plate,
        'category': '',  # å…¬å‘Šç±»å‹
        'trade': '',
        'column': plate,
        'columnTitle': 'å†å²å…¬å‘ŠæŸ¥è¯¢',
        'pageNum': 1,
        'pageSize': 30,
        'tabName': 'fulltext',
        'sortName': '',
        'sortType': '',
        'limit': '',
        'showTitle': '',
        'seDate': f"{start_date.strftime('%Y-%m-%d')}~{end_date.strftime('%Y-%m-%d')}"
    }
    
    response = requests.post(url, data=data, headers=headers)
    return response.json()
```

### å“åº”è§£æ
```python
def parse_announcements(response_data):
    """è§£æå…¬å‘Šæ•°æ®"""
    announcements = []
    
    if 'announcements' in response_data:
        for item in response_data['announcements']:
            announcement = {
                'announcement_id': item.get('announcementId'),
                'stock_code': item.get('secCode'),
                'stock_name': item.get('secName'),
                'title': item.get('announcementTitle'),
                'type': item.get('announcementType'),
                'publish_date': item.get('announcementTime'),
                'url': f"http://www.cninfo.com.cn/{item.get('adjunctUrl')}",
                'summary': item.get('announcementContent', '')[:200]
            }
            announcements.append(announcement)
    
    return announcements
```

---

## 3ï¸âƒ£ è´¢è”ç¤¾

### å‚è€ƒèµ„æ–™
- åŠ å¯†ä»£ç : `docs/è´¢è”ç¤¾.js.md`

### MD5åŠ å¯†å®ç°
```python
import hashlib

def generate_md5_token(timestamp):
    """ç”ŸæˆMD5 tokenï¼ˆå‚è€ƒJSä»£ç ï¼‰"""
    # å‚è€ƒè´¢è”ç¤¾.js.mdä¸­çš„åŠ å¯†é€»è¾‘
    secret = "your_secret_key"  # éœ€è¦ä»JSä¸­æå–
    raw_string = f"{timestamp}{secret}"
    
    md5_hash = hashlib.md5(raw_string.encode('utf-8')).hexdigest()
    return md5_hash
```

### APIè°ƒç”¨
```python
def get_cls_news():
    """è·å–è´¢è”ç¤¾å¿«è®¯"""
    url = "https://www.cls.cn/api/sw"
    
    timestamp = str(int(time.time() * 1000))
    token = generate_md5_token(timestamp)
    
    headers = {
        'User-Agent': 'Mozilla/5.0...',
        'Referer': 'https://www.cls.cn/',
        'token': token,
        'timestamp': timestamp
    }
    
    params = {
        'app': 'CailianpressWeb',
        'os': 'web',
        'sv': '7.7.5',
        'sign': token
    }
    
    response = requests.get(url, params=params, headers=headers)
    return response.json()
```

---

## ğŸ”§ å®ç°æ­¥éª¤

### é˜¶æ®µ1: åŸºç¡€å®ç°ï¼ˆæœ¬å‘¨ï¼‰

#### 1. å®‰è£…ä¾èµ–
```bash
pip install pycryptodome  # ç”¨äº3DESåŠ å¯†
pip install curl_cffi      # ç”¨äºæ¨¡æ‹Ÿæµè§ˆå™¨
```

#### 2. å®ç°åŠ å¯†å‡½æ•°
- 3DESåŠ å¯†ï¼ˆä¸­å›½è£åˆ¤æ–‡ä¹¦ç½‘ï¼‰
- MD5åŠ å¯†ï¼ˆè´¢è”ç¤¾ï¼‰

#### 3. å®ç°APIè°ƒç”¨
- ä¸­å›½è£åˆ¤æ–‡ä¹¦ç½‘æœç´¢
- å·¨æ½®èµ„è®¯ç½‘å…¬å‘ŠæŸ¥è¯¢
- è´¢è”ç¤¾å¿«è®¯è·å–

### é˜¶æ®µ2: åçˆ¬è™«å¤„ç†ï¼ˆä¸‹å‘¨ï¼‰

#### 1. ä½¿ç”¨curl_cffi
```python
from curl_cffi import requests as curl_requests

session = curl_requests.Session(impersonate="chrome120")
response = session.get(url, headers=headers)
```

#### 2. ä»£ç†IPæ± 
```python
proxies = {
    'http': 'http://proxy1:port',
    'https': 'https://proxy1:port'
}

response = requests.get(url, proxies=proxies)
```

#### 3. è¯·æ±‚é¢‘ç‡æ§åˆ¶
```python
import time

def rate_limited_request(url, min_interval=1):
    """é™åˆ¶è¯·æ±‚é¢‘ç‡"""
    time.sleep(min_interval)
    return requests.get(url)
```

### é˜¶æ®µ3: é›†æˆåˆ°ç»Ÿä¸€APIï¼ˆä¸‹ä¸‹å‘¨ï¼‰

#### 1. æ›´æ–°unified_news_api.py
```python
# æ·»åŠ æ³•å¾‹é£é™©æ•°æ®æº
from backend.dataflows.legal.wenshu_crawler import get_wenshu_crawler

# æ·»åŠ å…¬å¸å…¬å‘Šæ•°æ®æº
from backend.dataflows.announcement.cninfo_crawler import get_cninfo_crawler
```

#### 2. åˆ›å»ºAPIç«¯ç‚¹
```python
@router.get("/api/legal-risk/{stock_code}")
async def get_legal_risk(stock_code: str):
    """è·å–æ³•å¾‹é£é™©"""
    crawler = get_wenshu_crawler()
    # è·å–å…¬å¸åç§°
    company_name = get_company_name(stock_code)
    cases = crawler.search_company_cases(company_name)
    risk = crawler.analyze_legal_risk(cases)
    return risk
```

---

## ğŸ“‹ æ³¨æ„äº‹é¡¹

### 1. æ³•å¾‹åˆè§„
- éµå®ˆrobots.txt
- ä¸è¦é¢‘ç¹è¯·æ±‚
- ä»…ç”¨äºä¸ªäººå­¦ä¹ ç ”ç©¶

### 2. æ•°æ®å‡†ç¡®æ€§
- éªŒè¯è¿”å›æ•°æ®
- å¤„ç†å¼‚å¸¸æƒ…å†µ
- è®°å½•é”™è¯¯æ—¥å¿—

### 3. æ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨ç¼“å­˜
- å¼‚æ­¥è¯·æ±‚
- è¿æ¥æ± å¤ç”¨

---

## ğŸ§ª æµ‹è¯•

### æµ‹è¯•è„šæœ¬
```python
# test_real_api.py
def test_wenshu():
    """æµ‹è¯•è£åˆ¤æ–‡ä¹¦ç½‘"""
    crawler = get_wenshu_crawler()
    cases = crawler.search_company_cases("è´µå·èŒ…å°é…’è‚¡ä»½æœ‰é™å…¬å¸")
    assert len(cases) > 0
    
def test_cninfo():
    """æµ‹è¯•å·¨æ½®èµ„è®¯ç½‘"""
    crawler = get_cninfo_crawler()
    announcements = crawler.get_company_announcements("600519")
    assert len(announcements) > 0
```

---

## ğŸ“š å‚è€ƒèµ„æº

### GitHubé¡¹ç›®
1. https://github.com/nixinxin/WenShu
2. https://github.com/sixs/wenshu_spider

### åŠ å¯†ä»£ç 
1. `docs/ä¸­å›½è£åˆ¤æ–‡ä¹¦ç½‘.cpws.js.md` - 3DESåŠ å¯†
2. `docs/è´¢è”ç¤¾.js.md` - MD5åŠ å¯†

### APIæ–‡æ¡£
1. å·¨æ½®èµ„è®¯ç½‘: http://www.cninfo.com.cn
2. è´¢è”ç¤¾: https://www.cls.cn

---

**ä¸‹ä¸€æ­¥**: å¼€å§‹å®ç°3DESåŠ å¯†å’ŒçœŸå®APIè°ƒç”¨ï¼
